{
    "docs": [
        {
            "location": "/",
            "text": "Computer Science Notes\n\u00b6\n\n\nGetting Started\n\u00b6\n\n\nIn this website, I'll work on my notes about several topics:\n\n\n\n\nLeetCode in Python\n\n\nOperating System | notes\n\n\nMaching Learning | notes\n\n\n\n\nPlease don't hesitate to give me your feedback if any adjustment is needed. You can simply press the \"Pencil icon\" in the upper right corner to edit the contents.\n\n\nHow I generate this website\n\u00b6\n\n\nI use the static site generator \nMkDocs\n and the beautiful theme \nMaterial for MkDocs\n to build this website!\n\n\nSince there are some LaTeX equations \nKaTeX\n doesn't support, here I use \nMathJax\n to render the math equations in my website.\n\n\nI also add \noverflow-x: auto\n to prevent the overflow issue on mobile devices, so you can scroll horizontally in the math display equations.\n\n\nMore Informations\n\u00b6\n\n\nFor more informations please visit \nmy github site\n.\n\n\nMy blog: \nJay's Blog\n\n\nMail to: \nwalkccray@gmail.com\n\n\nBy Jay Chen on April 13, 2018.",
            "title": "Preface"
        },
        {
            "location": "/#computer-science-notes",
            "text": "",
            "title": "Computer Science Notes"
        },
        {
            "location": "/#getting-started",
            "text": "In this website, I'll work on my notes about several topics:   LeetCode in Python  Operating System | notes  Maching Learning | notes   Please don't hesitate to give me your feedback if any adjustment is needed. You can simply press the \"Pencil icon\" in the upper right corner to edit the contents.",
            "title": "Getting Started"
        },
        {
            "location": "/#how-i-generate-this-website",
            "text": "I use the static site generator  MkDocs  and the beautiful theme  Material for MkDocs  to build this website!  Since there are some LaTeX equations  KaTeX  doesn't support, here I use  MathJax  to render the math equations in my website.  I also add  overflow-x: auto  to prevent the overflow issue on mobile devices, so you can scroll horizontally in the math display equations.",
            "title": "How I generate this website"
        },
        {
            "location": "/#more-informations",
            "text": "For more informations please visit  my github site .  My blog:  Jay's Blog  Mail to:  walkccray@gmail.com  By Jay Chen on April 13, 2018.",
            "title": "More Informations"
        },
        {
            "location": "/LeetCode/",
            "text": "Solutions to LeetCode in Python\n\u00b6",
            "title": "Preface"
        },
        {
            "location": "/LeetCode/#solutions-to-leetcode-in-python",
            "text": "",
            "title": "Solutions to LeetCode in Python"
        },
        {
            "location": "/LeetCode/001-100/001-010/",
            "text": "1. Two Sum \n$\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \ntwoSum\n(\nself\n,\n \nnums\n,\n \ntarget\n):\n\n        \nmap\n \n=\n \n{}\n\n        \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\nnums\n)):\n\n            \nif\n \nnums\n[\ni\n]\n \nnot\n \nin\n \nmap\n:\n\n                \nmap\n[\ntarget\n \n-\n \nnums\n[\ni\n]]\n \n=\n \ni\n\n            \nelse\n:\n\n                \nreturn\n \nmap\n[\nnums\n[\ni\n]],\n \ni\n\n    \nreturn\n \n-\n1\n,\n \n-\n1\n\n\n\n\n\nMap each $number$ in $nums$ with $target - number$ in line 6.\n\n\nWhen next time we find that the $number$ is in the map, simply return them.\n\n\n2. Add Two Numbers \n$\\star\\star$\n\u00b6\n\n\n# Definition for singly-linked list.\n\n\n# class ListNode(object):\n\n\n# def __init__(self, x):\n\n\n# self.val = x\n\n\n# self.next = None\n\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \naddTwoNumbers\n(\nself\n,\n \nl1\n,\n \nl2\n):\n\n        \ncarry\n \n=\n \n0\n\n        \nroot\n \n=\n \nn\n \n=\n \nListNode\n(\n0\n)\n\n        \nwhile\n \nl1\n \nor\n \nl2\n \nor\n \ncarry\n:\n\n            \nval1\n \n=\n \nval2\n \n=\n \n0\n\n            \nif\n \nl1\n:\n\n                \nval1\n \n=\n \nl1\n.\nval\n\n                \nl1\n \n=\n \nl1\n.\nnext\n\n            \nif\n \nl2\n:\n\n                \nval2\n \n=\n \nl2\n.\nval\n\n                \nl2\n \n=\n \nl2\n.\nnext\n\n            \ncarry\n,\n \nval\n \n=\n \ndivmod\n(\nval1\n \n+\n \nval2\n \n+\n \ncarry\n,\n \n10\n)\n\n            \nn\n.\nnext\n \n=\n \nListNode\n(\nval\n)\n\n            \nn\n \n=\n \nn\n.\nnext\n\n        \nreturn\n \nroot\n.\nnext\n\n\n\n\n\nKeep a $carry$ and initialize it with $0$, if $val1 + val2 + carry \\ge 10$, $carry = 1$.\n\n\nFor example,\n\n\n\n\\begin{align}\n\\text{Enter while}, \\\\\n2 + 5 + 0 (carry) & = 7  & \\Rightarrow carry = 0, \\\\\n4 + 6 + 0 (carry) & = 10 & \\Rightarrow carry = 1, \\\\\n3 + 4 + 1 (carry) & = 8  & \\Rightarrow carry = 0, \\\\\n\\text{end while}.\n\\end{align}\n\n\n\n\n3. Longest Substring Without Repeating Characters \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nlengthOfLongestSubstring\n(\nself\n,\n \ns\n):\n\n        \ncur\n \n=\n \nmaxLength\n \n=\n \n0\n         \n        \nusedChar\n \n=\n \n{}\n\n        \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\ns\n)):\n\n            \nif\n \ns\n[\ni\n]\n \nin\n \nusedChar\n \nand\n \ncur\n \n<=\n \nusedChar\n[\ns\n[\ni\n]]:\n\n                \ncur\n \n=\n \nusedChar\n[\ns\n[\ni\n]]\n \n+\n \n1\n\n            \nelse\n:\n\n                \nmaxLength\n \n=\n \nmax\n(\nmaxLength\n,\n \ni\n \n-\n \ncur\n \n+\n \n1\n)\n\n            \nusedChar\n[\ns\n[\ni\n]]\n \n=\n \ni\n\n        \nreturn\n \nmaxLength\n\n\n\n\n\nFirst initialize a map named $usedChar$.\n\n\nFor each char in the string $s$:\n\n\n\n\nif the char is in the $usedChar$ (there are repeating characters) and $cur \\le \\text{the map of that char}$, update the current position to the index next to that char.\n\n\nelse (the substring is still no repeating characters), update the value of $maxLength$.\n\n\nmap the char with its index, sometimes we mean to \nupdate\n it.\n\n\n\n\n4. Median of Two Sorted Arrays \n$\\star\\star\\star$\n\u00b6\n\n\n5. Longest Palindromic Substring \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nlongestPalindrome\n(\nself\n,\n \ns\n):\n\n        \ns\n \n=\n \n'#'\n \n+\n \n'#'\n.\njoin\n(\ns\n)\n \n+\n \n'#'\n                             \n# for example: \"aba\" -> \"#a#b#a#\"\n\n        \nRL\n \n=\n \n[\n0\n]\n \n*\n \nlen\n(\ns\n)\n\n        \npos\n \n=\n \nmaxRight\n \n=\n \nmaxPos\n \n=\n \nmaxLen\n \n=\n \n0\n\n        \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\ns\n)):\n\n            \nif\n \ni\n \n<\n \nmaxRight\n:\n\n                \nRL\n[\ni\n]\n \n=\n \nmin\n(\nRL\n[\n2\n \n*\n \npos\n \n-\n \ni\n],\n \nmaxRight\n \n-\n \ni\n)\n      \n# 2 * pos - i = i - 2 * (i - pos)\n\n            \nelse\n:\n\n                \nRL\n[\ni\n]\n \n=\n \n1\n\n            \nwhile\n \ni\n \n-\n \nRL\n[\ni\n]\n \n>=\n \n0\n \nand\n \ni\n \n+\n \nRL\n[\ni\n]\n \n<\n \nlen\n(\ns\n)\n \nand\n \ns\n[\ni\n \n-\n \nRL\n[\ni\n]]\n \n==\n \ns\n[\ni\n \n+\n \nRL\n[\ni\n]]:\n\n                \nRL\n[\ni\n]\n \n+=\n \n1\n\n            \nif\n \nRL\n[\ni\n]\n \n+\n \ni\n \n-\n \n1\n \n>\n \nmaxRight\n:\n                        \n# update maxRight (boundaray) and the according position\n\n                \npos\n,\n \nmaxRight\n \n=\n \ni\n,\n \nRL\n[\ni\n]\n \n+\n \ni\n \n-\n \n1\n\n            \nif\n \nmaxLen\n \n<\n \nRL\n[\ni\n]:\n                                  \n# update maxLen and the according position\n\n                \nmaxPos\n,\n \nmaxLen\n \n=\n \npos\n,\n \nRL\n[\ni\n]\n \n-\n \n1\n\n        \ns\n \n=\n \ns\n[\nmaxPos\n \n-\n \nmaxLen\n:\nmaxPos\n \n+\n \nmaxLen\n \n+\n \n1\n]\n              \n# take the desire part, including '#'\n\n        \ns\n \n=\n \ns\n.\nreplace\n(\n'#'\n,\n \n''\n)\n                                  \n# replace '#'s with ''\n\n        \nreturn\n \ns\n\n\n\n\n\nBy using \nManacher's\n Algorithm\n, we can find out the longest palindrome in $O(n)$.\n\n\nThe key idea is to keep a variable $RL$, which records the longest length extended from index $i$.\n\n\nFor better comprehension, I use \nreplace()\n instead of calculate the index in the original string $s$.\n\n\n6. ZigZag Conversion \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nconvert\n(\nself\n,\n \ns\n,\n \nnumRows\n):\n\n        \ndirection\n \n=\n \n(\nnumRows\n \n==\n \n1\n)\n \n-\n \n1\n\n        \nrows\n,\n \nidx\n \n=\n \n[\n''\n]\n \n*\n \nnumRows\n,\n \n0\n\n        \nfor\n \nc\n \nin\n \ns\n:\n\n            \nrows\n[\nidx\n]\n \n+=\n \nc\n\n            \nif\n \nidx\n \n==\n \n0\n \nor\n \nidx\n \n==\n \nnumRows\n \n-\n \n1\n:\n\n                \ndirection\n \n*=\n \n-\n1\n\n            \nidx\n \n+=\n \ndirection\n\n        \nreturn\n \n''\n.\njoin\n(\nrows\n)\n\n\n\n\n\nThe solution is very simple by using list in Python.\n\n\nWe keep a variable $direction$ to determine the direction of the zigzag pattern, and add them to the list $rows$.\n\n\n7. Reverse Integer \n$\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nreverse\n(\nself\n,\n \nx\n):\n\n        \nisNegative\n \n=\n \nFalse\n\n        \nif\n \nx\n \n<\n \n0\n:\n               \n# x is negative\n\n            \nx\n \n*=\n \n-\n1\n\n            \nisNegative\n \n=\n \nTrue\n\n        \nret\n \n=\n \n0\n\n        \nwhile\n \nx\n \n!=\n \n0\n:\n\n            \nret\n \n=\n \nret\n \n*\n \n10\n \n+\n \nx\n \n%\n \n10\n\n            \nx\n \n/=\n \n10\n\n        \nif\n \nisNegative\n:\n\n            \nret\n \n*=\n \n-\n1\n\n        \nif\n \nret\n \n>\n \n2\n**\n31\n \n-\n \n1\n \nor\n \nret\n \n<\n \n-\n2\n**\n31\n:\n\n            \nreturn\n \n0\n\n        \nreturn\n \nret\n\n\n\n\n\nIn order to handle a negative integer, we declare a variable $isNegative$.\n\n\nSince Python won't overflow, so we have to check whether the $ret$ is $> 2^{31} - 1$ or $< -2^{31}$.\n\n\n8. String to Integer (atoi) \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nmyAtoi\n(\nself\n,\n \ns\n):\n\n        \nif\n \nlen\n(\ns\n)\n \n==\n \n0\n:\n\n            \nreturn\n \n0\n\n        \nls\n \n=\n \nlist\n(\ns\n.\nstrip\n())\n\n        \nsign\n \n=\n \n-\n1\n \nif\n \nls\n[\n0\n]\n \n==\n \n'-'\n \nelse\n \n1\n\n        \nif\n \nls\n[\n0\n]\n \nin\n \n[\n'-'\n,\n \n'+'\n]:\n\n            \ndel\n \nls\n[\n0\n]\n\n        \nret\n,\n \ni\n \n=\n \n0\n,\n \n0\n\n        \nwhile\n \ni\n \n<\n \nlen\n(\nls\n)\n \nand\n \nls\n[\ni\n]\n.\nisdigit\n():\n\n            \nret\n \n=\n \nret\n \n*\n \n10\n \n+\n \nord\n(\nls\n[\ni\n])\n \n-\n \nord\n(\n'0'\n)\n\n            \ni\n \n+=\n \n1\n\n        \nreturn\n \nmax\n(\n-\n2\n**\n31\n,\n \nmin\n(\n2\n**\n31\n \n-\n \n1\n,\n \nsign\n \n*\n \nret\n))\n\n\n\n\n\nThe solution is very concise, if the string is empty, simply return $0$.\n\n\nWe have to use strip() to eliminate the blanks in the head and tail.\n\n\nFinally, if the $ret$ is $> 2^{31} - 1$, return $2^{31} - 1$ (INT_MAX).\n\n\nelse if the $ret$ is $< -2^{31}$, return $-2^{31}$ (INT_MIN).\n\n\n9. Palindrome Number \n$\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nisPalindrome\n(\nself\n,\n \nx\n):\n\n        \nif\n \nx\n \n<\n \n0\n \nor\n \nx\n \n!=\n \n0\n \nand\n \nx\n \n%\n \n10\n \n==\n \n0\n:\n\n            \nreturn\n \nFalse\n\n        \nrev\n \n=\n \n0\n\n        \nwhile\n \nx\n \n>\n \nrev\n:\n\n            \nrev\n \n=\n \nrev\n \n*\n \n10\n \n+\n \nx\n \n%\n \n10\n\n            \nx\n \n/=\n \n10\n\n        \nreturn\n \nx\n \n==\n \nrev\n \nor\n \nx\n \n==\n \nrev\n \n/\n \n10\n\n\n\n\n\nIf $x < 0$ or is an integer $\\ne 0$ but end with $0$, return False.\n\n\nThen simply reverse the $x$ until $x \\le rev$.\n\n\nIf $x = rev$ or $x = rev / 10$, return True, else return False.\n\n\n10. Regular Expression Matching \n$\\star\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nisMatch\n(\nself\n,\n \ns\n,\n \np\n):\n\n        \ndp\n \n=\n \n[[\nFalse\n]\n \n*\n \n(\nlen\n(\np\n)\n \n+\n \n1\n)\n \nfor\n \n_\n \nin\n \nrange\n(\nlen\n(\ns\n)\n \n+\n \n1\n)]\n\n        \ndp\n[\n0\n][\n0\n]\n \n=\n \nTrue\n\n        \nfor\n \nj\n \nin\n \nrange\n(\n1\n,\n \nlen\n(\np\n)\n \n+\n \n1\n):\n      \n# Initialize the first row\n\n            \nif\n \np\n[\nj\n \n-\n \n1\n]\n \n==\n \n'*'\n:\n\n                \ndp\n[\n0\n][\nj\n]\n \n=\n \ndp\n[\n0\n][\nj\n \n-\n \n2\n]\n\n        \nfor\n \ni\n \nin\n \nrange\n(\n1\n,\n \nlen\n(\ns\n)\n \n+\n \n1\n):\n\n            \nfor\n \nj\n \nin\n \nrange\n(\n1\n,\n \nlen\n(\np\n)\n \n+\n \n1\n):\n\n                \nif\n \ns\n[\ni\n \n-\n \n1\n]\n \n==\n \np\n[\nj\n \n-\n \n1\n]\n \nor\n \np\n[\nj\n \n-\n \n1\n]\n \n==\n \n'.'\n:\n\n                    \ndp\n[\ni\n][\nj\n]\n \n=\n \ndp\n[\ni\n \n-\n \n1\n][\nj\n \n-\n \n1\n]\n\n                \nelif\n \np\n[\nj\n \n-\n \n1\n]\n \n!=\n \n'*'\n:\n\n                    \ndp\n[\ni\n][\nj\n]\n \n=\n \nFalse\n\n                \nelif\n \np\n[\nj\n \n-\n \n1\n]\n \n==\n \n'*'\n \nand\n \n(\ns\n[\ni\n \n-\n \n1\n]\n \n==\n \np\n[\nj\n \n-\n \n2\n]\n \nor\n \np\n[\nj\n \n-\n \n2\n]\n \n==\n \n'.'\n):\n\n                    \ndp\n[\ni\n][\nj\n]\n \n=\n \ndp\n[\ni\n][\nj\n \n-\n \n2\n]\n \nor\n \ndp\n[\ni\n \n-\n \n1\n][\nj\n]\n\n                \nelse\n:\n \n                    \ndp\n[\ni\n][\nj\n]\n \n=\n \ndp\n[\ni\n][\nj\n \n-\n \n2\n]\n\n        \nreturn\n \ndp\n[\n-\n1\n][\n-\n1\n]\n\n\n\n\n\nFor example, if the inputs are $s = \"ab\"$ and $p = \".*\"$. We initialize a  DP table size of $[len(s) + 1] \\times [len(p) + 1]$:\n\n\n\n\\begin{array}{|c|c|c|c|}\n\\hline\ns \\backslash p  &   & . & * \\\\\n\\hline\n       &  &  &  \\\\\n\\hline\n     a &  &  &  \\\\\n\\hline\n     b &  &  &  \\\\\n\\hline\n\\end{array} \n\n\n\n\n(\nNote:\n The indices of $s$ and $p$ equal to index of $dp$ - $1$)\n\n\nSince $s = \"\"$ matches $p = \"\"$, $dp[0][0]$ must be $True$. Then we initailize the first row, if $p[j - 1] == \"*\"$, then $dp[0][j]$ must equal to $dp[0][j - 2]$, which means $p[i - 2]$ occurs zero time in this case.\n\n\nWe then continue to fill in the DP table row by row and column by column. There are 4 cases:\n\n\n\n\nIf $s[i - 1] == p[j - 1]$ or $p[j - 1] == \".\"$, which means $s[i - 1]$ matches $p[j - 1]$, so\n\\begin{equation}\ndp[i][j] = dp[i - 1][j - 1] \\quad (\\nwarrow).\n\\end{equation}\n\n\nElse if $p[i - 1] != \".\"$, which means $s[i - 1]$ doesn't match $p[j - 1]$, so\n\\begin{equation}\ndp[i][j] = False.\n\\end{equation}\n\n\nElse if $p[j - 1] == \"*\"$ and ($s[i - 1] == p[j - 2]$ or $p[j - 2] == \".\"$), which means $s[i - 1]$ matches $p[j - 2]$, thus $p[j - 2]$ occurs zero time or one time, so\n\\begin{equation}\ndp[i][j] = (dp[i][j - 2] \\quad (\\leftarrow\\leftarrow) ||dp[i - 1][j] \\quad (\\uparrow)).\n\\end{equation}\n\n\nElse if $p[j - 1] == \"*\"$ and ($s[i - 1] != p[j - 2]$ and $p[j - 2] != \".\"$), which means $s[i - 1]$ doesn't match $p[j - 2]$, thus $p[j - 2]$ occurs zero time, so\n\\begin{equation}\ndp[i][j] = dp[i][j - 2].\n\\end{equation}\n\n\n\n\nFinally, the DP table will look like:\n\n\n\n\\begin{array}{|c|c|c|c|}\n\\hline\ns \\backslash p  &   & . & * \\\\\n\\hline\n       & 1 & 0 & 1 \\\\\n\\hline\n     a & 0 & 1 & 1 \\\\\n\\hline\n     b & 0 & 0 & 1 \\\\\n\\hline\n\\end{array}",
            "title": "001-010"
        },
        {
            "location": "/LeetCode/001-100/001-010/#1-two-sum-star",
            "text": "class   Solution ( object ): \n     def   twoSum ( self ,   nums ,   target ): \n         map   =   {} \n         for   i   in   range ( len ( nums )): \n             if   nums [ i ]   not   in   map : \n                 map [ target   -   nums [ i ]]   =   i \n             else : \n                 return   map [ nums [ i ]],   i \n     return   - 1 ,   - 1   Map each $number$ in $nums$ with $target - number$ in line 6.  When next time we find that the $number$ is in the map, simply return them.",
            "title": "1. Two Sum $\\star$"
        },
        {
            "location": "/LeetCode/001-100/001-010/#2-add-two-numbers-starstar",
            "text": "# Definition for singly-linked list.  # class ListNode(object):  # def __init__(self, x):  # self.val = x  # self.next = None  class   Solution ( object ): \n     def   addTwoNumbers ( self ,   l1 ,   l2 ): \n         carry   =   0 \n         root   =   n   =   ListNode ( 0 ) \n         while   l1   or   l2   or   carry : \n             val1   =   val2   =   0 \n             if   l1 : \n                 val1   =   l1 . val \n                 l1   =   l1 . next \n             if   l2 : \n                 val2   =   l2 . val \n                 l2   =   l2 . next \n             carry ,   val   =   divmod ( val1   +   val2   +   carry ,   10 ) \n             n . next   =   ListNode ( val ) \n             n   =   n . next \n         return   root . next   Keep a $carry$ and initialize it with $0$, if $val1 + val2 + carry \\ge 10$, $carry = 1$.  For example,  \n\\begin{align}\n\\text{Enter while}, \\\\\n2 + 5 + 0 (carry) & = 7  & \\Rightarrow carry = 0, \\\\\n4 + 6 + 0 (carry) & = 10 & \\Rightarrow carry = 1, \\\\\n3 + 4 + 1 (carry) & = 8  & \\Rightarrow carry = 0, \\\\\n\\text{end while}.\n\\end{align}",
            "title": "2. Add Two Numbers $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/001-010/#3-longest-substring-without-repeating-characters-starstar",
            "text": "class   Solution ( object ): \n     def   lengthOfLongestSubstring ( self ,   s ): \n         cur   =   maxLength   =   0          \n         usedChar   =   {} \n         for   i   in   range ( len ( s )): \n             if   s [ i ]   in   usedChar   and   cur   <=   usedChar [ s [ i ]]: \n                 cur   =   usedChar [ s [ i ]]   +   1 \n             else : \n                 maxLength   =   max ( maxLength ,   i   -   cur   +   1 ) \n             usedChar [ s [ i ]]   =   i \n         return   maxLength   First initialize a map named $usedChar$.  For each char in the string $s$:   if the char is in the $usedChar$ (there are repeating characters) and $cur \\le \\text{the map of that char}$, update the current position to the index next to that char.  else (the substring is still no repeating characters), update the value of $maxLength$.  map the char with its index, sometimes we mean to  update  it.",
            "title": "3. Longest Substring Without Repeating Characters $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/001-010/#4-median-of-two-sorted-arrays-starstarstar",
            "text": "",
            "title": "4. Median of Two Sorted Arrays $\\star\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/001-010/#5-longest-palindromic-substring-starstar",
            "text": "class   Solution ( object ): \n     def   longestPalindrome ( self ,   s ): \n         s   =   '#'   +   '#' . join ( s )   +   '#'                               # for example: \"aba\" -> \"#a#b#a#\" \n         RL   =   [ 0 ]   *   len ( s ) \n         pos   =   maxRight   =   maxPos   =   maxLen   =   0 \n         for   i   in   range ( len ( s )): \n             if   i   <   maxRight : \n                 RL [ i ]   =   min ( RL [ 2   *   pos   -   i ],   maxRight   -   i )        # 2 * pos - i = i - 2 * (i - pos) \n             else : \n                 RL [ i ]   =   1 \n             while   i   -   RL [ i ]   >=   0   and   i   +   RL [ i ]   <   len ( s )   and   s [ i   -   RL [ i ]]   ==   s [ i   +   RL [ i ]]: \n                 RL [ i ]   +=   1 \n             if   RL [ i ]   +   i   -   1   >   maxRight :                          # update maxRight (boundaray) and the according position \n                 pos ,   maxRight   =   i ,   RL [ i ]   +   i   -   1 \n             if   maxLen   <   RL [ i ]:                                    # update maxLen and the according position \n                 maxPos ,   maxLen   =   pos ,   RL [ i ]   -   1 \n         s   =   s [ maxPos   -   maxLen : maxPos   +   maxLen   +   1 ]                # take the desire part, including '#' \n         s   =   s . replace ( '#' ,   '' )                                    # replace '#'s with '' \n         return   s   By using  Manacher's  Algorithm , we can find out the longest palindrome in $O(n)$.  The key idea is to keep a variable $RL$, which records the longest length extended from index $i$.  For better comprehension, I use  replace()  instead of calculate the index in the original string $s$.",
            "title": "5. Longest Palindromic Substring $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/001-010/#6-zigzag-conversion-starstar",
            "text": "class   Solution ( object ): \n     def   convert ( self ,   s ,   numRows ): \n         direction   =   ( numRows   ==   1 )   -   1 \n         rows ,   idx   =   [ '' ]   *   numRows ,   0 \n         for   c   in   s : \n             rows [ idx ]   +=   c \n             if   idx   ==   0   or   idx   ==   numRows   -   1 : \n                 direction   *=   - 1 \n             idx   +=   direction \n         return   '' . join ( rows )   The solution is very simple by using list in Python.  We keep a variable $direction$ to determine the direction of the zigzag pattern, and add them to the list $rows$.",
            "title": "6. ZigZag Conversion $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/001-010/#7-reverse-integer-star",
            "text": "class   Solution ( object ): \n     def   reverse ( self ,   x ): \n         isNegative   =   False \n         if   x   <   0 :                 # x is negative \n             x   *=   - 1 \n             isNegative   =   True \n         ret   =   0 \n         while   x   !=   0 : \n             ret   =   ret   *   10   +   x   %   10 \n             x   /=   10 \n         if   isNegative : \n             ret   *=   - 1 \n         if   ret   >   2 ** 31   -   1   or   ret   <   - 2 ** 31 : \n             return   0 \n         return   ret   In order to handle a negative integer, we declare a variable $isNegative$.  Since Python won't overflow, so we have to check whether the $ret$ is $> 2^{31} - 1$ or $< -2^{31}$.",
            "title": "7. Reverse Integer $\\star$"
        },
        {
            "location": "/LeetCode/001-100/001-010/#8-string-to-integer-atoi-starstar",
            "text": "class   Solution ( object ): \n     def   myAtoi ( self ,   s ): \n         if   len ( s )   ==   0 : \n             return   0 \n         ls   =   list ( s . strip ()) \n         sign   =   - 1   if   ls [ 0 ]   ==   '-'   else   1 \n         if   ls [ 0 ]   in   [ '-' ,   '+' ]: \n             del   ls [ 0 ] \n         ret ,   i   =   0 ,   0 \n         while   i   <   len ( ls )   and   ls [ i ] . isdigit (): \n             ret   =   ret   *   10   +   ord ( ls [ i ])   -   ord ( '0' ) \n             i   +=   1 \n         return   max ( - 2 ** 31 ,   min ( 2 ** 31   -   1 ,   sign   *   ret ))   The solution is very concise, if the string is empty, simply return $0$.  We have to use strip() to eliminate the blanks in the head and tail.  Finally, if the $ret$ is $> 2^{31} - 1$, return $2^{31} - 1$ (INT_MAX).  else if the $ret$ is $< -2^{31}$, return $-2^{31}$ (INT_MIN).",
            "title": "8. String to Integer (atoi) $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/001-010/#9-palindrome-number-star",
            "text": "class   Solution ( object ): \n     def   isPalindrome ( self ,   x ): \n         if   x   <   0   or   x   !=   0   and   x   %   10   ==   0 : \n             return   False \n         rev   =   0 \n         while   x   >   rev : \n             rev   =   rev   *   10   +   x   %   10 \n             x   /=   10 \n         return   x   ==   rev   or   x   ==   rev   /   10   If $x < 0$ or is an integer $\\ne 0$ but end with $0$, return False.  Then simply reverse the $x$ until $x \\le rev$.  If $x = rev$ or $x = rev / 10$, return True, else return False.",
            "title": "9. Palindrome Number $\\star$"
        },
        {
            "location": "/LeetCode/001-100/001-010/#10-regular-expression-matching-starstarstar",
            "text": "class   Solution : \n     def   isMatch ( self ,   s ,   p ): \n         dp   =   [[ False ]   *   ( len ( p )   +   1 )   for   _   in   range ( len ( s )   +   1 )] \n         dp [ 0 ][ 0 ]   =   True \n         for   j   in   range ( 1 ,   len ( p )   +   1 ):        # Initialize the first row \n             if   p [ j   -   1 ]   ==   '*' : \n                 dp [ 0 ][ j ]   =   dp [ 0 ][ j   -   2 ] \n         for   i   in   range ( 1 ,   len ( s )   +   1 ): \n             for   j   in   range ( 1 ,   len ( p )   +   1 ): \n                 if   s [ i   -   1 ]   ==   p [ j   -   1 ]   or   p [ j   -   1 ]   ==   '.' : \n                     dp [ i ][ j ]   =   dp [ i   -   1 ][ j   -   1 ] \n                 elif   p [ j   -   1 ]   !=   '*' : \n                     dp [ i ][ j ]   =   False \n                 elif   p [ j   -   1 ]   ==   '*'   and   ( s [ i   -   1 ]   ==   p [ j   -   2 ]   or   p [ j   -   2 ]   ==   '.' ): \n                     dp [ i ][ j ]   =   dp [ i ][ j   -   2 ]   or   dp [ i   -   1 ][ j ] \n                 else :  \n                     dp [ i ][ j ]   =   dp [ i ][ j   -   2 ] \n         return   dp [ - 1 ][ - 1 ]   For example, if the inputs are $s = \"ab\"$ and $p = \".*\"$. We initialize a  DP table size of $[len(s) + 1] \\times [len(p) + 1]$:  \n\\begin{array}{|c|c|c|c|}\n\\hline\ns \\backslash p  &   & . & * \\\\\n\\hline\n       &  &  &  \\\\\n\\hline\n     a &  &  &  \\\\\n\\hline\n     b &  &  &  \\\\\n\\hline\n\\end{array}   ( Note:  The indices of $s$ and $p$ equal to index of $dp$ - $1$)  Since $s = \"\"$ matches $p = \"\"$, $dp[0][0]$ must be $True$. Then we initailize the first row, if $p[j - 1] == \"*\"$, then $dp[0][j]$ must equal to $dp[0][j - 2]$, which means $p[i - 2]$ occurs zero time in this case.  We then continue to fill in the DP table row by row and column by column. There are 4 cases:   If $s[i - 1] == p[j - 1]$ or $p[j - 1] == \".\"$, which means $s[i - 1]$ matches $p[j - 1]$, so\n\\begin{equation}\ndp[i][j] = dp[i - 1][j - 1] \\quad (\\nwarrow).\n\\end{equation}  Else if $p[i - 1] != \".\"$, which means $s[i - 1]$ doesn't match $p[j - 1]$, so\n\\begin{equation}\ndp[i][j] = False.\n\\end{equation}  Else if $p[j - 1] == \"*\"$ and ($s[i - 1] == p[j - 2]$ or $p[j - 2] == \".\"$), which means $s[i - 1]$ matches $p[j - 2]$, thus $p[j - 2]$ occurs zero time or one time, so\n\\begin{equation}\ndp[i][j] = (dp[i][j - 2] \\quad (\\leftarrow\\leftarrow) ||dp[i - 1][j] \\quad (\\uparrow)).\n\\end{equation}  Else if $p[j - 1] == \"*\"$ and ($s[i - 1] != p[j - 2]$ and $p[j - 2] != \".\"$), which means $s[i - 1]$ doesn't match $p[j - 2]$, thus $p[j - 2]$ occurs zero time, so\n\\begin{equation}\ndp[i][j] = dp[i][j - 2].\n\\end{equation}   Finally, the DP table will look like:  \n\\begin{array}{|c|c|c|c|}\n\\hline\ns \\backslash p  &   & . & * \\\\\n\\hline\n       & 1 & 0 & 1 \\\\\n\\hline\n     a & 0 & 1 & 1 \\\\\n\\hline\n     b & 0 & 0 & 1 \\\\\n\\hline\n\\end{array}",
            "title": "10. Regular Expression Matching $\\star\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/011-020/",
            "text": "11. Container With Most Water \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nmaxArea\n(\nself\n,\n \nheight\n):\n\n        \nwater\n \n=\n \n0\n\n        \nl\n,\n \nr\n \n=\n \n0\n,\n \nlen\n(\nheight\n)\n \n-\n \n1\n\n        \nwhile\n \nl\n \n<\n \nr\n:\n\n            \nh\n \n=\n \nmin\n(\nheight\n[\nl\n],\n \nheight\n[\nr\n])\n\n            \nwater\n \n=\n \nmax\n(\nwater\n,\n \n(\nr\n \n-\n \nl\n)\n \n*\n \nh\n)\n\n            \nwhile\n \nheight\n[\nl\n]\n \n<=\n \nh\n \nand\n \nl\n \n<\n \nr\n:\n\n                \nl\n \n+=\n \n1\n\n            \nwhile\n \nheight\n[\nr\n]\n \n<=\n \nh\n \nand\n \nl\n \n<\n \nr\n:\n\n                \nr\n \n-=\n \n1\n\n        \nreturn\n \nwater\n\n\n\n\n\nThere is straightforward way to calculate all pairs in $O(n^2)$, just like bubble-sort.\n\n\nHowever, we can do this in $O(n)$ by compare the capacity contained from the leftest and rightest lines, and \nsqueeze\n them.\n\n\n12. Integer to Roman \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nintToRoman\n(\nself\n,\n \nnum\n):\n\n        \nM\n \n=\n \n[\n\"\"\n,\n \n\"M\"\n,\n \n\"MM\"\n,\n \n\"MMM\"\n]\n\n        \nC\n \n=\n \n[\n\"\"\n,\n \n\"C\"\n,\n \n\"CC\"\n,\n \n\"CCC\"\n,\n \n\"CD\"\n,\n \n\"D\"\n,\n \n\"DC\"\n,\n \n\"DCC\"\n,\n \n\"DCCC\"\n,\n \n\"CM\"\n]\n\n        \nX\n \n=\n \n[\n\"\"\n,\n \n\"X\"\n,\n \n\"XX\"\n,\n \n\"XXX\"\n,\n \n\"XL\"\n,\n \n\"L\"\n,\n \n\"LX\"\n,\n \n\"LXX\"\n,\n \n\"LXXX\"\n,\n \n\"XC\"\n]\n\n        \nI\n \n=\n \n[\n\"\"\n,\n \n\"I\"\n,\n \n\"II\"\n,\n \n\"III\"\n,\n \n\"IV\"\n,\n \n\"V\"\n,\n \n\"VI\"\n,\n \n\"VII\"\n,\n \n\"VIII\"\n,\n \n\"IX\"\n]\n\n        \nreturn\n \nM\n[\nnum\n \n/\n \n1000\n]\n \n+\n \nC\n[\nnum\n \n%\n \n1000\n \n/\n \n100\n]\n \n+\n \nX\n[\nnum\n \n%\n \n100\n \n/\n \n10\n]\n \n+\n \nI\n[\nnum\n \n%\n \n10\n]\n\n\n\n\n\nThis is very easy.\n\n\n13. Roman to Integer \n$\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nromanToInt\n(\nself\n,\n \ns\n):\n\n        \nroman\n \n=\n \n{\n'I'\n:\n \n1\n,\n \n'V'\n:\n \n5\n,\n \n'X'\n:\n \n10\n,\n \n'L'\n:\n \n50\n,\n \n'C'\n:\n \n100\n,\n \n'D'\n:\n \n500\n,\n \n'M'\n:\n \n1000\n}\n\n        \nret\n \n=\n \n0\n\n        \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\ns\n)\n \n-\n \n1\n):\n\n            \nif\n \nroman\n[\ns\n[\ni\n]]\n \n<\n \nroman\n[\ns\n[\ni\n \n+\n \n1\n]]:\n\n                \nret\n \n-=\n \nroman\n[\ns\n[\ni\n]]\n\n            \nelse\n:\n\n                \nret\n \n+=\n \nroman\n[\ns\n[\ni\n]]\n\n        \nreturn\n \nret\n \n+\n \nroman\n[\ns\n[\n-\n1\n]]\n       \n# remember to add the last element\n\n\n\n\n\nThis is easy, too.\n\n\n14. Longest Common Prefix \n$\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nlongestCommonPrefix\n(\nself\n,\n \nstrs\n):\n\n        \ndef\n \nLCP\n(\ns\n,\n \nt\n):\n\n            \nif\n \nlen\n(\ns\n)\n \n>\n \nlen\n(\nt\n):\n         \n                \ns\n,\n \nt\n \n=\n \nt\n,\n \ns\n             \n            \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\ns\n)):\n     \n# enumerate the shorter string\n\n                \nif\n \ns\n[\ni\n]\n \n!=\n \nt\n[\ni\n]:\n        \n# if ecounter a character that is different\n\n                    \nreturn\n \ns\n[:\ni\n]\n        \n# return the previous string\n\n            \nreturn\n \ns\n                    \n        \nreturn\n \nreduce\n(\nLCP\n,\n \nstrs\n)\n \nif\n \nstrs\n \nelse\n \n\"\"\n\n\n\n\n\nMake good use of reduce()!\n\n\n15. 3Sum \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nthreeSum\n(\nself\n,\n \nnums\n):\n\n        \nnums\n.\nsort\n()\n\n        \nres\n \n=\n \n[]\n\n        \nfor\n \ni\n \nin\n \nrange\n \n(\nlen\n(\nnums\n)\n \n-\n \n2\n):\n\n            \nif\n \ni\n \n==\n \n0\n \nor\n \ni\n \n>\n \n0\n \nand\n \nnums\n[\ni\n]\n \n!=\n \nnums\n[\ni\n \n-\n \n1\n]:\n\n                \nl\n,\n \nr\n,\n \ntarget\n \n=\n \ni\n \n+\n \n1\n,\n \nlen\n(\nnums\n)\n \n-\n \n1\n,\n \n0\n \n-\n \nnums\n[\ni\n]\n\n                \nwhile\n \nl\n \n<\n \nr\n:\n\n                    \nif\n \nnums\n[\nl\n]\n \n+\n \nnums\n[\nr\n]\n \n==\n \ntarget\n:\n      \n# same as 1. TwoSum\n\n                        \nres\n.\nappend\n((\nnums\n[\ni\n],\n \nnums\n[\nl\n],\n \nnums\n[\nr\n]))\n\n                        \nwhile\n \nl\n \n<\n \nr\n \nand\n \nnums\n[\nl\n]\n \n==\n \nnums\n[\nl\n \n+\n \n1\n]:\n     \n# avoid duplicate solutions\n\n                            \nl\n \n+=\n \n1\n\n                        \nwhile\n \nl\n \n<\n \nr\n \nand\n \nnums\n[\nr\n]\n \n==\n \nnums\n[\nr\n \n-\n \n1\n]:\n     \n# avoid duplicate solutions\n\n                            \nr\n \n-=\n \n1\n\n                        \nl\n \n+=\n \n1\n\n                        \nr\n \n-=\n \n1\n\n                    \nelif\n \nnums\n[\nl\n]\n \n+\n \nnums\n[\nr\n]\n \n<\n \ntarget\n:\n\n                        \nl\n \n+=\n \n1\n\n                    \nelse\n:\n\n                        \nr\n \n-=\n \n1\n\n        \nreturn\n \nres\n\n\n\n\n\nWe sort the array in increasing order, then this problem can be reduced to \n1. Two Sum\n but a little different by scanning each element in the array and letting\n\n\n\\begin{equation}\ntarget = 0 - nums[i].\n\\end{equation}\n\n\nSince we have already sorted the array, the procedure can be accelerated to linear time and the total running time is $O(n\\lg n) + O(n^2)$.\n\n\n16. 3Sum Closest \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nthreeSumClosest\n(\nself\n,\n \nnums\n,\n \ntarget\n):\n\n        \nnums\n.\nsort\n()\n\n        \nret\n \n=\n \nnums\n[\n0\n]\n \n+\n \nnums\n[\n1\n]\n \n+\n \nnums\n[\n2\n]\n           \n# initialize the return value\n\n        \nfor\n \ni\n \nin\n \nrange\n \n(\nlen\n(\nnums\n)\n \n-\n \n2\n):\n\n            \nl\n,\n \nr\n \n=\n \ni\n \n+\n \n1\n,\n \nlen\n(\nnums\n)\n \n-\n \n1\n             \n# this is like 3Sum\n\n            \nwhile\n \nl\n \n<\n \nr\n:\n            \n                \nsum\n \n=\n \nnums\n[\ni\n]\n \n+\n \nnums\n[\nl\n]\n \n+\n \nnums\n[\nr\n]\n\n                \nif\n \nsum\n \n==\n \ntarget\n:\n\n                    \nreturn\n \nsum\n\n                \nif\n \nabs\n(\nsum\n \n-\n \ntarget\n)\n \n<\n \nabs\n(\nret\n \n-\n \ntarget\n):\n         \n# keep the value of ret\n\n                    \nret\n \n=\n \nsum\n\n                \nif\n \nsum\n \n<\n \ntarget\n:\n\n                    \nl\n \n+=\n \n1\n\n                \nelif\n \nsum\n \n>\n \ntarget\n:\n\n                    \nr\n \n-=\n \n1\n\n        \nreturn\n \nret\n\n\n\n\n\nThis is very similar to \n15. 3Sum\n.\n\n\n17. Letter Combinations of a Phone Number \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nletterCombinations\n(\nself\n,\n \ndigits\n):\n\n        \nif\n \ndigits\n \n==\n \n''\n:\n \n            \nreturn\n \n[]\n\n        \nmap\n \n=\n \n{\n'2'\n:\n \n'abc'\n,\n \n'3'\n:\n \n'def'\n,\n \n'4'\n:\n \n'ghi'\n,\n \n'5'\n:\n \n'jkl'\n,\n \n'6'\n:\n \n'mno'\n,\n \n'7'\n:\n \n'pqrs'\n,\n \n'8'\n:\n \n'tuv'\n,\n \n'9'\n:\n \n'wxyz'\n}\n\n        \nret\n \n=\n \n[\n''\n]\n                      \n# initialize the return list\n\n        \nfor\n \ni\n \nin\n \ndigits\n:\n                \n# for each number in the digits\n\n            \ntmp\n \n=\n \n[]\n            \n            \nfor\n \nj\n \nin\n \nret\n:\n               \n# for each element \"already\" in the list\n\n                \nfor\n \nk\n \nin\n \nmap\n[\ni\n]:\n        \n# for each element in map[i]\n\n                    \ntmp\n.\nappend\n(\nj\n \n+\n \nk\n)\n\n            \nret\n \n=\n \ntmp\n                   \n# replace the ret with tmp \n\n        \nreturn\n \nret\n\n\n\n\n\nThis is a straightforward solution, but the run time is not fast.\n\n\nWe append the number to the elements that is \"already\" in the return list, then refresh the return list with variable $tmp$.\n\n\n18. 4Sum \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nfourSum\n(\nself\n,\n \nnums\n,\n \ntarget\n):\n\n        \ndef\n \nfindNsum\n(\nnums\n,\n \ntarget\n,\n \nN\n,\n \ntmp\n,\n \nret\n):\n\n            \nif\n \nlen\n(\nnums\n)\n \n<\n \nN\n \nor\n \nN\n \n<\n \n2\n \nor\n \ntarget\n \n<\n \nnums\n[\n0\n]\n \n*\n \nN\n \nor\n \ntarget\n \n>\n \nnums\n[\n-\n1\n]\n \n*\n \nN\n:\n\n                \nreturn\n\n            \nif\n \nN\n \n==\n \n2\n:\n\n                \nl\n,\n \nr\n \n=\n \n0\n,\n \nlen\n(\nnums\n)\n \n-\n \n1\n\n                \nwhile\n \nl\n \n<\n \nr\n:\n\n                    \nif\n \nnums\n[\nl\n]\n \n+\n \nnums\n[\nr\n]\n \n==\n \ntarget\n:\n\n                        \nret\n.\nappend\n(\ntmp\n \n+\n \n[\nnums\n[\nl\n],\n \nnums\n[\nr\n]])\n\n                        \nl\n \n+=\n \n1\n\n                        \nwhile\n \nl\n \n<\n \nr\n \nand\n \nnums\n[\nl\n]\n \n==\n \nnums\n[\nl\n \n-\n \n1\n]:\n\n                            \nl\n \n+=\n \n1\n\n                    \nelif\n \nnums\n[\nl\n]\n \n+\n \nnums\n[\nr\n]\n \n<\n \ntarget\n:\n\n                        \nl\n \n+=\n \n1\n\n                    \nelse\n:\n\n                        \nr\n \n-=\n \n1\n\n            \nelse\n:\n\n                \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\nnums\n)\n \n-\n \nN\n \n+\n \n1\n):\n\n                    \nif\n \ni\n \n==\n \n0\n \nor\n \ni\n \n>\n \n0\n \nand\n \nnums\n[\ni\n \n-\n \n1\n]\n \n!=\n \nnums\n[\ni\n]:\n\n                        \nfindNsum\n(\nnums\n[\ni\n \n+\n \n1\n:],\n \ntarget\n \n-\n \nnums\n[\ni\n],\n \nN\n \n-\n \n1\n,\n \ntmp\n \n+\n \n[\nnums\n[\ni\n]],\n \nret\n)\n\n        \nret\n \n=\n \n[]\n\n        \nfindNsum\n(\nsorted\n(\nnums\n),\n \ntarget\n,\n \n4\n,\n \n[],\n \nret\n)\n\n        \nreturn\n \nret\n\n\n\n\n\nThis problem let us to think about a general solution of \nN sum\n, we can recusively reduce the N sum to 2 sum.\n\n\nThe complexity of N sum in general is $O(n^{N - 1})$.\n\n\nSo the problem of 4 sum is $O(n^{4 - 1}) = O(n^3)$.\n\n\n19. Remove Nth Node From End of List \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nremoveNthFromEnd\n(\nself\n,\n \nhead\n,\n \nn\n):\n    \n# x is the number of ListNode\n\n        \nfast\n \n=\n \nslow\n \n=\n \nhead\n                  \n# initialize\n\n        \nfor\n \n_\n \nin\n \nrange\n(\nn\n):\n\n            \nfast\n \n=\n \nfast\n.\nnext\n                \n# fast's final position = 1 + n\n\n        \nif\n \nnot\n \nfast\n:\n                        \n# n >= x\n\n            \nreturn\n \nhead\n.\nnext\n                \n        \nwhile\n \nfast\n.\nnext\n:\n                    \n# [x - (1 + n)]'s iterations\n\n            \nfast\n \n=\n \nfast\n.\nnext\n                \n# until None\n\n            \nslow\n \n=\n \nslow\n.\nnext\n                \n# slow's final position = 1 + [x - (1 + n)] = x - n\n\n        \nslow\n.\nnext\n \n=\n \nslow\n.\nnext\n.\nnext\n          \n# skip the position = x - n + 1\n\n        \nreturn\n \nhead\n\n\n\n\n\nThe approach is to carefully count on the index.\n\n\nAssume there are $x = 7$ nodes in the ListNode and $n = 2$, we first assign tow variables $fast$ and $slow$ which are both equal to $head$.\n\n\nWe then iterate the index on $fast$.\n\n\nAfter the first for-loop,\n\n\n\\begin{equation}\nfast = 1 + n = 3.\n\\end{equation}\n\n\nIf $n = x$, then return $head.next$ since we remove the $head$.\n\n\nAfter the while-loop,\n\n\n\n\\begin{align}\nfast & = \\text{None} \\\\\nslow & = x - n = 5.\n\\end{align}\n\n\n\n\nThen we skip $x - n + 1 = 6$ (the desired removed node).\n\n\nFinally, the ListNode is \n1->2->3->4->5->7\n.\n\n\n20. Valid Parentheses \n$\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n\n    \ndef\n \nisValid\n(\nself\n,\n \ns\n):\n\n        \nstack\n \n=\n \n[]\n\n        \ndict\n \n=\n \n{\n\")\"\n:\n \n\"(\"\n,\n \n\"]\"\n:\n \n\"[\"\n,\n \n\"}\"\n:\n \n\"{\"\n}\n\n        \nfor\n \nchar\n \nin\n \ns\n:\n\n            \nif\n \nchar\n \nin\n \ndict\n.\nvalues\n():\n\n                \nstack\n.\nappend\n(\nchar\n)\n\n            \nelif\n \nchar\n \nin\n \ndict\n.\nkeys\n():\n\n                \nif\n \nstack\n \n==\n \n[]\n \nor\n \ndict\n[\nchar\n]\n \n!=\n \nstack\n.\npop\n():\n\n                    \nreturn\n \nFalse\n\n            \nelse\n:\n\n                \nreturn\n \nFalse\n\n        \nreturn\n \nstack\n \n==\n \n[]",
            "title": "011-020"
        },
        {
            "location": "/LeetCode/001-100/011-020/#11-container-with-most-water-starstar",
            "text": "class   Solution ( object ): \n     def   maxArea ( self ,   height ): \n         water   =   0 \n         l ,   r   =   0 ,   len ( height )   -   1 \n         while   l   <   r : \n             h   =   min ( height [ l ],   height [ r ]) \n             water   =   max ( water ,   ( r   -   l )   *   h ) \n             while   height [ l ]   <=   h   and   l   <   r : \n                 l   +=   1 \n             while   height [ r ]   <=   h   and   l   <   r : \n                 r   -=   1 \n         return   water   There is straightforward way to calculate all pairs in $O(n^2)$, just like bubble-sort.  However, we can do this in $O(n)$ by compare the capacity contained from the leftest and rightest lines, and  squeeze  them.",
            "title": "11. Container With Most Water $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/011-020/#12-integer-to-roman-starstar",
            "text": "class   Solution ( object ): \n     def   intToRoman ( self ,   num ): \n         M   =   [ \"\" ,   \"M\" ,   \"MM\" ,   \"MMM\" ] \n         C   =   [ \"\" ,   \"C\" ,   \"CC\" ,   \"CCC\" ,   \"CD\" ,   \"D\" ,   \"DC\" ,   \"DCC\" ,   \"DCCC\" ,   \"CM\" ] \n         X   =   [ \"\" ,   \"X\" ,   \"XX\" ,   \"XXX\" ,   \"XL\" ,   \"L\" ,   \"LX\" ,   \"LXX\" ,   \"LXXX\" ,   \"XC\" ] \n         I   =   [ \"\" ,   \"I\" ,   \"II\" ,   \"III\" ,   \"IV\" ,   \"V\" ,   \"VI\" ,   \"VII\" ,   \"VIII\" ,   \"IX\" ] \n         return   M [ num   /   1000 ]   +   C [ num   %   1000   /   100 ]   +   X [ num   %   100   /   10 ]   +   I [ num   %   10 ]   This is very easy.",
            "title": "12. Integer to Roman $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/011-020/#13-roman-to-integer-star",
            "text": "class   Solution ( object ): \n     def   romanToInt ( self ,   s ): \n         roman   =   { 'I' :   1 ,   'V' :   5 ,   'X' :   10 ,   'L' :   50 ,   'C' :   100 ,   'D' :   500 ,   'M' :   1000 } \n         ret   =   0 \n         for   i   in   range ( len ( s )   -   1 ): \n             if   roman [ s [ i ]]   <   roman [ s [ i   +   1 ]]: \n                 ret   -=   roman [ s [ i ]] \n             else : \n                 ret   +=   roman [ s [ i ]] \n         return   ret   +   roman [ s [ - 1 ]]         # remember to add the last element   This is easy, too.",
            "title": "13. Roman to Integer $\\star$"
        },
        {
            "location": "/LeetCode/001-100/011-020/#14-longest-common-prefix-star",
            "text": "class   Solution ( object ): \n     def   longestCommonPrefix ( self ,   strs ): \n         def   LCP ( s ,   t ): \n             if   len ( s )   >   len ( t ):          \n                 s ,   t   =   t ,   s              \n             for   i   in   range ( len ( s )):       # enumerate the shorter string \n                 if   s [ i ]   !=   t [ i ]:          # if ecounter a character that is different \n                     return   s [: i ]          # return the previous string \n             return   s                     \n         return   reduce ( LCP ,   strs )   if   strs   else   \"\"   Make good use of reduce()!",
            "title": "14. Longest Common Prefix $\\star$"
        },
        {
            "location": "/LeetCode/001-100/011-020/#15-3sum-starstar",
            "text": "class   Solution ( object ): \n     def   threeSum ( self ,   nums ): \n         nums . sort () \n         res   =   [] \n         for   i   in   range   ( len ( nums )   -   2 ): \n             if   i   ==   0   or   i   >   0   and   nums [ i ]   !=   nums [ i   -   1 ]: \n                 l ,   r ,   target   =   i   +   1 ,   len ( nums )   -   1 ,   0   -   nums [ i ] \n                 while   l   <   r : \n                     if   nums [ l ]   +   nums [ r ]   ==   target :        # same as 1. TwoSum \n                         res . append (( nums [ i ],   nums [ l ],   nums [ r ])) \n                         while   l   <   r   and   nums [ l ]   ==   nums [ l   +   1 ]:       # avoid duplicate solutions \n                             l   +=   1 \n                         while   l   <   r   and   nums [ r ]   ==   nums [ r   -   1 ]:       # avoid duplicate solutions \n                             r   -=   1 \n                         l   +=   1 \n                         r   -=   1 \n                     elif   nums [ l ]   +   nums [ r ]   <   target : \n                         l   +=   1 \n                     else : \n                         r   -=   1 \n         return   res   We sort the array in increasing order, then this problem can be reduced to  1. Two Sum  but a little different by scanning each element in the array and letting  \\begin{equation}\ntarget = 0 - nums[i].\n\\end{equation}  Since we have already sorted the array, the procedure can be accelerated to linear time and the total running time is $O(n\\lg n) + O(n^2)$.",
            "title": "15. 3Sum $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/011-020/#16-3sum-closest-starstar",
            "text": "class   Solution ( object ): \n     def   threeSumClosest ( self ,   nums ,   target ): \n         nums . sort () \n         ret   =   nums [ 0 ]   +   nums [ 1 ]   +   nums [ 2 ]             # initialize the return value \n         for   i   in   range   ( len ( nums )   -   2 ): \n             l ,   r   =   i   +   1 ,   len ( nums )   -   1               # this is like 3Sum \n             while   l   <   r :             \n                 sum   =   nums [ i ]   +   nums [ l ]   +   nums [ r ] \n                 if   sum   ==   target : \n                     return   sum \n                 if   abs ( sum   -   target )   <   abs ( ret   -   target ):           # keep the value of ret \n                     ret   =   sum \n                 if   sum   <   target : \n                     l   +=   1 \n                 elif   sum   >   target : \n                     r   -=   1 \n         return   ret   This is very similar to  15. 3Sum .",
            "title": "16. 3Sum Closest $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/011-020/#17-letter-combinations-of-a-phone-number-starstar",
            "text": "class   Solution ( object ): \n     def   letterCombinations ( self ,   digits ): \n         if   digits   ==   '' :  \n             return   [] \n         map   =   { '2' :   'abc' ,   '3' :   'def' ,   '4' :   'ghi' ,   '5' :   'jkl' ,   '6' :   'mno' ,   '7' :   'pqrs' ,   '8' :   'tuv' ,   '9' :   'wxyz' } \n         ret   =   [ '' ]                        # initialize the return list \n         for   i   in   digits :                  # for each number in the digits \n             tmp   =   []             \n             for   j   in   ret :                 # for each element \"already\" in the list \n                 for   k   in   map [ i ]:          # for each element in map[i] \n                     tmp . append ( j   +   k ) \n             ret   =   tmp                     # replace the ret with tmp  \n         return   ret   This is a straightforward solution, but the run time is not fast.  We append the number to the elements that is \"already\" in the return list, then refresh the return list with variable $tmp$.",
            "title": "17. Letter Combinations of a Phone Number $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/011-020/#18-4sum-starstar",
            "text": "class   Solution ( object ): \n     def   fourSum ( self ,   nums ,   target ): \n         def   findNsum ( nums ,   target ,   N ,   tmp ,   ret ): \n             if   len ( nums )   <   N   or   N   <   2   or   target   <   nums [ 0 ]   *   N   or   target   >   nums [ - 1 ]   *   N : \n                 return \n             if   N   ==   2 : \n                 l ,   r   =   0 ,   len ( nums )   -   1 \n                 while   l   <   r : \n                     if   nums [ l ]   +   nums [ r ]   ==   target : \n                         ret . append ( tmp   +   [ nums [ l ],   nums [ r ]]) \n                         l   +=   1 \n                         while   l   <   r   and   nums [ l ]   ==   nums [ l   -   1 ]: \n                             l   +=   1 \n                     elif   nums [ l ]   +   nums [ r ]   <   target : \n                         l   +=   1 \n                     else : \n                         r   -=   1 \n             else : \n                 for   i   in   range ( len ( nums )   -   N   +   1 ): \n                     if   i   ==   0   or   i   >   0   and   nums [ i   -   1 ]   !=   nums [ i ]: \n                         findNsum ( nums [ i   +   1 :],   target   -   nums [ i ],   N   -   1 ,   tmp   +   [ nums [ i ]],   ret ) \n         ret   =   [] \n         findNsum ( sorted ( nums ),   target ,   4 ,   [],   ret ) \n         return   ret   This problem let us to think about a general solution of  N sum , we can recusively reduce the N sum to 2 sum.  The complexity of N sum in general is $O(n^{N - 1})$.  So the problem of 4 sum is $O(n^{4 - 1}) = O(n^3)$.",
            "title": "18. 4Sum $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/011-020/#19-remove-nth-node-from-end-of-list-starstar",
            "text": "class   Solution ( object ): \n     def   removeNthFromEnd ( self ,   head ,   n ):      # x is the number of ListNode \n         fast   =   slow   =   head                    # initialize \n         for   _   in   range ( n ): \n             fast   =   fast . next                  # fast's final position = 1 + n \n         if   not   fast :                          # n >= x \n             return   head . next                 \n         while   fast . next :                      # [x - (1 + n)]'s iterations \n             fast   =   fast . next                  # until None \n             slow   =   slow . next                  # slow's final position = 1 + [x - (1 + n)] = x - n \n         slow . next   =   slow . next . next            # skip the position = x - n + 1 \n         return   head   The approach is to carefully count on the index.  Assume there are $x = 7$ nodes in the ListNode and $n = 2$, we first assign tow variables $fast$ and $slow$ which are both equal to $head$.  We then iterate the index on $fast$.  After the first for-loop,  \\begin{equation}\nfast = 1 + n = 3.\n\\end{equation}  If $n = x$, then return $head.next$ since we remove the $head$.  After the while-loop,  \n\\begin{align}\nfast & = \\text{None} \\\\\nslow & = x - n = 5.\n\\end{align}  Then we skip $x - n + 1 = 6$ (the desired removed node).  Finally, the ListNode is  1->2->3->4->5->7 .",
            "title": "19. Remove Nth Node From End of List $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/011-020/#20-valid-parentheses-star",
            "text": "class   Solution ( object ): \n     def   isValid ( self ,   s ): \n         stack   =   [] \n         dict   =   { \")\" :   \"(\" ,   \"]\" :   \"[\" ,   \"}\" :   \"{\" } \n         for   char   in   s : \n             if   char   in   dict . values (): \n                 stack . append ( char ) \n             elif   char   in   dict . keys (): \n                 if   stack   ==   []   or   dict [ char ]   !=   stack . pop (): \n                     return   False \n             else : \n                 return   False \n         return   stack   ==   []",
            "title": "20. Valid Parentheses $\\star$"
        },
        {
            "location": "/LeetCode/001-100/021-030/",
            "text": "21. Merge Two Sorted Lists \n$\\star$\n\u00b6\n\n\nclass\n \nSolution\n(\nobject\n):\n       \n    \ndef\n \nmergeTwoLists\n(\nself\n,\n \nl1\n,\n \nl2\n):\n\n        \nif\n \nl1\n \nand\n \nl2\n:\n\n            \nif\n \nl1\n.\nval\n \n>\n \nl2\n.\nval\n:\n\n                \nl1\n,\n \nl2\n \n=\n \nl2\n,\n \nl1\n\n            \nl1\n.\nnext\n \n=\n \nself\n.\nmergeTwoLists\n(\nl1\n.\nnext\n,\n \nl2\n)\n\n        \nreturn\n \nl1\n \nor\n \nl2\n\n\n\n\n\nBasic solution is too easy. We can try in a recursive way.\n\n\nWe write the code in a recursive manner, but indeed iteratively append the element.\n\n\n22. Generate Parentheses \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \ngenerateParenthesis\n(\nself\n,\n \nn\n):\n\n        \nstr\n \n=\n \n''\n\n        \nparens\n \n=\n \n[]\n\n        \nreturn\n \nself\n.\nstrGen\n(\nstr\n,\n \nn\n,\n \nn\n,\n \nparens\n)\n\n    \ndef\n \nstrGen\n(\nself\n,\n \nstr\n,\n \nl\n,\n \nr\n,\n \nparens\n):\n\n        \nif\n \nl\n \n==\n \n0\n \nand\n \nr\n \n==\n \n0\n:\n\n            \nparens\n.\nappend\n(\nstr\n)\n\n        \nif\n \nl\n \n>=\n \n1\n:\n\n            \nself\n.\nstrGen\n(\nstr\n \n+\n \n'('\n,\n \nl\n \n-\n \n1\n,\n \nr\n,\n \nparens\n)\n\n        \nif\n \nr\n \n>\n \nl\n:\n\n            \nself\n.\nstrGen\n(\nstr\n \n+\n \n')'\n,\n \nl\n,\n \nr\n \n-\n \n1\n,\n \nparens\n)\n\n        \nreturn\n \nparens\n\n\n\n\n\nWe define a new function $strGen$, and recursively call \nstrGen(str + '(', l - 1, r)\n and \nstrGen(str + ')', l, r - 1\n. \n\n\nIf $l = 0$ and $r = 0$, i.e., all left and right parentheses are depleted, then append the $str$ to list $parens$.\n\n\nRemember to clear $parens$ every time!\n\n\n23. Merge k Sorted Lists \n$\\star\\star\\star$\n\u00b6\n\n\n\n\nThe $ListNode$ structure is as follow:\n\n\n\n\nclass\n \nListNode\n:\n\n    \ndef\n \n__init__\n(\nself\n,\n \nx\n):\n\n        \nself\n.\nval\n \n=\n \nx\n\n        \nself\n.\nnext\n \n=\n \nNone\n\n\n\n\n\nfrom\n \nheapq\n \nimport\n \nheappush\n,\n \nheappop\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nmergeKLists\n(\nself\n,\n \nlists\n):\n\n        \nhead\n \n=\n \ncurr\n \n=\n \nListNode\n(\n0\n)\n   \n# a dummy with value 0\n\n        \nheap\n \n=\n \n[]\n                   \n# an empty heap\n\n        \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\nlists\n)):\n\n            \nif\n \nlists\n[\ni\n]:\n\n                \nheappush\n(\nheap\n,\n \n(\nlists\n[\ni\n]\n.\nval\n,\n \ni\n,\n \nlists\n[\ni\n]))\n\n        \nwhile\n \nheap\n:\n\n            \nnode\n \n=\n \nheappop\n(\nheap\n)\n\n            \nidx\n \n=\n \nnode\n[\n1\n]\n\n            \ncurr\n.\nnext\n \n=\n \nnode\n[\n2\n]\n     \n# trace the value\n\n            \ncurr\n \n=\n \ncurr\n.\nnext\n\n            \nif\n \ncurr\n.\nnext\n:\n\n                \nheappush\n(\nheap\n,\n \n(\ncurr\n.\nnext\n.\nval\n,\n \nidx\n,\n \ncurr\n.\nnext\n))\n\n        \nreturn\n \nhead\n.\nnext\n\n\n\n\n\nWe use \nheapq\n to solve the problem.\n\n\nFirst, we declare a variable $head = ListNode(0)$, a dummy to hold the first value, and initailize an empyt list $heap = []$.\n\n\nThen we $\\text{heappush}$ every \nheads\n' value of $lists$ and $lists$ itself to $heap$.\n\n\nWhile $heap$ is not empty, we $\\text{heappop}$ a node and assign following variables:\n\n\n\n\n$idx = node[1]$: to keep which list in $lists$.\n\n\n$curr.next = node[2]$: to trace the value linked with head.\n\n\n$curr = curr.next$: to move $curr$ forward.\n\n\n\n\nIf $curr.next$ is not $None$, we again $\\text{heappush}$ $curr.next$ to $heap$.\n\n\nWe can test the problem with following codes:\n\n\ndef\n \nprintList\n(\nans\n):\n\n    \ncurr\n \n=\n \nans\n\n    \nwhile\n \ncurr\n \nis\n \nnot\n \nNone\n:\n\n        \nprint\n(\ncurr\n.\nval\n)\n\n        \ncurr\n \n=\n \ncurr\n.\nnext\n\n\n\nif\n \n__name__\n \n==\n \n\"__main__\"\n:\n\n    \nl1\n \n=\n \nListNode\n(\n1\n)\n\n    \nl1\n.\nnext\n \n=\n \nListNode\n(\n1\n)\n\n    \nl1\n.\nnext\n.\nnext\n \n=\n \nListNode\n(\n2\n)\n\n\n    \nl2\n \n=\n \nListNode\n(\n1\n)\n\n    \nl2\n.\nnext\n \n=\n \nListNode\n(\n2\n)\n\n    \nl2\n.\nnext\n.\nnext\n \n=\n \nListNode\n(\n5\n)\n\n\n    \nl3\n \n=\n \nListNode\n(\n2\n)\n\n    \nl3\n.\nnext\n \n=\n \nListNode\n(\n3\n)\n\n    \nl3\n.\nnext\n.\nnext\n \n=\n \nListNode\n(\n6\n)\n\n\n    \nl\n \n=\n \n[\nl1\n,\n \nl2\n,\n \nl3\n]\n\n\n    \nsol\n \n=\n \nSolution\n()\n\n    \nans\n \n=\n \nsol\n.\nmergeKLists\n(\nl\n)\n\n\n    \nprinter\n(\nans\n)\n\n\n\n\n\n24. Swap Nodes in Pairs \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nswapPairs\n(\nself\n,\n \nhead\n):\n\n        \nprev\n,\n \nprev\n.\nnext\n \n=\n \nself\n,\n \nhead\n\n        \nwhile\n \nprev\n.\nnext\n \nand\n \nprev\n.\nnext\n.\nnext\n:\n\n            \na\n \n=\n \nprev\n.\nnext\n\n            \nb\n \n=\n \na\n.\nnext\n\n            \nprev\n.\nnext\n,\n \nb\n.\nnext\n,\n \na\n.\nnext\n \n=\n \nb\n,\n \na\n,\n \nb\n.\nnext\n\n            \nprev\n \n=\n \na\n\n        \nreturn\n \nself\n.\nnext\n        \n\n\n\n\nWe keep:\n\n\n\n\n$prev$: the previous node \n\n\n$prev.next$: $head$\n\n\n$a$: current node\n\n\n$b$: current node's next\n\n\n\n\nBy above, we can easily change \nprev -> a -> b -> b.next\n to \nprev -> b -> a -> b.next\n.\n\n\n25. Reverse Nodes in k-Group \n$\\star\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nreverseKGroup\n(\nself\n,\n \nhead\n,\n \nk\n):\n\n        \nif\n \nhead\n \nis\n \nNone\n \nor\n \nk\n \n==\n \n1\n:\n\n            \nreturn\n \nhead\n\n        \nprevhead\n,\n \nprevhead\n.\nnext\n \n=\n \nself\n,\n \nhead\n\n        \ncurr\n \n=\n \nprev\n \n=\n \nprevhead\n\n        \nnext\n \n=\n \nListNode\n(\n0\n)\n\n        \nnum\n \n=\n \n0\n\n        \nwhile\n \ncurr\n.\nnext\n:\n        \n# Calculate how many nodes are in the list\n\n            \ncurr\n \n=\n \ncurr\n.\nnext\n\n            \nnum\n \n+=\n \n1\n\n        \nwhile\n \nnum\n \n>=\n \nk\n:\n\n            \ncurr\n \n=\n \nprev\n.\nnext\n\n            \nnext\n \n=\n \ncurr\n.\nnext\n\n            \nfor\n \ni\n \nin\n \nrange\n(\n1\n,\n \nk\n):\n\n                \ncurr\n.\nnext\n \n=\n \nnext\n.\nnext\n\n                \nnext\n.\nnext\n \n=\n \nprev\n.\nnext\n\n                \nprev\n.\nnext\n \n=\n \nnext\n\n                \nnext\n \n=\n \ncurr\n.\nnext\n\n            \nprev\n \n=\n \ncurr\n\n            \nnum\n \n-=\n \nk\n\n        \nreturn\n \nprevhead\n.\nnext\n\n\n\n\n\nThe problem is a little bit complicate. It works like an \nexcavator's wheel\n.\n\n\nFor example, given the list: \n1(head) -> 2 -> 3 -> 4 -> 5 -> 6 -> 7\n.\n\n\nWe look more carefully inside the codes:\n\n\nif $head$ is $None$ or $k == 1$, we simply return $head$.\n\n\nWe declare the value $prevhead = self$ as the object itself, and set the attribute $prevhead.next = head$ to \npoint\n to the first node(i.e., $1$ in the list):\n\n\nprevhead -> 1(head) -> 2 -> 3 -> 4 -> 5 -> 6 -> 7\n.\n\n\nAnd we keep two variable $curr$ and $prev$, both equal to $prevhead$ in the beginning:\n\n\nprevhead/curr/prev -> 1(head) -> 2 -> 3 -> 4 -> 5 -> 6 -> 7\n.\n\n\n\n\nIn the first while loop: we linearly scan the list to count the $num$ of nodes in the list.\n\n\nIn the second while loop:\n\n\n\n\n    \nwhile\n \nnum\n \n>=\n \nk\n:\n\n        \ncurr\n \n=\n \nprev\n.\nnext\n\n        \nnext\n \n=\n \ncurr\n.\nnext\n\n\n\n\n\nWe set $curr = prev.next$(i.e., $1$) and $next = curr.next$(i.e., $2$) as the begin vaue of the $k$ Group(using $k = 3$ to explain the core idea).\n\n\nprevhead/prev -> 1(curr) -> 2(next) -> 3 -> 4 -> 5 -> 6 -> 7\n.\n\n\n    \nfor\n \ni\n \nin\n \nrange\n(\n1\n,\n \nk\n):\n\n        \ncurr\n.\nnext\n \n=\n \nnext\n.\nnext\n\n        \nnext\n.\nnext\n \n=\n \nprev\n.\nnext\n\n        \nprev\n.\nnext\n \n=\n \nnext\n\n        \nnext\n \n=\n \ncurr\n.\nnext\n\n\n\n\n\n\n\n$k = 1$\n\n\n$curr.next = next.next$: \n1(curr) -> 3\n\n\n$next.next = prev.next$: \n2(next) -> 1\n\n\n$prev.next = next$: \nprev -> 2\n\n\n$next = curr.next$: \nnext = 3\n\n\n\n\n\n\n\n\nprevhead/prev -> 2 -> 1(curr) -> 3(next) -> 4 -> 5 -> 6 -> 7\n.\n\n\n\n\n$k = 2$\n\n\n$curr.next = next.next$: \n1(curr) -> 4\n\n\n$next.next = prev.next$: \n3(next) -> 2\n\n\n$prev.next = next$: \nprev -> 3\n\n\n$next = curr.next$: \nnext = 4\n\n\n\n\n\n\n\n\nprevhead/prev -> 3 -> 2 -> 1(curr) -> 4(next) -> 5 -> 6 -> 7\n.\n\n\nAfter doing the first for loop,\n\n\n    \nprev\n \n=\n \ncurr\n\n\n\n\n\n$prev = curr$ means that we now set $prev = 1(curr)$, the new pointer to do the following $k$ group.\n\n\nprevhead -> 3 -> 2 -> 1(curr/prev) -> 4(next) -> 5 -> 6 -> 7\n.\n\n\nYou can think following now:\n\n\nprevhead -> 3 -> 2 -> 1(prev) -> 4(curr) -> 5(next) -> 6 -> 7\n.\n\nprevhead -> 3 -> 2 -> 1(prev) -> 5 -> 4(curr) -> 6(next) -> 7\n.\n\nprevhead -> 3 -> 2 -> 1(prev) -> 6 -> 5 -> 4(curr) -> 7(next)\n.\n\n\nWe can test the problem with following codes:\n\n\ndef\n \nprinter\n(\na\n):\n\n    \ncurr\n \n=\n \na\n\n    \nwhile\n \ncurr\n \nis\n \nnot\n \nNone\n:\n\n        \nprint\n(\ncurr\n.\nval\n,\n \nend\n \n=\n \n' -> '\n,\n \nsep\n \n=\n \n''\n)\n\n        \ncurr\n \n=\n \ncurr\n.\nnext\n\n    \nprint\n(\n''\n)\n\n\n\n\n\ndef\n \ngenerateListNode\n(\nn\n):\n\n    \nprev\n \n=\n \ncurr\n \n=\n \nListNode\n(\n0\n)\n\n    \nfor\n \ni\n \nin\n \nrange\n(\n1\n,\n \nn\n):\n\n        \ncurr\n.\nnext\n \n=\n \nListNode\n(\ni\n)\n\n        \ncurr\n \n=\n \ncurr\n.\nnext\n\n    \nreturn\n \nprev\n.\nnext\n\n\n\n\n\nif\n \n__name__\n \n==\n \n\"__main__\"\n:\n\n    \nl\n \n=\n \ngenerateListNode\n(\n7\n)\n\n    \n# printer(l)\n\n\n    \nsol\n \n=\n \nSolution\n()\n\n    \na\n \n=\n \nsol\n.\nreverseKGroup\n(\nl\n,\n \n3\n)\n\n\n    \n# print('----------------')\n\n    \n# printer(a)\n\n\n\n\n\n26. Remove Duplicates from Sorted Array \n$\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nremoveDuplicates\n(\nself\n,\n \nnums\n):\n\n        \nif\n \nlen\n(\nnums\n)\n \n==\n \n0\n:\n      \n# return if the list is empty\n\n            \nreturn\n \n0\n\n        \nidx\n \n=\n \n0\n\n        \nwhile\n \nidx\n \n<\n \nlen\n(\nnums\n)\n \n-\n \n1\n:\n\n            \nif\n \nnums\n[\nidx\n]\n \n==\n \nnums\n[\nidx\n \n+\n \n1\n]:\n\n                \nnums\n.\nremove\n(\nnums\n[\nidx\n])\n\n            \nelse\n:\n\n                \nidx\n \n+=\n \n1\n\n        \nreturn\n \nlen\n(\nnums\n)\n\n\n\n\n\nThis is very easy. We simply remove duplicate nums iterably.\n\n\n27. Remove Element \n$\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nremoveElement\n(\nself\n,\n \nnums\n,\n \nval\n):\n\n        \ni\n \n=\n \n0\n\n        \nwhile\n \ni\n \n<\n \nlen\n(\nnums\n):\n\n            \nif\n \nnums\n[\ni\n]\n \n==\n \nval\n:\n\n                \nnums\n.\npop\n(\ni\n)\n     \n# pop the i-th element in nums\n\n            \nelse\n:\n\n                \ni\n \n+=\n \n1\n\n        \nreturn\n \ni\n\n\n\n\n\nIn order to solve this \nin-place\n, we cannot use $O(n)$ extra space. Therefore, we declare $i$ to keep \ncurrent\n index of $nums$.\n\n\nWe don't use \nremove()\n since it's time-comsuming. Instead, we use \npop()\n.\n\n\n28. Implement strStr() \n$\\star$\n\u00b6\n\n\nThis brute-force way is easy. And the time complexity is $O((n - m + 1)m)$.\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nstrStr\n(\nself\n,\n \nhaystack\n,\n \nneedle\n):\n\n        \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\nhaystack\n)\n \n-\n \nlen\n(\nneedle\n)\n \n+\n \n1\n):\n\n            \nif\n \nhaystack\n[\ni\n:\n \ni\n \n+\n \nlen\n(\nneedle\n)]\n \n==\n \nneedle\n:\n\n                \nreturn\n \ni\n\n        \nreturn\n \n-\n1\n\n\n\n\n\nWe challenge ourselves by using \nKMP\n. This can be done in $O(n + m)$. However, I don't know why KMP runs slower than the brute-force method in LeetCode. Maybe it just want us to do the brute-force in one star problem LoL.\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nstrStr\n(\nself\n,\n \nhaystack\n,\n \nneedle\n):\n\n        \nif\n \nneedle\n \n==\n \n\"\"\n:\n                    \n# Remember to check this first!\n\n            \nreturn\n \n0\n\n        \nreturn\n \nself\n.\nKMP\n(\nhaystack\n,\n \nneedle\n)\n\n\n    \ndef\n \nKMP\n(\nself\n,\n \nA\n,\n \nB\n):\n\n        \nlps\n \n=\n \nself\n.\ncomputeLPSArray\n(\nB\n)\n\n        \ni\n \n=\n \nj\n \n=\n \n0\n\n        \nwhile\n \ni\n \n<\n \nlen\n(\nA\n):\n\n            \nif\n \nA\n[\ni\n]\n \n==\n \nB\n[\nj\n]:\n\n                \ni\n \n+=\n \n1\n\n                \nj\n \n+=\n \n1\n\n            \nif\n \nj\n \n==\n \nlen\n(\nB\n):\n\n                \nreturn\n \ni\n \n-\n \nj\n\n                \nj\n \n=\n \nlps\n[\nj\n \n-\n \n1\n]\n              \n# This line won't execute, but we can still find all indices\n\n            \nelif\n \ni\n \n<\n \nlen\n(\nA\n)\n \nand\n \nA\n[\ni\n]\n \n!=\n \nB\n[\nj\n]:\n\n                \nif\n \nj\n \n!=\n \n0\n:\n\n                    \nj\n \n=\n \nlps\n[\nj\n \n-\n \n1\n]\n\n                \nelse\n:\n\n                    \ni\n \n+=\n \n1\n\n        \nreturn\n \n-\n1\n\n\n    \ndef\n \ncomputeLPSArray\n(\nself\n,\n \nB\n):\n\n        \nm\n \n=\n \nlen\n(\nB\n)\n\n        \nlps\n \n=\n \n[\n0\n]\n \n*\n \nm\n                       \n# Longest proper prefix which is also suffix\n\n        \nlps\n[\n0\n]\n \n=\n \n0\n\n        \nk\n \n=\n \n0\n                               \n# Current paired length\n\n        \nfor\n \ni\n \nin\n \nrange\n(\n1\n,\n \nm\n):\n\n            \nwhile\n \nk\n \n>\n \n0\n \nand\n \nB\n[\nk\n]\n \n!=\n \nB\n[\ni\n]:\n\n                \nk\n \n=\n \nlps\n[\nk\n \n-\n \n1\n]\n\n            \nif\n \nB\n[\nk\n]\n \n==\n \nB\n[\ni\n]:\n\n                \nk\n \n+=\n \n1\n\n            \nlps\n[\ni\n]\n \n=\n \nk\n\n        \nreturn\n \nlps\n\n\n\n\n\n29. Divide Two Integers \n$\\star\\star$\n\u00b6\n\n\nBinary problem...\n\n\n30. Substring with Concatenation of All Words \n$\\star\\star\\star$\n\u00b6",
            "title": "021-030"
        },
        {
            "location": "/LeetCode/001-100/021-030/#21-merge-two-sorted-lists-star",
            "text": "class   Solution ( object ):        \n     def   mergeTwoLists ( self ,   l1 ,   l2 ): \n         if   l1   and   l2 : \n             if   l1 . val   >   l2 . val : \n                 l1 ,   l2   =   l2 ,   l1 \n             l1 . next   =   self . mergeTwoLists ( l1 . next ,   l2 ) \n         return   l1   or   l2   Basic solution is too easy. We can try in a recursive way.  We write the code in a recursive manner, but indeed iteratively append the element.",
            "title": "21. Merge Two Sorted Lists $\\star$"
        },
        {
            "location": "/LeetCode/001-100/021-030/#22-generate-parentheses-starstar",
            "text": "class   Solution : \n     def   generateParenthesis ( self ,   n ): \n         str   =   '' \n         parens   =   [] \n         return   self . strGen ( str ,   n ,   n ,   parens ) \n     def   strGen ( self ,   str ,   l ,   r ,   parens ): \n         if   l   ==   0   and   r   ==   0 : \n             parens . append ( str ) \n         if   l   >=   1 : \n             self . strGen ( str   +   '(' ,   l   -   1 ,   r ,   parens ) \n         if   r   >   l : \n             self . strGen ( str   +   ')' ,   l ,   r   -   1 ,   parens ) \n         return   parens   We define a new function $strGen$, and recursively call  strGen(str + '(', l - 1, r)  and  strGen(str + ')', l, r - 1 .   If $l = 0$ and $r = 0$, i.e., all left and right parentheses are depleted, then append the $str$ to list $parens$.  Remember to clear $parens$ every time!",
            "title": "22. Generate Parentheses $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/021-030/#23-merge-k-sorted-lists-starstarstar",
            "text": "The $ListNode$ structure is as follow:   class   ListNode : \n     def   __init__ ( self ,   x ): \n         self . val   =   x \n         self . next   =   None   from   heapq   import   heappush ,   heappop  class   Solution : \n     def   mergeKLists ( self ,   lists ): \n         head   =   curr   =   ListNode ( 0 )     # a dummy with value 0 \n         heap   =   []                     # an empty heap \n         for   i   in   range ( len ( lists )): \n             if   lists [ i ]: \n                 heappush ( heap ,   ( lists [ i ] . val ,   i ,   lists [ i ])) \n         while   heap : \n             node   =   heappop ( heap ) \n             idx   =   node [ 1 ] \n             curr . next   =   node [ 2 ]       # trace the value \n             curr   =   curr . next \n             if   curr . next : \n                 heappush ( heap ,   ( curr . next . val ,   idx ,   curr . next )) \n         return   head . next   We use  heapq  to solve the problem.  First, we declare a variable $head = ListNode(0)$, a dummy to hold the first value, and initailize an empyt list $heap = []$.  Then we $\\text{heappush}$ every  heads ' value of $lists$ and $lists$ itself to $heap$.  While $heap$ is not empty, we $\\text{heappop}$ a node and assign following variables:   $idx = node[1]$: to keep which list in $lists$.  $curr.next = node[2]$: to trace the value linked with head.  $curr = curr.next$: to move $curr$ forward.   If $curr.next$ is not $None$, we again $\\text{heappush}$ $curr.next$ to $heap$.  We can test the problem with following codes:  def   printList ( ans ): \n     curr   =   ans \n     while   curr   is   not   None : \n         print ( curr . val ) \n         curr   =   curr . next  if   __name__   ==   \"__main__\" : \n     l1   =   ListNode ( 1 ) \n     l1 . next   =   ListNode ( 1 ) \n     l1 . next . next   =   ListNode ( 2 ) \n\n     l2   =   ListNode ( 1 ) \n     l2 . next   =   ListNode ( 2 ) \n     l2 . next . next   =   ListNode ( 5 ) \n\n     l3   =   ListNode ( 2 ) \n     l3 . next   =   ListNode ( 3 ) \n     l3 . next . next   =   ListNode ( 6 ) \n\n     l   =   [ l1 ,   l2 ,   l3 ] \n\n     sol   =   Solution () \n     ans   =   sol . mergeKLists ( l ) \n\n     printer ( ans )",
            "title": "23. Merge k Sorted Lists $\\star\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/021-030/#24-swap-nodes-in-pairs-starstar",
            "text": "class   Solution : \n     def   swapPairs ( self ,   head ): \n         prev ,   prev . next   =   self ,   head \n         while   prev . next   and   prev . next . next : \n             a   =   prev . next \n             b   =   a . next \n             prev . next ,   b . next ,   a . next   =   b ,   a ,   b . next \n             prev   =   a \n         return   self . next           We keep:   $prev$: the previous node   $prev.next$: $head$  $a$: current node  $b$: current node's next   By above, we can easily change  prev -> a -> b -> b.next  to  prev -> b -> a -> b.next .",
            "title": "24. Swap Nodes in Pairs $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/021-030/#25-reverse-nodes-in-k-group-starstarstar",
            "text": "class   Solution : \n     def   reverseKGroup ( self ,   head ,   k ): \n         if   head   is   None   or   k   ==   1 : \n             return   head \n         prevhead ,   prevhead . next   =   self ,   head \n         curr   =   prev   =   prevhead \n         next   =   ListNode ( 0 ) \n         num   =   0 \n         while   curr . next :          # Calculate how many nodes are in the list \n             curr   =   curr . next \n             num   +=   1 \n         while   num   >=   k : \n             curr   =   prev . next \n             next   =   curr . next \n             for   i   in   range ( 1 ,   k ): \n                 curr . next   =   next . next \n                 next . next   =   prev . next \n                 prev . next   =   next \n                 next   =   curr . next \n             prev   =   curr \n             num   -=   k \n         return   prevhead . next   The problem is a little bit complicate. It works like an  excavator's wheel .  For example, given the list:  1(head) -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 .  We look more carefully inside the codes:  if $head$ is $None$ or $k == 1$, we simply return $head$.  We declare the value $prevhead = self$ as the object itself, and set the attribute $prevhead.next = head$ to  point  to the first node(i.e., $1$ in the list):  prevhead -> 1(head) -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 .  And we keep two variable $curr$ and $prev$, both equal to $prevhead$ in the beginning:  prevhead/curr/prev -> 1(head) -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 .   In the first while loop: we linearly scan the list to count the $num$ of nodes in the list.  In the second while loop:        while   num   >=   k : \n         curr   =   prev . next \n         next   =   curr . next   We set $curr = prev.next$(i.e., $1$) and $next = curr.next$(i.e., $2$) as the begin vaue of the $k$ Group(using $k = 3$ to explain the core idea).  prevhead/prev -> 1(curr) -> 2(next) -> 3 -> 4 -> 5 -> 6 -> 7 .       for   i   in   range ( 1 ,   k ): \n         curr . next   =   next . next \n         next . next   =   prev . next \n         prev . next   =   next \n         next   =   curr . next    $k = 1$  $curr.next = next.next$:  1(curr) -> 3  $next.next = prev.next$:  2(next) -> 1  $prev.next = next$:  prev -> 2  $next = curr.next$:  next = 3     prevhead/prev -> 2 -> 1(curr) -> 3(next) -> 4 -> 5 -> 6 -> 7 .   $k = 2$  $curr.next = next.next$:  1(curr) -> 4  $next.next = prev.next$:  3(next) -> 2  $prev.next = next$:  prev -> 3  $next = curr.next$:  next = 4     prevhead/prev -> 3 -> 2 -> 1(curr) -> 4(next) -> 5 -> 6 -> 7 .  After doing the first for loop,       prev   =   curr   $prev = curr$ means that we now set $prev = 1(curr)$, the new pointer to do the following $k$ group.  prevhead -> 3 -> 2 -> 1(curr/prev) -> 4(next) -> 5 -> 6 -> 7 .  You can think following now:  prevhead -> 3 -> 2 -> 1(prev) -> 4(curr) -> 5(next) -> 6 -> 7 . prevhead -> 3 -> 2 -> 1(prev) -> 5 -> 4(curr) -> 6(next) -> 7 . prevhead -> 3 -> 2 -> 1(prev) -> 6 -> 5 -> 4(curr) -> 7(next) .  We can test the problem with following codes:  def   printer ( a ): \n     curr   =   a \n     while   curr   is   not   None : \n         print ( curr . val ,   end   =   ' -> ' ,   sep   =   '' ) \n         curr   =   curr . next \n     print ( '' )   def   generateListNode ( n ): \n     prev   =   curr   =   ListNode ( 0 ) \n     for   i   in   range ( 1 ,   n ): \n         curr . next   =   ListNode ( i ) \n         curr   =   curr . next \n     return   prev . next   if   __name__   ==   \"__main__\" : \n     l   =   generateListNode ( 7 ) \n     # printer(l) \n\n     sol   =   Solution () \n     a   =   sol . reverseKGroup ( l ,   3 ) \n\n     # print('----------------') \n     # printer(a)",
            "title": "25. Reverse Nodes in k-Group $\\star\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/021-030/#26-remove-duplicates-from-sorted-array-star",
            "text": "class   Solution : \n     def   removeDuplicates ( self ,   nums ): \n         if   len ( nums )   ==   0 :        # return if the list is empty \n             return   0 \n         idx   =   0 \n         while   idx   <   len ( nums )   -   1 : \n             if   nums [ idx ]   ==   nums [ idx   +   1 ]: \n                 nums . remove ( nums [ idx ]) \n             else : \n                 idx   +=   1 \n         return   len ( nums )   This is very easy. We simply remove duplicate nums iterably.",
            "title": "26. Remove Duplicates from Sorted Array $\\star$"
        },
        {
            "location": "/LeetCode/001-100/021-030/#27-remove-element-star",
            "text": "class   Solution : \n     def   removeElement ( self ,   nums ,   val ): \n         i   =   0 \n         while   i   <   len ( nums ): \n             if   nums [ i ]   ==   val : \n                 nums . pop ( i )       # pop the i-th element in nums \n             else : \n                 i   +=   1 \n         return   i   In order to solve this  in-place , we cannot use $O(n)$ extra space. Therefore, we declare $i$ to keep  current  index of $nums$.  We don't use  remove()  since it's time-comsuming. Instead, we use  pop() .",
            "title": "27. Remove Element $\\star$"
        },
        {
            "location": "/LeetCode/001-100/021-030/#28-implement-strstr-star",
            "text": "This brute-force way is easy. And the time complexity is $O((n - m + 1)m)$.  class   Solution : \n     def   strStr ( self ,   haystack ,   needle ): \n         for   i   in   range ( len ( haystack )   -   len ( needle )   +   1 ): \n             if   haystack [ i :   i   +   len ( needle )]   ==   needle : \n                 return   i \n         return   - 1   We challenge ourselves by using  KMP . This can be done in $O(n + m)$. However, I don't know why KMP runs slower than the brute-force method in LeetCode. Maybe it just want us to do the brute-force in one star problem LoL.  class   Solution : \n     def   strStr ( self ,   haystack ,   needle ): \n         if   needle   ==   \"\" :                      # Remember to check this first! \n             return   0 \n         return   self . KMP ( haystack ,   needle ) \n\n     def   KMP ( self ,   A ,   B ): \n         lps   =   self . computeLPSArray ( B ) \n         i   =   j   =   0 \n         while   i   <   len ( A ): \n             if   A [ i ]   ==   B [ j ]: \n                 i   +=   1 \n                 j   +=   1 \n             if   j   ==   len ( B ): \n                 return   i   -   j \n                 j   =   lps [ j   -   1 ]                # This line won't execute, but we can still find all indices \n             elif   i   <   len ( A )   and   A [ i ]   !=   B [ j ]: \n                 if   j   !=   0 : \n                     j   =   lps [ j   -   1 ] \n                 else : \n                     i   +=   1 \n         return   - 1 \n\n     def   computeLPSArray ( self ,   B ): \n         m   =   len ( B ) \n         lps   =   [ 0 ]   *   m                         # Longest proper prefix which is also suffix \n         lps [ 0 ]   =   0 \n         k   =   0                                 # Current paired length \n         for   i   in   range ( 1 ,   m ): \n             while   k   >   0   and   B [ k ]   !=   B [ i ]: \n                 k   =   lps [ k   -   1 ] \n             if   B [ k ]   ==   B [ i ]: \n                 k   +=   1 \n             lps [ i ]   =   k \n         return   lps",
            "title": "28. Implement strStr() $\\star$"
        },
        {
            "location": "/LeetCode/001-100/021-030/#29-divide-two-integers-starstar",
            "text": "Binary problem...",
            "title": "29. Divide Two Integers $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/021-030/#30-substring-with-concatenation-of-all-words-starstarstar",
            "text": "",
            "title": "30. Substring with Concatenation of All Words $\\star\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/031-040/",
            "text": "31. Next Permutation \n$\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nnextPermutation\n(\nself\n,\n \nnums\n):\n\n        \nn\n \n=\n \nlen\n(\nnums\n)\n               \n# Extract the value of len(nums) first\n\n        \ni\n \n=\n \n0\n\n        \nwhile\n \ni\n \n<\n \nn\n \n-\n \n1\n:\n            \n# Find the first ascending digit from the back of the nums\n\n            \nif\n \nnums\n[\nn\n \n-\n \n2\n \n-\n \ni\n]\n \n<\n \nnums\n[\nn\n \n-\n \n1\n \n-\n \ni\n]:\n\n                \nbreak\n\n            \ni\n \n+=\n \n1\n\n        \nif\n \ni\n \n==\n \nn\n \n-\n \n1\n:\n\n            \nnums\n \n=\n \nself\n.\nreverse\n(\nnums\n,\n \n0\n,\n \nn\n \n-\n \n1\n)\n\n        \nelse\n:\n\n            \ni\n \n=\n \nn\n \n-\n \ni\n \n-\n \n2\n           \n# Get the first ascending digit's index\n\n            \nj\n \n=\n \nn\n \n-\n \n1\n               \n# Swap the digit with the next big in following digits\n\n            \nwhile\n \ni\n \n<\n \nj\n:\n\n                \nif\n \nnums\n[\ni\n]\n \n<\n \nnums\n[\nj\n]:\n\n                    \nnums\n[\ni\n],\n \nnums\n[\nj\n]\n \n=\n \nnums\n[\nj\n],\n \nnums\n[\ni\n]\n\n                    \nbreak\n\n                \nj\n \n-=\n \n1\n\n            \nnums\n[\ni\n \n+\n \n1\n:\n \nn\n]\n \n=\n \nself\n.\nreverse\n(\nnums\n[\ni\n \n+\n \n1\n:\n \nn\n],\n \n0\n,\n \nn\n \n-\n \ni\n \n-\n \n2\n)\n\n    \ndef\n \nreverse\n(\nself\n,\n \nnums\n,\n \nl\n,\n \nr\n):\n\n        \nwhile\n \nl\n \n<\n \nr\n:\n\n            \nnums\n[\nl\n],\n \nnums\n[\nr\n]\n \n=\n \nnums\n[\nr\n],\n \nnums\n[\nl\n]\n\n            \nl\n \n+=\n \n1\n\n            \nr\n \n-=\n \n1\n\n        \nreturn\n \nnums\n\n\n\n\n\nIt took me for a while to understand the problem LoL. We have to find the first ascending digit.\n\n\nFor example, given $nums = [7, 6, 1, 5, 4, 3, 2]$. Since\n\n\n\\begin{equation}\n7 > 6 > 1 < 5 > 4 > 3 > 2,\n\\end{equation}\n\n\nThe first ascending digit is $1$, we then swap the digit with the next big(i.e., $2$) in following digits:\n\n\n\\begin{equation}\nnums = [7, 6, 2, 5, 4, 3, 1].\n\\end{equation}\n\n\nFinally, we reverse the digits in the back of $2$, \n[5, 4, 3, 1]\n to \n[1, 3, 4, 5]\n. The final result:\n\n\n\\begin{equation}\nnums = [7, 6, 2, 1, 3, 4, 5].\n\\end{equation}\n\n\n32. Longest Valid Parentheses \n$\\star\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nlongestValidParentheses\n(\nself\n,\n \ns\n):\n\n        \nstack\n \n=\n \n[]\n\n        \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\ns\n)):\n\n            \nif\n \ns\n[\ni\n]\n \n==\n \n'('\n:\n                             \n# s[i] = '('\n\n                \nstack\n.\nappend\n((\n'('\n,\n \ni\n))\n\n            \nelse\n:\n                                       \n# s[i] = ')'\n\n                \nif\n \nstack\n:\n                               \n# stack is not empty\n\n                    \nif\n \nstack\n[\nlen\n(\nstack\n)\n \n-\n \n1\n][\n0\n]\n \n==\n \n'('\n:\n \n# The last element[0] is '('\n\n                        \nstack\n.\npop\n()\n\n                    \nelse\n:\n                               \n# The last element[0] is ')'\n\n                        \nstack\n.\nappend\n((\n')'\n,\n \ni\n))\n\n                \nelse\n:\n                                   \n# stakc is empty\n\n                    \nstack\n.\nappend\n((\n')'\n,\n \ni\n))\n\n        \nif\n \nnot\n \nstack\n:\n\n            \nreturn\n \nlen\n(\ns\n)\n                               \n# The whole string is valid parentheses\n\n        \nelse\n:\n\n            \na\n,\n \nb\n,\n \nlongest\n \n=\n \nlen\n(\ns\n),\n \n0\n,\n \n0\n\n            \nwhile\n \nstack\n:\n\n                \nb\n \n=\n \nstack\n[\nlen\n(\nstack\n)\n \n-\n \n1\n][\n1\n]\n\n                \nstack\n.\npop\n()\n\n                \nlongest\n \n=\n \nmax\n(\nlongest\n,\n \na\n \n-\n \nb\n \n-\n \n1\n)\n\n                \na\n \n=\n \nb\n\n            \nlongest\n \n=\n \nmax\n(\nlongest\n,\n \na\n)\n                   \n# index[0..a - 1]\n\n        \nreturn\n \nlongest\n\n\n\n\n\nInitialize an empty stack and scan the string from beginning to end.\n\n\n\n\nIf current character is '(', push \n('(', index)\n to the stack. \n\n\nIf current character is ')' and the character in the top of stack is '(', we just find a matching pair so pop from the stack. Otherwise, we push \n(')', index)\n to the stack.\n\n\n\n\nAfter the scan is done, the stack will only contain the characters and indices of string which cannot be matched. If the stack is empty, the whole input string is valid. Otherwise, we can minus each adjacent indices to find the longest valid parentheses.\n\n\n33. Search in Rotated Sorted Array \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nsearch\n(\nself\n,\n \nnums\n,\n \ntarget\n):\n\n        \nif\n \nnot\n \nnums\n:\n\n            \nreturn\n \n-\n1\n\n        \nlow\n,\n \nhigh\n \n=\n \n0\n,\n \nlen\n(\nnums\n)\n \n-\n \n1\n\n        \nwhile\n \nlow\n \n<\n \nhigh\n:\n\n            \nmid\n \n=\n \nint\n((\nlow\n \n+\n \nhigh\n)\n \n/\n \n2\n)\n\n            \nif\n \nnums\n[\nmid\n]\n \n==\n \ntarget\n:\n\n                \nreturn\n \nmid\n\n            \nif\n \nnums\n[\nlow\n]\n \n<=\n \nnums\n[\nmid\n]:\n                              \n# There isn't pivot in left-half\n\n                \nif\n \nnums\n[\nlow\n]\n \n<=\n \ntarget\n \n<\n \nnums\n[\nmid\n]:\n                 \n# target is in left-half\n\n                    \nhigh\n \n=\n \nmid\n \n-\n \n1\n\n                \nelse\n:\n                                               \n# target is in right-half\n\n                    \nlow\n \n=\n \nmid\n \n+\n \n1\n\n            \nelse\n:\n                                                   \n# There isn't pivot in right-half\n\n                \nif\n \nnums\n[\nmid\n]\n \n<\n \ntarget\n \n<=\n \nnums\n[\nhigh\n]:\n                \n# target is in right-half\n\n                    \nlow\n \n=\n \nmid\n \n+\n \n1\n\n                \nelse\n:\n                                               \n# target is in left-half\n\n                    \nhigh\n \n=\n \nmid\n \n-\n \n1\n\n        \nif\n \nnums\n[\nlow\n]\n \n==\n \ntarget\n:\n\n            \nreturn\n \nlow\n\n        \nreturn\n \n-\n1\n\n\n\n\n\nThe core idea is like a regular binary search, but we check $nums[low] \\le nums[mid]$ every time, this means that \"There isn't pivot in left-half.\" And if $target$ is in the left-half, we then set $high = mid - 1$. Otherwise($target$ in right-half), we set $low = mid + 1$.\n\n\n34. Search for a Range \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nsearchRange\n(\nself\n,\n \nnums\n,\n \ntarget\n):\n\n        \nif\n \nnot\n \nnums\n:\n\n            \nreturn\n \n[\n-\n1\n,\n \n-\n1\n]\n\n        \ndef\n \nsearch\n(\nlow\n,\n \nhigh\n):\n\n            \nif\n \nnums\n[\nlow\n]\n \n==\n \ntarget\n \n==\n \nnums\n[\nhigh\n]:\n\n                \nreturn\n \n[\nlow\n,\n \nhigh\n]\n\n            \nif\n \nnums\n[\nlow\n]\n \n<=\n \ntarget\n \n<=\n \nnums\n[\nhigh\n]:\n\n                \nmid\n \n=\n \nint\n((\nlow\n \n+\n \nhigh\n)\n \n/\n \n2\n)\n\n                \nleft\n \n=\n \nsearch\n(\nlow\n,\n \nmid\n)\n\n                \nright\n \n=\n \nsearch\n(\nmid\n \n+\n \n1\n,\n \nhigh\n)\n\n                \nif\n \n[\n-\n1\n,\n \n-\n1\n]\n \n==\n \nleft\n \nor\n \n[\n-\n1\n,\n \n-\n1\n]\n \n==\n \nright\n:\n\n                    \nreturn\n \nmax\n(\nleft\n,\n \nright\n)\n\n                \nelse\n:\n\n                    \nreturn\n \n[\nleft\n[\n0\n],\n \nright\n[\n1\n]]\n\n            \nreturn\n \n[\n-\n1\n,\n \n-\n1\n]\n\n        \nreturn\n \nsearch\n(\n0\n,\n \nlen\n(\nnums\n)\n \n-\n \n1\n)\n\n\n\n\n\nThe core idea is still like a regular binary search. We define a new function $search(low, high)$, and recursively find the $left$ range and $right$ range. If $[-1, -1] == left$ or $[-1, -1] == right$, which means $left$ or $right$ doens't contain the valid range, we then discard it. Otherwise we return $[left[0], right[1]]$.\n\n\n35. Search Insert Position \n$\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nsearchInsert\n(\nself\n,\n \nnums\n,\n \ntarget\n):\n\n        \nlow\n,\n \nhigh\n \n=\n \n0\n,\n \nlen\n(\nnums\n)\n\n        \nwhile\n \nlow\n \n<\n \nhigh\n:\n\n            \nmid\n \n=\n \nint\n((\nlow\n \n+\n \nhigh\n)\n \n/\n \n2\n)\n\n            \nif\n \nnums\n[\nmid\n]\n \n>=\n \ntarget\n:\n\n                \nhigh\n \n=\n \nmid\n\n            \nelse\n:\n\n                \nlow\n \n=\n \nmid\n \n+\n \n1\n\n        \nreturn\n \nlow\n\n\n\n\n\nUnlike before problem, here we set $high = len(nums)$ not $high = len(nums) - 1$ for tricky purpose.\n\n\nIf the input is $[1, 3, 5, 6], 7$ and $high = len(nums) - 1$, the output will be $3$, which is wrong. Therefore, we set $high = len(nums)$.\n\n\n36. Valid Sudoku \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nisValidSudoku\n(\nself\n,\n \nboard\n):\n\n        \ndef\n \nisValidRow\n(\nboard\n):\n\n            \nfor\n \nrow\n \nin\n \nboard\n:\n\n                \nif\n \nisValid\n(\nrow\n)\n \n==\n \nFalse\n:\n\n                    \nreturn\n \nFalse\n\n            \nreturn\n \nTrue\n\n        \ndef\n \nisValidCol\n(\nboard\n):\n\n            \nfor\n \ncol\n \nin\n \nzip\n(\n*\nboard\n):\n\n                \nif\n \nisValid\n(\ncol\n)\n \n==\n \nFalse\n:\n\n                    \nreturn\n \nFalse\n\n            \nreturn\n \nTrue\n\n        \ndef\n \nisValidSquare\n(\nboard\n):\n\n            \nfor\n \ni\n \nin\n \n(\n0\n,\n \n3\n,\n \n6\n):\n\n                \nfor\n \nj\n \nin\n \n(\n0\n,\n \n3\n,\n \n6\n):\n\n                    \nsquare\n \n=\n \n[\nboard\n[\nx\n][\ny\n]\n \nfor\n \nx\n \nin\n \nrange\n(\ni\n,\n \ni\n \n+\n \n3\n)\n \nfor\n \ny\n \nin\n \nrange\n(\nj\n,\n \nj\n \n+\n \n3\n)]\n\n                    \nif\n \nisValid\n(\nsquare\n)\n \n==\n \nFalse\n:\n\n                        \nreturn\n \nFalse\n\n            \nreturn\n \nTrue\n\n        \ndef\n \nisValid\n(\nlist\n):\n\n            \nres\n \n=\n \n[\ni\n \nfor\n \ni\n \nin\n \nlist\n \nif\n \ni\n \n!=\n \n'.'\n]\n\n            \nreturn\n \nlen\n(\nres\n)\n \n==\n \nlen\n(\nset\n(\nres\n))\n\n        \nreturn\n \nisValidRow\n(\nboard\n)\n \nand\n \nisValidCol\n(\nboard\n)\n \nand\n \nisValidSquare\n(\nboard\n)\n\n\n\n\n\nHere we skillfully use \nzip(*board)\n to get each column in the board.\n\n\nWe define $isValid$ function, and $len(res) == len(set(res))$ to check whether there are duplicates or not.\n\n\n37. Sudoku Solver \n$\\star\\star\\star$\n\u00b6\n\n\n38. Count and Say \n$\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \ncountAndSay\n(\nself\n,\n \nn\n):\n\n        \ndict\n \n=\n \n{\n1\n:\n \n'1'\n,\n \n2\n:\n \n'11'\n,\n \n3\n:\n \n'21'\n,\n \n4\n:\n \n'1211'\n,\n \n5\n:\n \n'111221'\n}\n\n        \nif\n \nn\n \n<=\n \n5\n:\n\n            \nreturn\n \ndict\n[\nn\n]\n\n        \nfor\n \ni\n \nin\n \nrange\n(\n6\n,\n \nn\n \n+\n \n1\n):\n\n            \nstring\n \n=\n \n''\n\n            \nj\n \n=\n \n0\n\n            \nwhile\n \nj\n \n<=\n \nlen\n(\ndict\n[\ni\n \n-\n \n1\n])\n \n-\n \n2\n:\n\n                \ncnt\n \n=\n \n1\n\n                \nwhile\n \nj\n \n<=\n \nlen\n(\ndict\n[\ni\n \n-\n \n1\n])\n \n-\n \n2\n \nand\n \ndict\n[\ni\n \n-\n \n1\n][\nj\n]\n \n==\n \ndict\n[\ni\n \n-\n \n1\n][\nj\n \n+\n \n1\n]:\n\n                    \ncnt\n \n+=\n \n1\n\n                    \nj\n \n+=\n \n1\n\n                \nstring\n \n+=\n \n(\nstr\n(\ncnt\n)\n \n+\n \nstr\n(\ndict\n[\ni\n \n-\n \n1\n][\nj\n]))\n\n                \nj\n \n+=\n \n1\n\n            \nif\n \nj\n \n==\n \nlen\n(\ndict\n[\ni\n \n-\n \n1\n])\n \n-\n \n1\n:\n\n                \nstring\n \n+=\n \n(\nstr\n(\n1\n)\n \n+\n \nstr\n(\ndict\n[\ni\n \n-\n \n1\n][\nj\n]))\n\n            \ndict\n[\ni\n]\n \n=\n \nstring\n\n        \nreturn\n \ndict\n[\nn\n]\n\n\n\n\n\nEasy but troublesome.\n\n\n39. Combination Sum \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \ncombinationSum\n(\nself\n,\n \ncandidates\n,\n \ntarget\n):\n\n        \ncandidates\n.\nsort\n()\n\n        \nreturn\n \nself\n.\ndfs\n(\ncandidates\n,\n \ntarget\n,\n \n0\n,\n \n[],\n \n[])\n\n    \ndef\n \ndfs\n(\nself\n,\n \ncandidates\n,\n \ntarget\n,\n \nstart\n,\n \nans\n,\n \nres\n):\n\n        \nif\n \ntarget\n \n==\n \n0\n:\n\n            \nres\n.\nappend\n(\nans\n)\n\n            \nreturn\n\n        \nfor\n \ni\n \nin\n \nrange\n(\nstart\n,\n \nlen\n(\ncandidates\n)):\n\n            \nif\n \ncandidates\n[\ni\n]\n \n>\n \ntarget\n:\n\n                \nbreak\n\n            \nself\n.\ndfs\n(\ncandidates\n,\n \ntarget\n \n-\n \ncandidates\n[\ni\n],\n \ni\n,\n \nans\n \n+\n \n[\ncandidates\n[\ni\n]],\n \nres\n)\n\n        \nreturn\n \nres\n\n\n\n\n\nWe can use \ndfs\n to solve this kind of problems. $candidates.sort()$ first can let us do some early break:\n\n\n    \nfor\n \ni\n \nin\n \nrange\n(\nstart\n,\n \nlen\n(\ncandidates\n)):\n\n        \nif\n \ncandidates\n[\ni\n]\n \n>\n \ntarget\n:\n\n            \nbreak\n\n\n\n\n\nLet's now work on an example. Given $candidates = [2, 3, 6, 7]$ and $target = 7$.\n\n\nFor simplicity, we omit the parameters $candidates$ and $res$ to explain the idea.\n\n\nWhen we call $dfs[7, 0, []]$ in the beginning, it'll then call\n\n\n\\begin{equation}\ndfs[5, 0, [2]], dfs[4, 1, [3]], dfs[1, 2, [6]], dfs[0, 3, [7]]\n\\end{equation}\n\n\nSince $target = 0$ in $dfs[0, 3, [7]]$, we append $[7]$ to $res$.\n\n\nFor each branch, it'll do dfs to find all possible solutions.\n\n\n40. Combination Sum II \n$\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \ncombinationSum2\n(\nself\n,\n \ncandidates\n,\n \ntarget\n):\n\n        \ncandidates\n.\nsort\n()\n\n        \nreturn\n \nself\n.\ndfs\n(\ncandidates\n,\n \ntarget\n,\n \n0\n,\n \n[],\n \n[])\n\n    \ndef\n \ndfs\n(\nself\n,\n \ncandidates\n,\n \ntarget\n,\n \nstart\n,\n \nans\n,\n \nres\n):\n\n        \nif\n \ntarget\n \n==\n \n0\n:\n\n            \nres\n.\nappend\n(\nans\n)\n\n            \nreturn\n\n        \nfor\n \ni\n \nin\n \nrange\n(\nstart\n,\n \nlen\n(\ncandidates\n)):\n\n            \nif\n \ncandidates\n[\ni\n]\n \n>\n \ntarget\n:\n\n                \nbreak\n\n            \nif\n \ni\n \n!=\n \nstart\n \nand\n \ncandidates\n[\ni\n]\n \n==\n \ncandidates\n[\ni\n \n-\n \n1\n]:\n\n                \ncontinue\n\n            \nself\n.\ndfs\n(\ncandidates\n,\n \ntarget\n \n-\n \ncandidates\n[\ni\n],\n \ni\n \n+\n \n1\n,\n \nans\n \n+\n \n[\ncandidates\n[\ni\n]],\n \nres\n)\n\n        \nreturn\n \nres\n\n\n\n\n\nThis problem is very like \n39. Combination Sum\n.\n\n\nWe just revise the variable $start$ in dfs procedure to $i + 1$ to ensure that each number in \nC\n may only be used once in the combination.\n\n\n    \nif\n \ni\n \n!=\n \nstart\n \nand\n \ncandidates\n[\ni\n]\n \n==\n \ncandidates\n[\ni\n \n-\n \n1\n]:\n\n        \ncontinue\n\n\n\n\n\nThese lines also ensure the same thing.",
            "title": "031-040"
        },
        {
            "location": "/LeetCode/001-100/031-040/#31-next-permutation-star",
            "text": "class   Solution : \n     def   nextPermutation ( self ,   nums ): \n         n   =   len ( nums )                 # Extract the value of len(nums) first \n         i   =   0 \n         while   i   <   n   -   1 :              # Find the first ascending digit from the back of the nums \n             if   nums [ n   -   2   -   i ]   <   nums [ n   -   1   -   i ]: \n                 break \n             i   +=   1 \n         if   i   ==   n   -   1 : \n             nums   =   self . reverse ( nums ,   0 ,   n   -   1 ) \n         else : \n             i   =   n   -   i   -   2             # Get the first ascending digit's index \n             j   =   n   -   1                 # Swap the digit with the next big in following digits \n             while   i   <   j : \n                 if   nums [ i ]   <   nums [ j ]: \n                     nums [ i ],   nums [ j ]   =   nums [ j ],   nums [ i ] \n                     break \n                 j   -=   1 \n             nums [ i   +   1 :   n ]   =   self . reverse ( nums [ i   +   1 :   n ],   0 ,   n   -   i   -   2 ) \n     def   reverse ( self ,   nums ,   l ,   r ): \n         while   l   <   r : \n             nums [ l ],   nums [ r ]   =   nums [ r ],   nums [ l ] \n             l   +=   1 \n             r   -=   1 \n         return   nums   It took me for a while to understand the problem LoL. We have to find the first ascending digit.  For example, given $nums = [7, 6, 1, 5, 4, 3, 2]$. Since  \\begin{equation}\n7 > 6 > 1 < 5 > 4 > 3 > 2,\n\\end{equation}  The first ascending digit is $1$, we then swap the digit with the next big(i.e., $2$) in following digits:  \\begin{equation}\nnums = [7, 6, 2, 5, 4, 3, 1].\n\\end{equation}  Finally, we reverse the digits in the back of $2$,  [5, 4, 3, 1]  to  [1, 3, 4, 5] . The final result:  \\begin{equation}\nnums = [7, 6, 2, 1, 3, 4, 5].\n\\end{equation}",
            "title": "31. Next Permutation $\\star$"
        },
        {
            "location": "/LeetCode/001-100/031-040/#32-longest-valid-parentheses-starstarstar",
            "text": "class   Solution : \n     def   longestValidParentheses ( self ,   s ): \n         stack   =   [] \n         for   i   in   range ( len ( s )): \n             if   s [ i ]   ==   '(' :                               # s[i] = '(' \n                 stack . append (( '(' ,   i )) \n             else :                                         # s[i] = ')' \n                 if   stack :                                 # stack is not empty \n                     if   stack [ len ( stack )   -   1 ][ 0 ]   ==   '(' :   # The last element[0] is '(' \n                         stack . pop () \n                     else :                                 # The last element[0] is ')' \n                         stack . append (( ')' ,   i )) \n                 else :                                     # stakc is empty \n                     stack . append (( ')' ,   i )) \n         if   not   stack : \n             return   len ( s )                                 # The whole string is valid parentheses \n         else : \n             a ,   b ,   longest   =   len ( s ),   0 ,   0 \n             while   stack : \n                 b   =   stack [ len ( stack )   -   1 ][ 1 ] \n                 stack . pop () \n                 longest   =   max ( longest ,   a   -   b   -   1 ) \n                 a   =   b \n             longest   =   max ( longest ,   a )                     # index[0..a - 1] \n         return   longest   Initialize an empty stack and scan the string from beginning to end.   If current character is '(', push  ('(', index)  to the stack.   If current character is ')' and the character in the top of stack is '(', we just find a matching pair so pop from the stack. Otherwise, we push  (')', index)  to the stack.   After the scan is done, the stack will only contain the characters and indices of string which cannot be matched. If the stack is empty, the whole input string is valid. Otherwise, we can minus each adjacent indices to find the longest valid parentheses.",
            "title": "32. Longest Valid Parentheses $\\star\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/031-040/#33-search-in-rotated-sorted-array-starstar",
            "text": "class   Solution : \n     def   search ( self ,   nums ,   target ): \n         if   not   nums : \n             return   - 1 \n         low ,   high   =   0 ,   len ( nums )   -   1 \n         while   low   <   high : \n             mid   =   int (( low   +   high )   /   2 ) \n             if   nums [ mid ]   ==   target : \n                 return   mid \n             if   nums [ low ]   <=   nums [ mid ]:                                # There isn't pivot in left-half \n                 if   nums [ low ]   <=   target   <   nums [ mid ]:                   # target is in left-half \n                     high   =   mid   -   1 \n                 else :                                                 # target is in right-half \n                     low   =   mid   +   1 \n             else :                                                     # There isn't pivot in right-half \n                 if   nums [ mid ]   <   target   <=   nums [ high ]:                  # target is in right-half \n                     low   =   mid   +   1 \n                 else :                                                 # target is in left-half \n                     high   =   mid   -   1 \n         if   nums [ low ]   ==   target : \n             return   low \n         return   - 1   The core idea is like a regular binary search, but we check $nums[low] \\le nums[mid]$ every time, this means that \"There isn't pivot in left-half.\" And if $target$ is in the left-half, we then set $high = mid - 1$. Otherwise($target$ in right-half), we set $low = mid + 1$.",
            "title": "33. Search in Rotated Sorted Array $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/031-040/#34-search-for-a-range-starstar",
            "text": "class   Solution : \n     def   searchRange ( self ,   nums ,   target ): \n         if   not   nums : \n             return   [ - 1 ,   - 1 ] \n         def   search ( low ,   high ): \n             if   nums [ low ]   ==   target   ==   nums [ high ]: \n                 return   [ low ,   high ] \n             if   nums [ low ]   <=   target   <=   nums [ high ]: \n                 mid   =   int (( low   +   high )   /   2 ) \n                 left   =   search ( low ,   mid ) \n                 right   =   search ( mid   +   1 ,   high ) \n                 if   [ - 1 ,   - 1 ]   ==   left   or   [ - 1 ,   - 1 ]   ==   right : \n                     return   max ( left ,   right ) \n                 else : \n                     return   [ left [ 0 ],   right [ 1 ]] \n             return   [ - 1 ,   - 1 ] \n         return   search ( 0 ,   len ( nums )   -   1 )   The core idea is still like a regular binary search. We define a new function $search(low, high)$, and recursively find the $left$ range and $right$ range. If $[-1, -1] == left$ or $[-1, -1] == right$, which means $left$ or $right$ doens't contain the valid range, we then discard it. Otherwise we return $[left[0], right[1]]$.",
            "title": "34. Search for a Range $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/031-040/#35-search-insert-position-star",
            "text": "class   Solution : \n     def   searchInsert ( self ,   nums ,   target ): \n         low ,   high   =   0 ,   len ( nums ) \n         while   low   <   high : \n             mid   =   int (( low   +   high )   /   2 ) \n             if   nums [ mid ]   >=   target : \n                 high   =   mid \n             else : \n                 low   =   mid   +   1 \n         return   low   Unlike before problem, here we set $high = len(nums)$ not $high = len(nums) - 1$ for tricky purpose.  If the input is $[1, 3, 5, 6], 7$ and $high = len(nums) - 1$, the output will be $3$, which is wrong. Therefore, we set $high = len(nums)$.",
            "title": "35. Search Insert Position $\\star$"
        },
        {
            "location": "/LeetCode/001-100/031-040/#36-valid-sudoku-starstar",
            "text": "class   Solution : \n     def   isValidSudoku ( self ,   board ): \n         def   isValidRow ( board ): \n             for   row   in   board : \n                 if   isValid ( row )   ==   False : \n                     return   False \n             return   True \n         def   isValidCol ( board ): \n             for   col   in   zip ( * board ): \n                 if   isValid ( col )   ==   False : \n                     return   False \n             return   True \n         def   isValidSquare ( board ): \n             for   i   in   ( 0 ,   3 ,   6 ): \n                 for   j   in   ( 0 ,   3 ,   6 ): \n                     square   =   [ board [ x ][ y ]   for   x   in   range ( i ,   i   +   3 )   for   y   in   range ( j ,   j   +   3 )] \n                     if   isValid ( square )   ==   False : \n                         return   False \n             return   True \n         def   isValid ( list ): \n             res   =   [ i   for   i   in   list   if   i   !=   '.' ] \n             return   len ( res )   ==   len ( set ( res )) \n         return   isValidRow ( board )   and   isValidCol ( board )   and   isValidSquare ( board )   Here we skillfully use  zip(*board)  to get each column in the board.  We define $isValid$ function, and $len(res) == len(set(res))$ to check whether there are duplicates or not.",
            "title": "36. Valid Sudoku $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/031-040/#37-sudoku-solver-starstarstar",
            "text": "",
            "title": "37. Sudoku Solver $\\star\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/031-040/#38-count-and-say-star",
            "text": "class   Solution : \n     def   countAndSay ( self ,   n ): \n         dict   =   { 1 :   '1' ,   2 :   '11' ,   3 :   '21' ,   4 :   '1211' ,   5 :   '111221' } \n         if   n   <=   5 : \n             return   dict [ n ] \n         for   i   in   range ( 6 ,   n   +   1 ): \n             string   =   '' \n             j   =   0 \n             while   j   <=   len ( dict [ i   -   1 ])   -   2 : \n                 cnt   =   1 \n                 while   j   <=   len ( dict [ i   -   1 ])   -   2   and   dict [ i   -   1 ][ j ]   ==   dict [ i   -   1 ][ j   +   1 ]: \n                     cnt   +=   1 \n                     j   +=   1 \n                 string   +=   ( str ( cnt )   +   str ( dict [ i   -   1 ][ j ])) \n                 j   +=   1 \n             if   j   ==   len ( dict [ i   -   1 ])   -   1 : \n                 string   +=   ( str ( 1 )   +   str ( dict [ i   -   1 ][ j ])) \n             dict [ i ]   =   string \n         return   dict [ n ]   Easy but troublesome.",
            "title": "38. Count and Say $\\star$"
        },
        {
            "location": "/LeetCode/001-100/031-040/#39-combination-sum-starstar",
            "text": "class   Solution : \n     def   combinationSum ( self ,   candidates ,   target ): \n         candidates . sort () \n         return   self . dfs ( candidates ,   target ,   0 ,   [],   []) \n     def   dfs ( self ,   candidates ,   target ,   start ,   ans ,   res ): \n         if   target   ==   0 : \n             res . append ( ans ) \n             return \n         for   i   in   range ( start ,   len ( candidates )): \n             if   candidates [ i ]   >   target : \n                 break \n             self . dfs ( candidates ,   target   -   candidates [ i ],   i ,   ans   +   [ candidates [ i ]],   res ) \n         return   res   We can use  dfs  to solve this kind of problems. $candidates.sort()$ first can let us do some early break:       for   i   in   range ( start ,   len ( candidates )): \n         if   candidates [ i ]   >   target : \n             break   Let's now work on an example. Given $candidates = [2, 3, 6, 7]$ and $target = 7$.  For simplicity, we omit the parameters $candidates$ and $res$ to explain the idea.  When we call $dfs[7, 0, []]$ in the beginning, it'll then call  \\begin{equation}\ndfs[5, 0, [2]], dfs[4, 1, [3]], dfs[1, 2, [6]], dfs[0, 3, [7]]\n\\end{equation}  Since $target = 0$ in $dfs[0, 3, [7]]$, we append $[7]$ to $res$.  For each branch, it'll do dfs to find all possible solutions.",
            "title": "39. Combination Sum $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/031-040/#40-combination-sum-ii-starstar",
            "text": "class   Solution : \n     def   combinationSum2 ( self ,   candidates ,   target ): \n         candidates . sort () \n         return   self . dfs ( candidates ,   target ,   0 ,   [],   []) \n     def   dfs ( self ,   candidates ,   target ,   start ,   ans ,   res ): \n         if   target   ==   0 : \n             res . append ( ans ) \n             return \n         for   i   in   range ( start ,   len ( candidates )): \n             if   candidates [ i ]   >   target : \n                 break \n             if   i   !=   start   and   candidates [ i ]   ==   candidates [ i   -   1 ]: \n                 continue \n             self . dfs ( candidates ,   target   -   candidates [ i ],   i   +   1 ,   ans   +   [ candidates [ i ]],   res ) \n         return   res   This problem is very like  39. Combination Sum .  We just revise the variable $start$ in dfs procedure to $i + 1$ to ensure that each number in  C  may only be used once in the combination.       if   i   !=   start   and   candidates [ i ]   ==   candidates [ i   -   1 ]: \n         continue   These lines also ensure the same thing.",
            "title": "40. Combination Sum II $\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/041-050/",
            "text": "41. First Missing Positive \n$\\star\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \nfirstMissingPositive\n(\nself\n,\n \nnums\n):\n\n        \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\nnums\n)):\n\n            \nwhile\n \nnums\n[\ni\n]\n \n>\n \n0\n \nand\n \nnums\n[\ni\n]\n \n<\n \nlen\n(\nnums\n)\n \nand\n \nnums\n[\nnums\n[\ni\n]\n \n-\n \n1\n]\n \n!=\n \nnums\n[\ni\n]:\n\n                \nidx\n \n=\n \nnums\n[\ni\n]\n\n                \nnums\n[\ni\n],\n \nnums\n[\nidx\n \n-\n \n1\n]\n \n=\n \nnums\n[\nidx\n \n-\n \n1\n],\n \nidx\n\n        \nfor\n \ni\n \nin\n \nrange\n(\nlen\n(\nnums\n)):\n\n            \nif\n \nnums\n[\ni\n]\n \n!=\n \ni\n \n+\n \n1\n:\n\n                \nreturn\n \ni\n \n+\n \n1\n\n        \nreturn\n \nlen\n(\nnums\n)\n \n+\n \n1\n\n\n\n\n\nWe linearly scan the $nums$, and swap $nums[i]$ with $nums[nums[i] - 1]$ if\n\n\n\n\n$nums[i]$ is positive,\n\n\n$nums[i] < len(nums)$ and \n\n\n$nums[nums[i] - 1] != nums[i]$(the destination doesn't hold the correct value).\n\n\n\n\nSo, $idx = 0$ will hold value $1$, $idx = 1$ will hold value $2$, and $idx = 2$ will hold value $3$...\n\n\nFor example, given input $nums = [-1, 4, 2, 1, 9, 10]$, in\n\n\n    \nwhile\n \nnums\n[\ni\n]\n \n>\n \n0\n \nand\n \nnums\n[\ni\n]\n \n<\n \nlen\n(\nnums\n)\n \nand\n \nnums\n[\nnums\n[\ni\n]\n \n-\n \n1\n]\n \n!=\n \nnums\n[\ni\n]:\n\n        \nidx\n \n=\n \nnums\n[\ni\n]\n\n        \nnums\n[\ni\n],\n \nnums\n[\nidx\n \n-\n \n1\n]\n \n=\n \nnums\n[\nidx\n \n-\n \n1\n],\n \nidx\n\n\n\n\n\nwhne $i = 1$, $nums[1] = 4$, we first check the value of $nums[4 - 1] = nums[3]$ is $4$ or not, but $nums[3] = 1$, so we swap $nums[1] = 4$ with $nums[3] = 1$. And now, $nums[i] = 1$\n\n\n42. Trapping Rain Water \n$\\star\\star\\star$\n\u00b6\n\n\nclass\n \nSolution\n:\n\n    \ndef\n \ntrap\n(\nself\n,\n \nheight\n):\n\n        \nif\n \nlen\n(\nheight\n)\n \n<\n \n3\n:\n\n            \nreturn\n \n0\n\n        \nleftWall\n,\n \nrightWall\n \n=\n \nheight\n[\n0\n],\n \nheight\n[\nlen\n(\nheight\n)\n \n-\n \n1\n]\n\n        \nleft\n,\n \nright\n \n=\n \n1\n,\n \nlen\n(\nheight\n)\n \n-\n \n2\n\n        \nwater\n \n=\n \n0\n\n        \nwhile\n \nleft\n \n<=\n \nright\n:\n\n            \nif\n \nleftWall\n \n<=\n \nrightWall\n:\n\n                \nleftWall\n \n=\n \nmax\n(\nleftWall\n,\n \nheight\n[\nleft\n])\n\n                \nwater\n \n+=\n \nleftWall\n \n-\n \nheight\n[\nleft\n]\n\n                \nleft\n \n+=\n \n1\n\n            \nelse\n:\n\n                \nrightWall\n \n=\n \nmax\n(\nrightWall\n,\n \nheight\n[\nright\n])\n\n                \nwater\n \n+=\n \nrightWall\n \n-\n \nheight\n[\nright\n]\n\n                \nright\n \n-=\n \n1\n\n        \nreturn\n \nwater",
            "title": "041-050"
        },
        {
            "location": "/LeetCode/001-100/041-050/#41-first-missing-positive-starstarstar",
            "text": "class   Solution : \n     def   firstMissingPositive ( self ,   nums ): \n         for   i   in   range ( len ( nums )): \n             while   nums [ i ]   >   0   and   nums [ i ]   <   len ( nums )   and   nums [ nums [ i ]   -   1 ]   !=   nums [ i ]: \n                 idx   =   nums [ i ] \n                 nums [ i ],   nums [ idx   -   1 ]   =   nums [ idx   -   1 ],   idx \n         for   i   in   range ( len ( nums )): \n             if   nums [ i ]   !=   i   +   1 : \n                 return   i   +   1 \n         return   len ( nums )   +   1   We linearly scan the $nums$, and swap $nums[i]$ with $nums[nums[i] - 1]$ if   $nums[i]$ is positive,  $nums[i] < len(nums)$ and   $nums[nums[i] - 1] != nums[i]$(the destination doesn't hold the correct value).   So, $idx = 0$ will hold value $1$, $idx = 1$ will hold value $2$, and $idx = 2$ will hold value $3$...  For example, given input $nums = [-1, 4, 2, 1, 9, 10]$, in       while   nums [ i ]   >   0   and   nums [ i ]   <   len ( nums )   and   nums [ nums [ i ]   -   1 ]   !=   nums [ i ]: \n         idx   =   nums [ i ] \n         nums [ i ],   nums [ idx   -   1 ]   =   nums [ idx   -   1 ],   idx   whne $i = 1$, $nums[1] = 4$, we first check the value of $nums[4 - 1] = nums[3]$ is $4$ or not, but $nums[3] = 1$, so we swap $nums[1] = 4$ with $nums[3] = 1$. And now, $nums[i] = 1$",
            "title": "41. First Missing Positive $\\star\\star\\star$"
        },
        {
            "location": "/LeetCode/001-100/041-050/#42-trapping-rain-water-starstarstar",
            "text": "class   Solution : \n     def   trap ( self ,   height ): \n         if   len ( height )   <   3 : \n             return   0 \n         leftWall ,   rightWall   =   height [ 0 ],   height [ len ( height )   -   1 ] \n         left ,   right   =   1 ,   len ( height )   -   2 \n         water   =   0 \n         while   left   <=   right : \n             if   leftWall   <=   rightWall : \n                 leftWall   =   max ( leftWall ,   height [ left ]) \n                 water   +=   leftWall   -   height [ left ] \n                 left   +=   1 \n             else : \n                 rightWall   =   max ( rightWall ,   height [ right ]) \n                 water   +=   rightWall   -   height [ right ] \n                 right   -=   1 \n         return   water",
            "title": "42. Trapping Rain Water $\\star\\star\\star$"
        },
        {
            "location": "/OS/",
            "text": "Operating System | notes\n\u00b6\n\n\nIn this page, I'll work on my notes when I have class of \nOperating System, Spring 2018\n by Professor \nTei-Wei Kuo\n. Professor Kuo has also upload the course videos to \nYouTube\n.\n\n\nThe materials are mainly from the \nOperating System Concepts, 9th Edition\n.",
            "title": "Preface"
        },
        {
            "location": "/OS/#operating-system-notes",
            "text": "In this page, I'll work on my notes when I have class of  Operating System, Spring 2018  by Professor  Tei-Wei Kuo . Professor Kuo has also upload the course videos to  YouTube .  The materials are mainly from the  Operating System Concepts, 9th Edition .",
            "title": "Operating System | notes"
        },
        {
            "location": "/OS/Chap01/",
            "text": "Dummy\n\u00b6",
            "title": "Chapter 1 Introduction"
        },
        {
            "location": "/OS/Chap01/#dummy",
            "text": "",
            "title": "Dummy"
        },
        {
            "location": "/OS/Chap02/",
            "text": "Chapter 2 Operating-System Structures\n\u00b6\n\n\nObjectives:\n\n\n\n\nTo describe the services an operating system provides to users, processes, and other systems.\n\n\nTo discuss the various ways of structuring an operating system.\n\n\nTo explain how operating systems are installed and customized and how they boot.\n\n\n\n\n2.1 Operating-System Services\n\u00b6\n\n\n\n\n\n\n\n\nUser interface (UI)\n\n\n\n\ncommand-line interface (CLI)\n\n\nbatch interface\n\n\ngraphical user interface \n\n\n\n\n\n\n\n\nProgram execution. OS load a program into memory $\\to$ run that program $\\to$ end execution\n\n\n\n\nnormally\n\n\nabnormally (error)\n\n\n\n\n\n\n\n\nI/O operations. A running program may require I/O:\n\n\n\n\nfile\n\n\nI/O device: recording to a CD or DVD ...\n\n\n\n\n\n\n\n\nFile-system manipulation.\n\n\n\n\nread/write files\n\n\ncreate/delete them by name\n\n\nsearch\n\n\nlist file (ls)\n\n\n\n\n\n\n\n\nCommunications.\n\n\n\n\nshared memory\n\n\nmessage passing: packets of information in predefined formats are moved between processes by the operating system\n\n\n\n\n\n\n\n\nError detection\n\n\n\n\nResource allocation\n\n\nAccounting. users can be billed\n\n\nProtection and security\n\n\n\n\n2.2 User and Operating-System Interface\n\u00b6\n\n\n2.2.1 Command Interpreters\n\u00b6\n\n\nOn systems with multiple command interpreters to choose from, the interpreters are known as \nshells\n.\n\n\nTwo approaches:\n\n\n\n\nthe command interpreter itself contains the code to execute the command.\n\n\nfast but the interpreter tends to be big! $\\to$ painful in revision!\n\n\ne.g. \ncd\n, \nls\n, \ndel\n\n\n\n\n\n\nthe command interpreter merely uses the command to identify a file to be loaded into memory and executed $\\to$ search exec files\n\n\nparameter passing\n\n\nbeing slow\n\n\ninconsistent interpretation of parameters\n\n\ne.g. \nrm\n\n\n\n\n\n\n\n\n2.2.2 Graphical User Interfaces\n\u00b6\n\n\n\n\ndesktop\n\n\nicons\n\n\nfolder\n\n\nmouse\n\n\ngestures on the touchscreen\n\n\n\n\n2.2.3 Choice of Interface\n\u00b6\n\n\n\n\nshell scripts\n\n\ne.g. \nUNIX\n and \nLinux\n.\n\n\n\n\n\n\n\n\n2.3 Systems Calls\n\u00b6\n\n\n\n\nSystem calls provide an interface to the services made available by an operating system.\n\n\ne.g. writing a simple program to read data from one file and copy them to another file causes a lot of system calls!\n\n\n\n\nC/C++\n\n\n\n\nEach read and write must return status information regarding various possible error conditions.\n\n\n\n\napplication programming interface (API): it specifies a set of functions\n\n\nWindows API\n\n\nPOSIX API\n\n\nUNIX\n\n\nLinux\n\n\nmacOS\n\n\n\n\n\n\nJava API\n\n\n\n\n\n\n\n\nlibc\n: UNIX and Linux for programs written in C\n\n\nWhy prefer API rather than invoking actual system calls?\n\n\n\n\nprotability (expected to run on any system)\n\n\nactual system calls can be more difficult to learn\n\n\n\n\nThe relationship between an \nAPI\n, the \nsystem-call interface\n, and the \nOS\n\n\n\b\n\n\nThe caller need know nothing about how the system call is implemented or what it does during execution. Rather, the caller need only obey the API and understand what the operating system will do as a result of the execution of that system call.\n\n\nMake explicit to implicit\n.\n\n\nThree general methods are used to pass parameters to the operating system.\n\n\n\n\n\n\nthrough registers (Linux and Solaris)\n\n\n\n\nblock,\n\n\ntable, \n\n\nmemory, \n\n\nand the address of the\n\n\n\n\n\n\n\n\nplaced or pushed onto the stack $\\to$ popped off the stack by the OS\n\n\n\n\n\n\n\n\n2.4 Types of System Calls\n\u00b6\n\n\n2.4.1 Process Control\n\u00b6\n\n\nA running program halts either\n\n\n\n\nnormally: \nend()\n\n\nabnormally: \nabort()\n\n\n\n\nerror $\\to$ dump (written to disk, may be examined by a debugger)\n\n\nMore severe errors can be indicated by a higher-level error parameter.\n\n\ne.g. Standard C Library\n\n\n\n\n2.4.2 File Management\n\u00b6\n\n\n2.4.3 Device Management\n\u00b6\n\n\n2.4.4 Information Maintenance\n\u00b6\n\n\nMany systems provide system calls to \ndump()\n memory. This provision is useful for debugging. A program trace lists each system call as it is executed. Even microprocessors provide a CPU mode known as single step, in which a trap is executed by the CPU after every instruction. The trap is usually caught by a debugger.\n\n\n2.4.5 Communication\n\u00b6\n\n\n2.4.6 Protection\n\u00b6\n\n\n2.5 System Programs\n\u00b6\n\n\n2.6 Operating-System Design and Implementation\n\u00b6\n\n\n2.6.1 Design Goals\n\u00b6\n\n\n2.6.2 Mechanisms and Policies\n\u00b6\n\n\n2.6.3 Implementation\n\u00b6",
            "title": "Chapter 2 Operating-System Structures"
        },
        {
            "location": "/OS/Chap02/#chapter-2-operating-system-structures",
            "text": "Objectives:   To describe the services an operating system provides to users, processes, and other systems.  To discuss the various ways of structuring an operating system.  To explain how operating systems are installed and customized and how they boot.",
            "title": "Chapter 2 Operating-System Structures"
        },
        {
            "location": "/OS/Chap02/#21-operating-system-services",
            "text": "User interface (UI)   command-line interface (CLI)  batch interface  graphical user interface      Program execution. OS load a program into memory $\\to$ run that program $\\to$ end execution   normally  abnormally (error)     I/O operations. A running program may require I/O:   file  I/O device: recording to a CD or DVD ...     File-system manipulation.   read/write files  create/delete them by name  search  list file (ls)     Communications.   shared memory  message passing: packets of information in predefined formats are moved between processes by the operating system     Error detection   Resource allocation  Accounting. users can be billed  Protection and security",
            "title": "2.1 Operating-System Services"
        },
        {
            "location": "/OS/Chap02/#22-user-and-operating-system-interface",
            "text": "",
            "title": "2.2 User and Operating-System Interface"
        },
        {
            "location": "/OS/Chap02/#221-command-interpreters",
            "text": "On systems with multiple command interpreters to choose from, the interpreters are known as  shells .  Two approaches:   the command interpreter itself contains the code to execute the command.  fast but the interpreter tends to be big! $\\to$ painful in revision!  e.g.  cd ,  ls ,  del    the command interpreter merely uses the command to identify a file to be loaded into memory and executed $\\to$ search exec files  parameter passing  being slow  inconsistent interpretation of parameters  e.g.  rm",
            "title": "2.2.1 Command Interpreters"
        },
        {
            "location": "/OS/Chap02/#222-graphical-user-interfaces",
            "text": "desktop  icons  folder  mouse  gestures on the touchscreen",
            "title": "2.2.2 Graphical User Interfaces"
        },
        {
            "location": "/OS/Chap02/#223-choice-of-interface",
            "text": "shell scripts  e.g.  UNIX  and  Linux .",
            "title": "2.2.3 Choice of Interface"
        },
        {
            "location": "/OS/Chap02/#23-systems-calls",
            "text": "System calls provide an interface to the services made available by an operating system.  e.g. writing a simple program to read data from one file and copy them to another file causes a lot of system calls!   C/C++   Each read and write must return status information regarding various possible error conditions.   application programming interface (API): it specifies a set of functions  Windows API  POSIX API  UNIX  Linux  macOS    Java API     libc : UNIX and Linux for programs written in C  Why prefer API rather than invoking actual system calls?   protability (expected to run on any system)  actual system calls can be more difficult to learn   The relationship between an  API , the  system-call interface , and the  OS  \b  The caller need know nothing about how the system call is implemented or what it does during execution. Rather, the caller need only obey the API and understand what the operating system will do as a result of the execution of that system call.  Make explicit to implicit .  Three general methods are used to pass parameters to the operating system.    through registers (Linux and Solaris)   block,  table,   memory,   and the address of the     placed or pushed onto the stack $\\to$ popped off the stack by the OS",
            "title": "2.3 Systems Calls"
        },
        {
            "location": "/OS/Chap02/#24-types-of-system-calls",
            "text": "",
            "title": "2.4 Types of System Calls"
        },
        {
            "location": "/OS/Chap02/#241-process-control",
            "text": "A running program halts either   normally:  end()  abnormally:  abort()   error $\\to$ dump (written to disk, may be examined by a debugger)  More severe errors can be indicated by a higher-level error parameter.  e.g. Standard C Library",
            "title": "2.4.1 Process Control"
        },
        {
            "location": "/OS/Chap02/#242-file-management",
            "text": "",
            "title": "2.4.2 File Management"
        },
        {
            "location": "/OS/Chap02/#243-device-management",
            "text": "",
            "title": "2.4.3 Device Management"
        },
        {
            "location": "/OS/Chap02/#244-information-maintenance",
            "text": "Many systems provide system calls to  dump()  memory. This provision is useful for debugging. A program trace lists each system call as it is executed. Even microprocessors provide a CPU mode known as single step, in which a trap is executed by the CPU after every instruction. The trap is usually caught by a debugger.",
            "title": "2.4.4 Information Maintenance"
        },
        {
            "location": "/OS/Chap02/#245-communication",
            "text": "",
            "title": "2.4.5 Communication"
        },
        {
            "location": "/OS/Chap02/#246-protection",
            "text": "",
            "title": "2.4.6 Protection"
        },
        {
            "location": "/OS/Chap02/#25-system-programs",
            "text": "",
            "title": "2.5 System Programs"
        },
        {
            "location": "/OS/Chap02/#26-operating-system-design-and-implementation",
            "text": "",
            "title": "2.6 Operating-System Design and Implementation"
        },
        {
            "location": "/OS/Chap02/#261-design-goals",
            "text": "",
            "title": "2.6.1 Design Goals"
        },
        {
            "location": "/OS/Chap02/#262-mechanisms-and-policies",
            "text": "",
            "title": "2.6.2 Mechanisms and Policies"
        },
        {
            "location": "/OS/Chap02/#263-implementation",
            "text": "",
            "title": "2.6.3 Implementation"
        },
        {
            "location": "/OS/Chap03/",
            "text": "Chapter 3 Process Concept\n\u00b6\n\n\n3.1 Process Concept\n\u00b6\n\n\n\n\nProcess\n\n\nA program in execution, the basis of all computation.\n\n\n\n\n\n\nBatch system: jobs (= process)\n\n\nTime-shared system: user programs or tasks\n\n\n\n\n3.1.1 The process\n\u00b6\n\n\nProcess consists\n\n\n\n\ntext\n section: program code\n\n\ndata\n section: \nglobal variables\n\n\nheap\n: memory\n\n\ncurrent activity (\nprogram counter\n + \nregisters\n)\n\n\n\bstack\n: \ntemporary data\n:\n\n\nfunction parameters\n\n\nreturn addresses\n\n\n\n\nlocal variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgram\n\n\nProcess\n\n\n\n\n\n\n\n\n\n\npassive\n entity\n\n\nactive\n entity\n\n\n\n\n\n\na file containing a list of instructions stored on disk (executable file)\n\n\nprogram counter: specifying the next instruction to execute + a set of associated resources\n\n\n\n\n\n\n\n\nWhen\n\n\n\n\ndouble-clicking an icon\n\n\nprog.exe\n\n\na.out\n\n\n\n\nan executable file is loaded into memory: \nprogram $\\to$ process\n.\n\n\nTwo different processes: the text section are equivalent, the data, heap and stack vary.\n\n\nProcess can be an execution environment for other code. (\nsimulation\n)\n\n\ne.g.\n\n\n    \njava\n \ntestProgram\n\n\n\n\n\n\n\nThe command \njava\n runs the JVM as an ordinary process, then executes the Java program \ntestProgram\n in the VM.\n\n\n\n\n3.1.2 Process State\n\u00b6\n\n\n\n\nNew\n\n\nRunning\n: execute instructions\n\n\nWaiting\n: wait some event (I/O, signal)\n\n\nReady\n: wait to be assigned to a processor\n\n\nTerminated\n\n\n\n\n\n\n\n\nProcess and Processor\n\n\nOnly \n1\n process runs on any processor. (Many processes may be \nready\n and \nwaiting\n)\n\n\n\n\n3.1.3 Process Control Block\n\u00b6\n\n\n\n\nProcess state\n\n\nProgram counter\n: address of the next instruction\n\n\nCPU registers\n: accumulators, index registers, stack pointers, general-purpose registers, and any condition-code information\n\n\nCPU-scheduling information\n\n\nMemory-management information\n\n\nAccounting information\n: the amount of CPU and real time used, time limits, account numbers, job or process numbers\n\n\nI/O status information\n: the list of I/O devices allocated to the process, a list of open files\n\n\n\n\n\n\n3.2 Process Scheduling\n\u00b6\n\n\n\n\nMultiprogramming\n: to have some process running at all times $\\to$ maximize CPU utilization\n\n\nTime sharing\n: switch the CPU among processes\n\n\nProcess scheduler\n: selects an available process\n\n\n\n\n3.2.1 Scheduling Queues\n\u00b6\n\n\nAs processes enter the system, they are put into a \njob queue\n.\n\n\n\n\nJob queue\n: consists of all processes in the system.\n\n\nReady queue\n: keep \nready\n and \nwaiting\n processes.\n\n\n\n\n\n\n\n\nWhen a process exit, it is removed from all queues and has its PCB and resources deallocated.\n\n\n3.2.2 Schedulers\n\u00b6\n\n\nProcesses are first spooled to a mass-storage device (e.g. disk). Then \n\n\n\n\n\n\nLong-term scheduler\n (job)\n\n\n\n\nselects processes from this pool\n\n\nloads them into memory \nfor\n execution\n\n\n\n\n\n\n\n\nShort-term scheduler\n (CPU)\n\n\n\n\nselects from among the processes that are ready to execute\n\n\nallocates CPU to one of them\n\n\n\n\n\n\n\n\n\n\nLong-term scheduler\n\n\n\n\nControls the \ndegree of multiprogramming\n (# processes)\n\n\nSelects a good \nprocess mix\n of I/O-bound and CPU-bound\n\n\n\n\n\n\n\n\nMedium-term scheduler\n\n\nSwapping\n\n\n\n\n\n\n3.2.3 Context Switch\n\u00b6\n\n\n\n\nWhen a context switch occurs\n\n\nThe kernel saves the context of the old process in its PCB and loads the saved context of the new process scheduled to run.\n\n\n\n\n3.3 Operations on Processes\n\u00b6\n\n\n3.3.1 Process Creation\n\u00b6\n\n\n\n\nProcess Identifier (pid)\n\n\nAn integer number, which provides a unique value for each process in the system, and it can be used as an \nindex\n to access various attributes of a process within the kernel.\n\n\n\n\n\n\ninit process\n\n\nA process has pid = 1, and serves as the root parent process for all user processes.\n\n\n\n\n\n\nWhen a process creates a child process, that child process may obtain the resources from\n\n\n\n\nOS\n\n\na subset of parent process\n\n\n\n\nWhen a process creates a new process\n\n\n\n\nThe parent continues to execute concurrently with its children.\n\n\nThe parent waits until some or all of its children have terminated.\n\n\n\n\nThere are also two address-space possibilities for the new process\n\n\n\n\nThe child process is a duplicate of the parent process (it has the same program and data as the parent).\n\n\nThe child process has a new program loaded into it.\n\n\n\n\n\n\nfork()\n\n\nThe new process created by \nfork()\n consists of a copy of the address of parent process.\n\n\n\n\n\n\n\n\nReturn code\n\n\n\n\nChild process: 0\n\n\nParent process: pid of the child\n\n\n\n\n\n\n\n\n\n\nAfter \nfork()\n syscall\n\n\nOne of the two processes uses the \nexec()\n syscall to replace the process's memory space with a new program.\n\n\n\n\nCreating a separate process using the UNIX \nfork()\n system call.\n\n\nint\n \nmain\n()\n \n{\n \n    \npid_t\n \npid\n;\n\n\n    \n/* fork a child process */\n\n    \npid\n \n=\n \nfork\n();\n\n    \nif\n \n(\npid\n \n<\n \n0\n)\n \n{\n                      \n/* error occurred */\n\n        \nfprintf\n(\nstderr\n,\n \n\"Fork Failed\"\n);\n\n        \nreturn\n \n1\n;\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n              \n/* child process */\n\n        \nexeclp\n(\n\"/bin/ls\"\n,\n \n\"ls\"\n,\n \nNULL\n);\n  \n/* a version of the `exec()` */\n\n    \n}\n \nelse\n \n{\n                            \n/* parent process */\n\n        \n/* parent will wait for the child to complete */\n\n        \nwait\n(\nNULL\n);\n\n        \nprintf\n(\n\"Child Complete\"\n);\n\n    \n}\n\n    \nreturn\n \n0\n;\n\n\n}\n\n\n\n\n\n\n3.3.2 Process Termination\n\u00b6\n\n\nA process terminates when it finishes executing its final statement and asks the operating system to delete it by using the \nexit()\n system call.\n\n\n\n\nTerminating process\n\n\nA parent needs to know the identities of its children if it is to terminate them.\n\n\n\n\nA parent can terminate its children by\n\n\n\n\nThe child use too much resources. (The parent have a mechanism to inspect the state of its children)\n\n\nThe task assigned to the child is no longer required.\n\n\nThe parent is exiting.\n\n\n\n\n\n\nCascading Termination\n\n\nIf a process terminates (either normally or abnormally), then all its children must also be terminated.\n\n\n\n\nexit()\n may be called either directly or indirectly (\nreturn\n):\n\n\n    \nexit\n(\n1\n);\n    \n/* directly exit with status 1 */\n\n\n\n\n\n\n\nProcess Table Entry (PTE)\n\n\nContains the process's exit status.\n\n\n\n\n\n\nZombie\n\n\nA process terminated, but whose parent hasn't called \nwait()\n. Once the parent calls \nwait()\n, the pid of the zombie process and its entry in the PTE are released.\n\n\n\n\nThe \ninit\n process periodically invokes \nwait()\n to collect and release the orphan's pid and PTE.\n\n\n3.4 Interprocess Communication\n\u00b6\n\n\nProcesses have two classifications:\n\n\n\n\nIndependent\n\n\nCooperating\n\n\nInformation sharing\n\n\nComputation speedup - multicore\n\n\nModularity\n\n\nConvenience - parallel tasks\n\n\n\n\n\n\n\n\nInterprocess communication (IPC)\n\n\n\n\nShared memory: slower (syscalls are required)\n\n\nMessage passing: faster (syscalls are required only to establish shared memory regions)\n\n\n\n\n\n\n3.4.1 Shared-Memory Systems\n\u00b6\n\n\nProducer\u2013consumer problem\n\u00b6\n\n\nA \nproducer\n process produces information that is consumed by a \nconsumer\n process.\n\n\ne.g.\n\n\n\n\nA compiler produce assembly code that is consumed by an assembler. The assembler, in turn, may produce object modules that are consumed by the loader.\n\n\nA server as a producer and a client as a consumer.\n\n\n\n\nWe need a buffer which resides in a region of shared memory (producer & consumer), and can be filled by the producer and emptied by the consumer.\n\n\n\n\nUnbounded buffer\n\n\nBounded buffer (more practical)\n\n\n\n\nImplement the shared \nbuffer\n as a circular array.\n\n#define BUFFER_SIZE 10\n\n\n\ntypedef\n \nstruct\n \n{\n\n    \n...\n\n\n}\n \nitem\n;\n\n\n\nitem\n \nbuffer\n[\nBUFFER_SIZE\n];\n\n\nint\n \nin\n \n=\n \n0\n;\n     \n/* points to the next free position */\n\n\nint\n \nout\n \n=\n \n0\n;\n    \n/* points to the first full position */\n\n\n\n\nwhile\n \n(\ntrue\n)\n \n{\n\n    \n/* produce an item in next_produced */\n\n\n    \nwhile\n \n(((\nin\n \n+\n \n1\n)\n \n%\n \nBUFFER_SIZE\n)\n \n==\n \nout\n)\n\n        \n;\n \n/* do nothing */\n\n\n    \nbuffer\n[\nin\n]\n \n=\n \nnext_produced\n;\n\n    \nin\n \n=\n \n(\nin\n \n+\n \n1\n)\n \n%\n \nBUFFER_SIZE\n;\n\n\n}\n\n\n\n\n\nitem\n \nnext_consumed\n;\n\n\n\nwhile\n \n(\ntrue\n)\n \n{\n\n    \nwhile\n \n(\nin\n \n==\n \nout\n)\n\n        \n;\n \n/* do nothing */\n\n\n        \nnext_consumed\n \n=\n \nbuffer\n[\nout\n];\n\n        \nout\n \n=\n \n(\nout\n \n+\n \n1\n)\n \n%\n \nBUFFER_SIZE\n;\n\n\n        \n/* consume the item in next_consumed */\n\n\n}\n\n\n\n\n\n3.4.2 Message-Passing Systems\n\u00b6\n\n\nMessage passing provides a mechanism to allow processes to communicate and to synchronize their actions \nwithout sharing the same address space\n.\n\n\n\n\nCommunication link\n\n\nIf processes $P$ and $Q$ want to communicate, they must send messages to and receive messages from each other.\n\n\n\n\nSeveral implentation of \nsend()\n/\nreceive()\n operations:\n\n\n\n\nDirect of indirect communication\n\n\nSynchronous or asynchronous communication\n\n\nAutomatic or explicit buffering\n\n\n\n\n3.4.2.1 Naming\n\u00b6\n\n\n\n\n\n\nDirect communication\n\n\nThe messages are sent to and received from processes.\n\n\n\n\n\n\nSymmetry\n\n\n\n\nsend(P, message)\n\n\nreceive(Q, message)\n\n\n\n\n\n\n\n\nAsymmetry\n\n\n\n\nsend(P, message)\n\n\nreceive(id, message)\n\n\n\n\n\n\n\n\n\n\n\n\nIndirect communication\n\n\nThe messages are sent to and received from \nmailboxes\n, or \nports\n.\n\n\n\n\nsend(A, message)\n \u2014 send a message to mailbox A\n\n\nreceive(A, message)\n \u2014 receive a message from mailbox A\n\n\n\n\n\n\n\n\nThe process that creates a new mailbox is that mailbox's owner by default.\n\n\n\n\nA mailbox can be owned by the OS.\n\n\n\n\n3.4.2.2 Synchronization\n\u00b6\n\n\nMessage passing may be either\n\n\n\n\n\n\nBlocking (synchronous)\n\n\n\n\nBlocking send (blocked until the message is received)\n\n\nBlocking receive\n\n\n\n\n\n\n\n\nNonblocking (asynchronous)\n\n\n\n\nNonblocking send\n\n\nNonblocking receive (valid message or a null)\n\n\n\n\n\n\n\n\n\n\nRendezvous\n\n\nWhen both \nsend()\n and \nreceive()\n are blocking.\n\n\n\n\n3.4.2.3 Buffering\n\u00b6\n\n\nMessages reside in a temporary queue:\n\n\n\n\nZero capacity (no buffering)\n\n\nBounded capacity\n\n\nUnbounded capacity\n\n\n\n\n3.5 Examples of IPC Systems\n\u00b6\n\n\n3.5.1 An Example: POSIX Shared Memory\n\u00b6\n\n\nmessage\n \nnext_consumed\n;\n\n\n\nwhile\n \n(\ntrue\n)\n \n{\n\n    \nreceive\n(\nnext_consumed\n);\n\n\n    \n/* consume the item in next consumed */\n\n\n}\n\n\n\n\n\nA process must first create a shared-memory:\n\n\n    \nshm_fd\n \n=\n \nshm_open\n(\nname\n,\n \nO_CREAT\n \n|\n \nO_RDRW\n,\n \n0666\n);\n\n\n\n\n\nThe \nftruncate()\n function configure the size of the object in bytes:\n\n\n    \nftruncate\n(\nshm_fd\n,\n \n4096\n);\n\n\n\n\n\n3.5.2 An Example: Mach\n\u00b6\n\n\nEven system calls are made by messages. When a task is created, two special mailboxes\n\n\n\n\nkernel mailbox\n\n\nnotify mailbox\n\n\n\n\nare also created.\n\n\nThere are three syscalls needed:\n\n\n\n\n\n\nmsg_send()\n\n\nIf the mailbox is full:\n\n\n\n\nWait indefinitely until there is room in the mailbox\n\n\nWait at most $n$ milliseconds\n\n\nDo not wait at all but rather return immediately\n\n\nTemporarily cache a message (server tasks)\n\n\n\n\n\n\n\n\nmsg_receive()\n\n\n\n\nmsg_rpc()\n: sends a message and waits for exactly one return message from the sender.\n\n\n\n\n\n\nRemote\n\n\nThe RPC (Remote Procedure Call) models a typical subroutine procedure call but can work between systems.\n\n\n\n\n\n\nport_allocate()\n\n\nCreates a new mailbox and allocates space for its queue of messages.\n\n\n\n\nMach guarantees that multiple messages from the same sender are queued in first-in, first-out (FIFO) order but does not guarantee an absolute ordering\n\n\n\n\nOne task can either own or receive from a mailbox\n\n\n\n\n\n\nMailbox set\n\n\nA collection of mailboxes.\n\n\n\n\n\n\nport_status()\n\n\ne.g. # of messages in a mailbox.\n\n\n\n\n3.5.3 An Example: Windows\n\u00b6\n\n\nApplication programs can be considered clients of a subsystem server.\n\n\n\n\nAdvanced Local Procedure Call (ALPC)\n\n\nIt is used for communication between two processes \non the same machine\n.\n\n\n\n\nWindows uses two types of ports\n\n\n\n\nConnection ports\n\n\nCommunication ports\n\n\n\n\n\n\nCallback\n\n\nAllows the client and server to accept requests when they would normally be expecting a reply.\n\n\n\n\nWhen an ALPC channel is created, 1 of 3 message-passing techniques is chosen:\n\n\n\n\nSmall messages: using the port's message queue.\n\n\nLarger messages: passed through a \nsection object\n (a region of shared memory)\n\n\nVery large messages: calling API to read/write directly into the address space.\n\n\n\n\n\n\n3.6 Communication in Client\u2013Server Systems\n\u00b6\n\n\n3.6.1 Sockets\n\u00b6\n\n\n\n\nSocket\n\n\nAn endpoint for communication. (IP + port#)\n\n\n\n\nA pair of processes communicating over a network employs \na pair\n of sockets\u2014one for each process.\n\n\n\n\nSocket behavior\n\n\nThe server waits for incoming client requests by listening to a specified port. Once a request is received, the server accepts a connection from the client socket to complete the connection.\n\n\n\n\nWell-known ports: (all ports below 1024 are considered well known)\n\n\n\n\n23: telnet\n\n\n21: FTP\n\n\n80: HTTP\n\n\n\n\n\n\nJava provides:\n\n\n\n\nConnection-oriented (TCP) sockets: \nSocket\n\n\nConnectionless (UDP) sockets: \nDatagramSocket\n\n\nMulticastSocket\n: a subclass of \nDatagramSocket\n. It allows data to be sent to multiple recipients.\n\n\n\n\n\n\nLoopback\n\n\nIP address 127.0.0.1.\n\n\n\n\n3.6.2 Remote Procedure Calls\n\u00b6\n\n\nThe RPC was designed as a way to abstract the procedure-call mechanism for use between systems with network connections.\n\n\nEach message is addressed to an RPC daemon listening to a port on the remote system, and each contains an identifier specifying the function to execute and the parameters to pass to that function.\n\n\n\n\nThe semantics of RPCs allows a client to invoke a procedure on a remote host as it would invoke a procedure locally.\n\n\n\n\n\n\nStub\n\n\nThe RPC system hides the details that allow communication to take place by providing a stub on the client side.\n\n\n\n\n\n\nParameter marshalling\n\n\nPackaging the parameters into a form that can be transmitted over a network.\n\n\n\n\nProcedure of RPCs:\n\n\n\n\nThe client invokes a RPC\n\n\nRPC system\n\n\ncalls the appropriate stub (client side)\n\n\npasses the stub the parameters to the RPC\n\n\n\n\n\n\nMarshals parameter: packaging the parameters into a form that can be transmitted over a network\n\n\nThe stub transmits a message to the server using message passing.\n\n\nA stub (server side) \n\n\nreceives this message\n\n\ninvokes the procedure on the server\n\n\n\n\n\n\n(optional) Return values using the same technique\n\n\n\n\nIssues for RPC:\n\n\n\n\nData representation\n\n\nExternal Data Representation (XDR)\n\n\nParameter marshalling\n\n\n\n\n\n\n\n\n\n\nSemantics of a call\n\n\nat most once\n\n\nexactly once (ACK)\n\n\n\n\n\n\nBinding of the client and server port\n\n\nMatchmaker (a rendezvous mechanism)\n\n\n\n\n\n\n\n\n\n\n3.6.3 Pipes\n\u00b6\n\n\nIn implementing a pipe, four issues:\n\n\n\n\nDoes the pipe allow bidirectional communication, or is communication unidirectional?\n\n\nIf two-way communication is allowed, is it half duplex (data can travel only one way at a time) or full duplex (data can travel in both directions at the same time)?\n\n\nMust a relationship (such as parent\u2013child) exist between the communicating processes?\n\n\nCan the pipes communicate over a network, or must the communicating processes reside on the same machine?\n\n\n\n\n3.6.3.1 Ordinary Pipes\n\u00b6\n\n\n    \npipe\n(\nint\n \nfd\n[])\n\n\n\n\n\n\n\nOrdinarya pipes on on Windows: \nanonymous pipes\n (similar to UNIX)\n\n\n3.6.3.2 Named Pipes\n\u00b6\n\n\n\n\n\n\n\n\nOrdinary Pipes\n\n\nNamed Pipes\n\n\n\n\n\n\n\n\n\n\nunidirectional\n\n\nbidirectional\n\n\n\n\n\n\nparent-child required\n\n\nnot required\n\n\n\n\n\n\n\n\n\n\nIn UNIX, named pipes = FIFOs. A FIFO is created with the \nmkfifo()\n.\n\n\n\n\nPipes in practice:\n\n\n \n# In this scenario, the ls command serves as the producer, and its output is consumed by the more command.\n\n $ ls \n|\n more",
            "title": "Chapter 3 Processes"
        },
        {
            "location": "/OS/Chap03/#chapter-3-process-concept",
            "text": "",
            "title": "Chapter 3 Process Concept"
        },
        {
            "location": "/OS/Chap03/#31-process-concept",
            "text": "Process  A program in execution, the basis of all computation.    Batch system: jobs (= process)  Time-shared system: user programs or tasks",
            "title": "3.1 Process Concept"
        },
        {
            "location": "/OS/Chap03/#311-the-process",
            "text": "Process consists   text  section: program code  data  section:  global variables  heap : memory  current activity ( program counter  +  registers )  \bstack :  temporary data :  function parameters  return addresses   local variables          Program  Process      passive  entity  active  entity    a file containing a list of instructions stored on disk (executable file)  program counter: specifying the next instruction to execute + a set of associated resources     When   double-clicking an icon  prog.exe  a.out   an executable file is loaded into memory:  program $\\to$ process .  Two different processes: the text section are equivalent, the data, heap and stack vary.  Process can be an execution environment for other code. ( simulation )  e.g.       java   testProgram    The command  java  runs the JVM as an ordinary process, then executes the Java program  testProgram  in the VM.",
            "title": "3.1.1 The process"
        },
        {
            "location": "/OS/Chap03/#312-process-state",
            "text": "New  Running : execute instructions  Waiting : wait some event (I/O, signal)  Ready : wait to be assigned to a processor  Terminated     Process and Processor  Only  1  process runs on any processor. (Many processes may be  ready  and  waiting )",
            "title": "3.1.2 Process State"
        },
        {
            "location": "/OS/Chap03/#313-process-control-block",
            "text": "Process state  Program counter : address of the next instruction  CPU registers : accumulators, index registers, stack pointers, general-purpose registers, and any condition-code information  CPU-scheduling information  Memory-management information  Accounting information : the amount of CPU and real time used, time limits, account numbers, job or process numbers  I/O status information : the list of I/O devices allocated to the process, a list of open files",
            "title": "3.1.3 Process Control Block"
        },
        {
            "location": "/OS/Chap03/#32-process-scheduling",
            "text": "Multiprogramming : to have some process running at all times $\\to$ maximize CPU utilization  Time sharing : switch the CPU among processes  Process scheduler : selects an available process",
            "title": "3.2 Process Scheduling"
        },
        {
            "location": "/OS/Chap03/#321-scheduling-queues",
            "text": "As processes enter the system, they are put into a  job queue .   Job queue : consists of all processes in the system.  Ready queue : keep  ready  and  waiting  processes.     When a process exit, it is removed from all queues and has its PCB and resources deallocated.",
            "title": "3.2.1 Scheduling Queues"
        },
        {
            "location": "/OS/Chap03/#322-schedulers",
            "text": "Processes are first spooled to a mass-storage device (e.g. disk). Then     Long-term scheduler  (job)   selects processes from this pool  loads them into memory  for  execution     Short-term scheduler  (CPU)   selects from among the processes that are ready to execute  allocates CPU to one of them      Long-term scheduler   Controls the  degree of multiprogramming  (# processes)  Selects a good  process mix  of I/O-bound and CPU-bound     Medium-term scheduler  Swapping",
            "title": "3.2.2 Schedulers"
        },
        {
            "location": "/OS/Chap03/#323-context-switch",
            "text": "When a context switch occurs  The kernel saves the context of the old process in its PCB and loads the saved context of the new process scheduled to run.",
            "title": "3.2.3 Context Switch"
        },
        {
            "location": "/OS/Chap03/#33-operations-on-processes",
            "text": "",
            "title": "3.3 Operations on Processes"
        },
        {
            "location": "/OS/Chap03/#331-process-creation",
            "text": "Process Identifier (pid)  An integer number, which provides a unique value for each process in the system, and it can be used as an  index  to access various attributes of a process within the kernel.    init process  A process has pid = 1, and serves as the root parent process for all user processes.    When a process creates a child process, that child process may obtain the resources from   OS  a subset of parent process   When a process creates a new process   The parent continues to execute concurrently with its children.  The parent waits until some or all of its children have terminated.   There are also two address-space possibilities for the new process   The child process is a duplicate of the parent process (it has the same program and data as the parent).  The child process has a new program loaded into it.    fork()  The new process created by  fork()  consists of a copy of the address of parent process.     Return code   Child process: 0  Parent process: pid of the child      After  fork()  syscall  One of the two processes uses the  exec()  syscall to replace the process's memory space with a new program.   Creating a separate process using the UNIX  fork()  system call.  int   main ()   {  \n     pid_t   pid ; \n\n     /* fork a child process */ \n     pid   =   fork (); \n     if   ( pid   <   0 )   {                        /* error occurred */ \n         fprintf ( stderr ,   \"Fork Failed\" ); \n         return   1 ; \n     }   else   if   ( pid   ==   0 )   {                /* child process */ \n         execlp ( \"/bin/ls\" ,   \"ls\" ,   NULL );    /* a version of the `exec()` */ \n     }   else   {                              /* parent process */ \n         /* parent will wait for the child to complete */ \n         wait ( NULL ); \n         printf ( \"Child Complete\" ); \n     } \n     return   0 ;  }",
            "title": "3.3.1 Process Creation"
        },
        {
            "location": "/OS/Chap03/#332-process-termination",
            "text": "A process terminates when it finishes executing its final statement and asks the operating system to delete it by using the  exit()  system call.   Terminating process  A parent needs to know the identities of its children if it is to terminate them.   A parent can terminate its children by   The child use too much resources. (The parent have a mechanism to inspect the state of its children)  The task assigned to the child is no longer required.  The parent is exiting.    Cascading Termination  If a process terminates (either normally or abnormally), then all its children must also be terminated.   exit()  may be called either directly or indirectly ( return ):       exit ( 1 );      /* directly exit with status 1 */    Process Table Entry (PTE)  Contains the process's exit status.    Zombie  A process terminated, but whose parent hasn't called  wait() . Once the parent calls  wait() , the pid of the zombie process and its entry in the PTE are released.   The  init  process periodically invokes  wait()  to collect and release the orphan's pid and PTE.",
            "title": "3.3.2 Process Termination"
        },
        {
            "location": "/OS/Chap03/#34-interprocess-communication",
            "text": "Processes have two classifications:   Independent  Cooperating  Information sharing  Computation speedup - multicore  Modularity  Convenience - parallel tasks     Interprocess communication (IPC)   Shared memory: slower (syscalls are required)  Message passing: faster (syscalls are required only to establish shared memory regions)",
            "title": "3.4 Interprocess Communication"
        },
        {
            "location": "/OS/Chap03/#341-shared-memory-systems",
            "text": "",
            "title": "3.4.1 Shared-Memory Systems"
        },
        {
            "location": "/OS/Chap03/#producerconsumer-problem",
            "text": "A  producer  process produces information that is consumed by a  consumer  process.  e.g.   A compiler produce assembly code that is consumed by an assembler. The assembler, in turn, may produce object modules that are consumed by the loader.  A server as a producer and a client as a consumer.   We need a buffer which resides in a region of shared memory (producer & consumer), and can be filled by the producer and emptied by the consumer.   Unbounded buffer  Bounded buffer (more practical)   Implement the shared  buffer  as a circular array. #define BUFFER_SIZE 10  typedef   struct   { \n     ...  }   item ;  item   buffer [ BUFFER_SIZE ];  int   in   =   0 ;       /* points to the next free position */  int   out   =   0 ;      /* points to the first full position */   while   ( true )   { \n     /* produce an item in next_produced */ \n\n     while   ((( in   +   1 )   %   BUFFER_SIZE )   ==   out ) \n         ;   /* do nothing */ \n\n     buffer [ in ]   =   next_produced ; \n     in   =   ( in   +   1 )   %   BUFFER_SIZE ;  }   item   next_consumed ;  while   ( true )   { \n     while   ( in   ==   out ) \n         ;   /* do nothing */ \n\n         next_consumed   =   buffer [ out ]; \n         out   =   ( out   +   1 )   %   BUFFER_SIZE ; \n\n         /* consume the item in next_consumed */  }",
            "title": "Producer\u2013consumer problem"
        },
        {
            "location": "/OS/Chap03/#342-message-passing-systems",
            "text": "Message passing provides a mechanism to allow processes to communicate and to synchronize their actions  without sharing the same address space .   Communication link  If processes $P$ and $Q$ want to communicate, they must send messages to and receive messages from each other.   Several implentation of  send() / receive()  operations:   Direct of indirect communication  Synchronous or asynchronous communication  Automatic or explicit buffering",
            "title": "3.4.2 Message-Passing Systems"
        },
        {
            "location": "/OS/Chap03/#3421-naming",
            "text": "Direct communication  The messages are sent to and received from processes.    Symmetry   send(P, message)  receive(Q, message)     Asymmetry   send(P, message)  receive(id, message)       Indirect communication  The messages are sent to and received from  mailboxes , or  ports .   send(A, message)  \u2014 send a message to mailbox A  receive(A, message)  \u2014 receive a message from mailbox A     The process that creates a new mailbox is that mailbox's owner by default.   A mailbox can be owned by the OS.",
            "title": "3.4.2.1 Naming"
        },
        {
            "location": "/OS/Chap03/#3422-synchronization",
            "text": "Message passing may be either    Blocking (synchronous)   Blocking send (blocked until the message is received)  Blocking receive     Nonblocking (asynchronous)   Nonblocking send  Nonblocking receive (valid message or a null)      Rendezvous  When both  send()  and  receive()  are blocking.",
            "title": "3.4.2.2 Synchronization"
        },
        {
            "location": "/OS/Chap03/#3423-buffering",
            "text": "Messages reside in a temporary queue:   Zero capacity (no buffering)  Bounded capacity  Unbounded capacity",
            "title": "3.4.2.3 Buffering"
        },
        {
            "location": "/OS/Chap03/#35-examples-of-ipc-systems",
            "text": "",
            "title": "3.5 Examples of IPC Systems"
        },
        {
            "location": "/OS/Chap03/#351-an-example-posix-shared-memory",
            "text": "message   next_consumed ;  while   ( true )   { \n     receive ( next_consumed ); \n\n     /* consume the item in next consumed */  }   A process must first create a shared-memory:       shm_fd   =   shm_open ( name ,   O_CREAT   |   O_RDRW ,   0666 );   The  ftruncate()  function configure the size of the object in bytes:       ftruncate ( shm_fd ,   4096 );",
            "title": "3.5.1 An Example: POSIX Shared Memory"
        },
        {
            "location": "/OS/Chap03/#352-an-example-mach",
            "text": "Even system calls are made by messages. When a task is created, two special mailboxes   kernel mailbox  notify mailbox   are also created.  There are three syscalls needed:    msg_send()  If the mailbox is full:   Wait indefinitely until there is room in the mailbox  Wait at most $n$ milliseconds  Do not wait at all but rather return immediately  Temporarily cache a message (server tasks)     msg_receive()   msg_rpc() : sends a message and waits for exactly one return message from the sender.    Remote  The RPC (Remote Procedure Call) models a typical subroutine procedure call but can work between systems.    port_allocate()  Creates a new mailbox and allocates space for its queue of messages.   Mach guarantees that multiple messages from the same sender are queued in first-in, first-out (FIFO) order but does not guarantee an absolute ordering   One task can either own or receive from a mailbox    Mailbox set  A collection of mailboxes.    port_status()  e.g. # of messages in a mailbox.",
            "title": "3.5.2 An Example: Mach"
        },
        {
            "location": "/OS/Chap03/#353-an-example-windows",
            "text": "Application programs can be considered clients of a subsystem server.   Advanced Local Procedure Call (ALPC)  It is used for communication between two processes  on the same machine .   Windows uses two types of ports   Connection ports  Communication ports    Callback  Allows the client and server to accept requests when they would normally be expecting a reply.   When an ALPC channel is created, 1 of 3 message-passing techniques is chosen:   Small messages: using the port's message queue.  Larger messages: passed through a  section object  (a region of shared memory)  Very large messages: calling API to read/write directly into the address space.",
            "title": "3.5.3 An Example: Windows"
        },
        {
            "location": "/OS/Chap03/#36-communication-in-clientserver-systems",
            "text": "",
            "title": "3.6 Communication in Client\u2013Server Systems"
        },
        {
            "location": "/OS/Chap03/#361-sockets",
            "text": "Socket  An endpoint for communication. (IP + port#)   A pair of processes communicating over a network employs  a pair  of sockets\u2014one for each process.   Socket behavior  The server waits for incoming client requests by listening to a specified port. Once a request is received, the server accepts a connection from the client socket to complete the connection.   Well-known ports: (all ports below 1024 are considered well known)   23: telnet  21: FTP  80: HTTP    Java provides:   Connection-oriented (TCP) sockets:  Socket  Connectionless (UDP) sockets:  DatagramSocket  MulticastSocket : a subclass of  DatagramSocket . It allows data to be sent to multiple recipients.    Loopback  IP address 127.0.0.1.",
            "title": "3.6.1 Sockets"
        },
        {
            "location": "/OS/Chap03/#362-remote-procedure-calls",
            "text": "The RPC was designed as a way to abstract the procedure-call mechanism for use between systems with network connections.  Each message is addressed to an RPC daemon listening to a port on the remote system, and each contains an identifier specifying the function to execute and the parameters to pass to that function.   The semantics of RPCs allows a client to invoke a procedure on a remote host as it would invoke a procedure locally.    Stub  The RPC system hides the details that allow communication to take place by providing a stub on the client side.    Parameter marshalling  Packaging the parameters into a form that can be transmitted over a network.   Procedure of RPCs:   The client invokes a RPC  RPC system  calls the appropriate stub (client side)  passes the stub the parameters to the RPC    Marshals parameter: packaging the parameters into a form that can be transmitted over a network  The stub transmits a message to the server using message passing.  A stub (server side)   receives this message  invokes the procedure on the server    (optional) Return values using the same technique   Issues for RPC:   Data representation  External Data Representation (XDR)  Parameter marshalling      Semantics of a call  at most once  exactly once (ACK)    Binding of the client and server port  Matchmaker (a rendezvous mechanism)",
            "title": "3.6.2 Remote Procedure Calls"
        },
        {
            "location": "/OS/Chap03/#363-pipes",
            "text": "In implementing a pipe, four issues:   Does the pipe allow bidirectional communication, or is communication unidirectional?  If two-way communication is allowed, is it half duplex (data can travel only one way at a time) or full duplex (data can travel in both directions at the same time)?  Must a relationship (such as parent\u2013child) exist between the communicating processes?  Can the pipes communicate over a network, or must the communicating processes reside on the same machine?",
            "title": "3.6.3 Pipes"
        },
        {
            "location": "/OS/Chap03/#3631-ordinary-pipes",
            "text": "pipe ( int   fd [])    Ordinarya pipes on on Windows:  anonymous pipes  (similar to UNIX)",
            "title": "3.6.3.1 Ordinary Pipes"
        },
        {
            "location": "/OS/Chap03/#3632-named-pipes",
            "text": "Ordinary Pipes  Named Pipes      unidirectional  bidirectional    parent-child required  not required      In UNIX, named pipes = FIFOs. A FIFO is created with the  mkfifo() .   Pipes in practice:    # In this scenario, the ls command serves as the producer, and its output is consumed by the more command. \n $ ls  |  more",
            "title": "3.6.3.2 Named Pipes"
        },
        {
            "location": "/OS/Chap04/",
            "text": "Chapter 4 Threads\n\u00b6\n\n\n4.1 Overview\n\u00b6\n\n\n\n\nThread\u2013Lightweight process (LWP)\n\n\nA basit unit of CPU utilization.\n\n\n\n\nA thread shares\n\n\n\n\ncode section\n\n\ndata section\n\n\nOS resources (e.g. open files and signals) \n\n\n\n\nA thread have its own\n\n\n\n\nthread ID\n\n\nprogram counter\n\n\nregister set\n\n\nstack\n\n\n\n\n\n\n4.1.1 Motivation\n\u00b6\n\n\nIt is generally more efficient to use one process that contains multiple threads since process creation is time consuming and resource intensive.\n\n\n\n\n4.1.2 Benefits\n\u00b6\n\n\nThe benefits of multithreaded:\n\n\n\n\nResponsiveness\n\n\nResource sharing\n\n\nEconomy\n\n\nScalability/Utilization\n\n\n\n\n4.2 Multicore Programming\n\u00b6\n\n\nA more recent, similar trend in system design is to place multiple computing cores on a single chip.\n\n\n\n\nMulticore or Multiprocessor systems\n\n\nThe cores appear across CPU chips or within CPU chips.\n\n\n\n\nConsider an application with 4 threads.\n\n\n\n\n\n\nWith a single core\n\n\n\n\n\n\n\n\nWith multiple cores\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParallelism\n\n\nConcurrency\n\n\n\n\n\n\n\n\n\n\nPerform more than one task simultaneously.\n\n\nAllow all the tasks to make progress.\n\n\n\n\n\n\n\n\n\n\nAmdahl's Law\n\n\nIf $S$ is the portion cannot be accelerated by $N$ cores (serially).\n\n\n$$speedup \\le \\frac{1}{S + \\frac{(1 - S)}{N}}$$\n\n\n\n\n4.2.1 Programming Challenges\n\u00b6\n\n\n\n\nIdentifying tasks: Dividing Activities\n\n\nBalance (Equal value)\n\n\nData splitting\n\n\nData dependency\n\n\nTesting and debugging\n\n\n\n\n4.2.2 Types of Parallelism\n\u00b6\n\n\n\n\nData parallelism\n\n\nDistribute subsets of the same data across multiple computing cores.\n\n\nEach core performs the same operation.\n\n\n\n\ne.g. \n\n\n$$\\sum_{i = 0}^{N - 1} arr[i] = \\sum_{i = 0}^{N / 2 - 1} arr[i] (\\text{thread } A) + \\sum_{i = N / 2}^{N - 1} arr[i] (\\text{thread } B).$$\n\n\n\n\nTask parallelism\n\n\nDistribute tasks (threads) across multiple computing cores.\n\n\nEach thread performs a unique operation.\n\n\n\n\n4.3 Multithreading Models\n\u00b6\n\n\n4.3.1 Many-to-One Model\n\u00b6\n\n\n\n\n\n\npros:\n\n\n\n\nEfficiency\n\n\n\n\n\n\n\n\ncons:\n\n\n\n\nOne blocking syscall blocks all\n\n\nNo parallelism for multiple processors\n\n\n\n\n\n\n\n\ne.g. Green threads (Solaris)\n\n\n\n\n4.3.2 One-to-One Model\n\u00b6\n\n\n\n\n\n\npros:\n\n\n\n\nOne syscall blocks one thread\n\n\n\n\n\n\n\n\ncons:\n\n\n\n\nOverheads in creating a kernel thread\n\n\n\n\n\n\n\n\ne.g. Windows NT/2000/XP, Linux, OS/2, Solaris 9\n\n\n\n\n4.3.3 Many-to-Many Model\n\u00b6\n\n\n\n\npros:\n\n\nA combination of parallelism and efficiency\n\n\n\n\n\n\n\n\ne.g. Solaris 2 & 9, IRIX, HP-UX, Tru64 UNIX\n\n\n\n\n\n\n4.4 Thread Libraries\n\u00b6\n\n\n\n\nUser level\n\n\nKernel level\n\n\n\n\nThree main thread libraries:\n\n\n\n\nPOSIX Pthreads: User or kernel level\n\n\nWindows: Kernel level\n\n\nJava: Level depending on the thread library on the host system.\n\n\n\n\nTwo general strategie for creating threads:\n\n\n\n\nAsynchronous threading: parent doesn't know children.\n\n\nSynchronous threading: parent must wait for all of its children. (\nfork-join\n)\n\n\n\n\nAll of the following examples use synchronous threading.\n\n\n4.4.1 Pthreads\n\u00b6\n\n\n\n\nPthreads\n\n\nThe POSIX standard (IEEE 1003.1c) defining an API for thread creation and synchronization. This is a \nspecification\n for thread behavior, not and \nimplementation\n.\n\n\n\n\n4.4.2 Windows Threads\n\u00b6\n\n\n4.4.3 Java Threads\n\u00b6\n\n\nCreating a \nThread\n object does not specifically create the new thread. $\\to$ \nstart()\n does!\n\n\n\n\nIt allocates memory and initializes a new thread in the JVM.\n\n\nIt calls the \nrun()\n method, making the thread eligible to be run by the JVM.\n(Note again that we never call the \nrun()\n method directly. Rather, we call the \nstart()\n method, and it calls the \nrun()\n method on our behalf)\n\n\n\n\n4.5 Implicit Threading\n\u00b6\n\n\n4.5.1 Thread Pools\n\u00b6\n\n\nThe issue of multithreaded server:\n\n\n\n\nTime to create the thread\n\n\nConcurrency\n\n\n\n\n\n\nThread pool\n\n\nCreate a number of threads at process startup and place them into a pool, where they sit and wait for work.\n\n\n\n\nThe benefits of thread pools:\n\n\n\n\nSpeed\n\n\nLimited # of threads, which is good for OS.\n\n\nSeperating the task of creating tasks allows us to use different strategies.\n\n\nDynamic or static thread pools\n\n\n\n\ne.g. \nQueueUserWorkItem()\n, \njava.util.concurrent\n.\n\n\n4.5.2 OpenMP\n\u00b6\n\n\n\n\nOpenMP\n\n\nA set of compiler directivese and APIs to support parallel programming in shared memory environment.\n\n\nThreads with divided workload are created automatically based on # of cores or a set bound.\n\n\n\n\n\n\nParallel regions\n\n\nBlocks of code that may run in parallel.\n\n\n\n\nWhen OpenMP encounters\n\n\n    \n#pragma omp parallel\n\n\n\n\n\nit creates as many threads are there are processing cores in the system.\n\n\ne.g.\n\n\n#pragma omp parallel for\n\n\nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n<\n \nN\n;\n \ni\n++\n)\n\n    \nc\n[\ni\n]\n \n=\n \na\n[\ni\n]\n \n+\n \nb\n[\ni\n];\n\n\n\n\n\n4.5.3 Grand Central Dispatch\n\u00b6\n\n\nA ma\nsOS/iOS combination of extensions to the C.\n\n\nLike OpenMP, GCD manges most of the details of threading.\n\n\n    \n^\n{\n \nprintf\n(\n\"I am a block.\"\n);\n \n}\n\n\n\n\n\nGCD schedules blocks for run-time execution by placing them on a \ndispatch queue\n.\n\n\n\n\nSerial (FIFO)\n\n\nConcurrent (FIFO)\n\n\nlow\n\n\ndefault\n\n\nhigh\n\n\n\n\n\n\n\n\ndispatch_queue_t\n \nqueue\n \n=\n \ndispatch_get_global_queue\n(\nDISPATCH_QUEUE_PRIORITY_DEFAULT\n,\n \n0\n);\n\n\ndispatch_async\n(\nqueue\n,\n \n^\n{\n \nprintf\n(\n\"I am a block.\"\n)\n \n});\n\n\n\n\n\n4.5.4 Other Approaches\n\u00b6\n\n\ne.g. Intel's Threading Building Blocks (TBB), \njava.util.concurrent\n.\n\n\n4.6 Threading Issues\n\u00b6\n\n\n4.6.1 The \nfork()\n and \nexec()\n System Calls\n\u00b6\n\n\n\n\nfork()\n issue\n\n\n\n\nDuplicate all threads?\n\n\nIs the new process single-threaded?\n\n\n\n\n\n\n\n\nexec()\n issue\n\n\nIf a thread invokese the \nexec()\n, the program specified in the parameter to \nexec()\n will replace the entire process\u2014including all threads. Thus if \nexec()\n is called immediately after forking, then duplicating all threads is unnecessary.\n\n\n\n\n4.6.2 Signal Handling\n\u00b6\n\n\nAll signals follows:\n\n\n\n\nA signal is generated by the occurrence of a particular event.\n\n\nThe signal is delivered to a process.\n\n\nOnce delivered, the signal must be handled.\n\n\n\n\nTwo types of signals:\n\n\n\n\n\n\nSynchronous signal: delivered to the same process that performed the operation causing the signal.\n\n\n\n\nillegal memory access\n\n\ndivision by 0\n\n\n\n\n\n\n\n\nAsynchronous signal\n\n\n\n\ngenerated by an external process (e.g. ^C)\n\n\nhaving a timer expire\n\n\n\n\n\n\n\n\nA signal may be handled by:\n\n\n\n\nA default signal handler\n\n\nA user-defined signal handler\n\n\n\n\nSignal delivering:\n\n\n\n\nDeliver the signal to the thread to which the signal applies. (e.g. division by 0)\n\n\nDeliver the signal to every thread in the process. (e.g. ^C)\n\n\nDeliver the signal to certain threads in the process.\n\n\nAssign a specific thread to receive all signals for the process.\n\n\n\n\nFunctions/Methods for delivering a signal:\n\n\n\n\n\n\nUNIX:\n\n\n    \nkill\n(\npid_t\n \npid\n,\n \nint\n \nsignal\n)\n\n\n\n\n\n\n\n\n\nPOSIX:\n\n\n    \npthread_kill\n(\npthread_t\n \ntid\n,\n \nint\n \nsignal\n)\n\n\n\n\n\n\n\n\n\nWindows:\n\n\n\n\nAsynchronous Procedure Calls (APCs)\n\n\n\n\n\n\n\n\n4.6.3 Thread Cancellation\n\u00b6\n\n\n\n\nTarget thread\n\n\nA thread that is to be canceled.\n\n\n\n\nCancellation of a target thread may occur in two different scenarios:\n\n\n\n\nAsynchronous cancellation\n. One thread immediately terminates the target thread.\n\n\nDeferred cancellation\n. The target thread periodically checks whether it should terminate, allowing it an opportunity to terminate itself in an orderly fashion.\n\n\n\n\n\n\nCanceling a thread asynchronously may not free a necessary system-wide resource.\n\n\n\n\npthread_tid\n;\n\n\n\n/* create the thread */\n\n\npthread_create\n(\n&\ntid\n,\n \n0\n,\n \nworker\n,\n \nNULL\n);\n\n\n...\n\n\n/* cancel the thread */\n\n\npthread_cancel\n(\ntid\n);\n\n\n\n\n\nPthreads supports three cancellation modes:\n\n\n\n\n\n\n\n\nMode\n\n\nState\n\n\nType\n\n\n\n\n\n\n\n\n\n\nOff\n\n\nDisabled\n\n\n\u2013\n\n\n\n\n\n\nDeferred\n\n\nEnabled\n\n\nDeferred\n\n\n\n\n\n\nAsynchronous\n\n\nEnabled\n\n\nAsynchronous\n\n\n\n\n\n\n\n\n\n\nCancellation point\n\n\nCancellation occurs only when a thread reaches a cancellation point.\n\n\n\n\n\n\nCleanup handler\n\n\nIf a cancellation request is found to be pending, this function allows any resources a thread may have acquired to be released before the thread is terminated.\n\n\n\n\ne.g. deferred cancellation:\n\n\nwhile\n \n(\n1\n)\n \n{\n\n    \n/* do some work for awhile */\n\n\n    \n/* check if there is a cancellation request */\n\n    \npthread_testcancel\n();\n\n\n}\n\n\n\n\n\n4.6.4 Thread-Local Storage\n\u00b6\n\n\n\n\nThread-Local Storage (TLS)\n\n\nEach thread might need its own copy of certain data.\n\n\n\n\nTLS is similar to \nstatic\n data.\n\n\n\n\n\n\n\n\nTLS\n\n\nLocal variables\n\n\n\n\n\n\n\n\n\n\nvisible across function invocations\n\n\nvisible only during a single function invocation\n\n\n\n\n\n\n\n\n4.6.5 Scheduler Activations\n\u00b6\n\n\n\n\nLightweight process (LWP)\n\n\nA virtual processor (kernel threads) on which the application can schedule a user thread to run. (many-to-many or two-level)\n\n\n\n\n\n\n\n\nScheduler activation\n\n\nThe kernel provides an application with a set of virtual processors (LWPs), and the application can schedule user threads onto an available virtual processor.\n\n\n\n\n\n\nUpcall\n\n\nThe kernel must inform an application about certain events.\n\n\n\n\n4.7 Operating-System Examples\n\u00b6\n\n\n4.7.1 Windows Threads\n\u00b6\n\n\nThe general components of a thread include:\n\n\n\n\nA thread ID uniquely identifying the thread\n\n\nA register set representing the status of the processor\n\n\nA user stack, employed when the thread is running in user mode\n\n\nA kernel stack, employed when the thread is running in kernel mode\n\n\nA private storage area used by various run-time libraries and dynamic link libraries (DLLs)\n\n\n\n\nContext\n (register set, stacks, and private sotrage area) of the thread:\n\n\n\n\n\n\nKernel space\n\n\n\n\n\n\nETHREAD\u2014executive thread block:\n\n\n\n\na pointer to the process\n\n\nthe address of the routine\n\n\na pointer to the corresponding KTHREAD\n\n\n\n\n\n\n\n\nKTHREAD\u2014kernel thread block\n\n\n\n\nscheduling/synchronization information\n\n\nthe kernel stack\n\n\na pointer to TEB\n\n\n\n\n\n\n\n\n\n\n\n\nUser space\n\n\n\n\nTEB\u2014thread environment block\n\n\nthe thread ID\n\n\na user-mode stack\n\n\nan array for TLS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.7.2 Linux Threads\n\u00b6\n\n\nclone()\n vs \nfork()\n\n\n\n\nterm \ntask\n\u2014rather than \nprocess\n or \nthread\n\n\nSeveral per-process data structures\n\n\npoints\n to the same data structures for open files, signal handling, virtual memory, etc.",
            "title": "Chapter 4 Threads"
        },
        {
            "location": "/OS/Chap04/#chapter-4-threads",
            "text": "",
            "title": "Chapter 4 Threads"
        },
        {
            "location": "/OS/Chap04/#41-overview",
            "text": "Thread\u2013Lightweight process (LWP)  A basit unit of CPU utilization.   A thread shares   code section  data section  OS resources (e.g. open files and signals)    A thread have its own   thread ID  program counter  register set  stack",
            "title": "4.1 Overview"
        },
        {
            "location": "/OS/Chap04/#411-motivation",
            "text": "It is generally more efficient to use one process that contains multiple threads since process creation is time consuming and resource intensive.",
            "title": "4.1.1 Motivation"
        },
        {
            "location": "/OS/Chap04/#412-benefits",
            "text": "The benefits of multithreaded:   Responsiveness  Resource sharing  Economy  Scalability/Utilization",
            "title": "4.1.2 Benefits"
        },
        {
            "location": "/OS/Chap04/#42-multicore-programming",
            "text": "A more recent, similar trend in system design is to place multiple computing cores on a single chip.   Multicore or Multiprocessor systems  The cores appear across CPU chips or within CPU chips.   Consider an application with 4 threads.    With a single core     With multiple cores        Parallelism  Concurrency      Perform more than one task simultaneously.  Allow all the tasks to make progress.      Amdahl's Law  If $S$ is the portion cannot be accelerated by $N$ cores (serially).  $$speedup \\le \\frac{1}{S + \\frac{(1 - S)}{N}}$$",
            "title": "4.2 Multicore Programming"
        },
        {
            "location": "/OS/Chap04/#421-programming-challenges",
            "text": "Identifying tasks: Dividing Activities  Balance (Equal value)  Data splitting  Data dependency  Testing and debugging",
            "title": "4.2.1 Programming Challenges"
        },
        {
            "location": "/OS/Chap04/#422-types-of-parallelism",
            "text": "Data parallelism  Distribute subsets of the same data across multiple computing cores.  Each core performs the same operation.   e.g.   $$\\sum_{i = 0}^{N - 1} arr[i] = \\sum_{i = 0}^{N / 2 - 1} arr[i] (\\text{thread } A) + \\sum_{i = N / 2}^{N - 1} arr[i] (\\text{thread } B).$$   Task parallelism  Distribute tasks (threads) across multiple computing cores.  Each thread performs a unique operation.",
            "title": "4.2.2 Types of Parallelism"
        },
        {
            "location": "/OS/Chap04/#43-multithreading-models",
            "text": "",
            "title": "4.3 Multithreading Models"
        },
        {
            "location": "/OS/Chap04/#431-many-to-one-model",
            "text": "pros:   Efficiency     cons:   One blocking syscall blocks all  No parallelism for multiple processors     e.g. Green threads (Solaris)",
            "title": "4.3.1 Many-to-One Model"
        },
        {
            "location": "/OS/Chap04/#432-one-to-one-model",
            "text": "pros:   One syscall blocks one thread     cons:   Overheads in creating a kernel thread     e.g. Windows NT/2000/XP, Linux, OS/2, Solaris 9",
            "title": "4.3.2 One-to-One Model"
        },
        {
            "location": "/OS/Chap04/#433-many-to-many-model",
            "text": "pros:  A combination of parallelism and efficiency     e.g. Solaris 2 & 9, IRIX, HP-UX, Tru64 UNIX",
            "title": "4.3.3 Many-to-Many Model"
        },
        {
            "location": "/OS/Chap04/#44-thread-libraries",
            "text": "User level  Kernel level   Three main thread libraries:   POSIX Pthreads: User or kernel level  Windows: Kernel level  Java: Level depending on the thread library on the host system.   Two general strategie for creating threads:   Asynchronous threading: parent doesn't know children.  Synchronous threading: parent must wait for all of its children. ( fork-join )   All of the following examples use synchronous threading.",
            "title": "4.4 Thread Libraries"
        },
        {
            "location": "/OS/Chap04/#441-pthreads",
            "text": "Pthreads  The POSIX standard (IEEE 1003.1c) defining an API for thread creation and synchronization. This is a  specification  for thread behavior, not and  implementation .",
            "title": "4.4.1 Pthreads"
        },
        {
            "location": "/OS/Chap04/#442-windows-threads",
            "text": "",
            "title": "4.4.2 Windows Threads"
        },
        {
            "location": "/OS/Chap04/#443-java-threads",
            "text": "Creating a  Thread  object does not specifically create the new thread. $\\to$  start()  does!   It allocates memory and initializes a new thread in the JVM.  It calls the  run()  method, making the thread eligible to be run by the JVM.\n(Note again that we never call the  run()  method directly. Rather, we call the  start()  method, and it calls the  run()  method on our behalf)",
            "title": "4.4.3 Java Threads"
        },
        {
            "location": "/OS/Chap04/#45-implicit-threading",
            "text": "",
            "title": "4.5 Implicit Threading"
        },
        {
            "location": "/OS/Chap04/#451-thread-pools",
            "text": "The issue of multithreaded server:   Time to create the thread  Concurrency    Thread pool  Create a number of threads at process startup and place them into a pool, where they sit and wait for work.   The benefits of thread pools:   Speed  Limited # of threads, which is good for OS.  Seperating the task of creating tasks allows us to use different strategies.  Dynamic or static thread pools   e.g.  QueueUserWorkItem() ,  java.util.concurrent .",
            "title": "4.5.1 Thread Pools"
        },
        {
            "location": "/OS/Chap04/#452-openmp",
            "text": "OpenMP  A set of compiler directivese and APIs to support parallel programming in shared memory environment.  Threads with divided workload are created automatically based on # of cores or a set bound.    Parallel regions  Blocks of code that may run in parallel.   When OpenMP encounters       #pragma omp parallel   it creates as many threads are there are processing cores in the system.  e.g.  #pragma omp parallel for  for   ( i   =   0 ;   i   <   N ;   i ++ ) \n     c [ i ]   =   a [ i ]   +   b [ i ];",
            "title": "4.5.2 OpenMP"
        },
        {
            "location": "/OS/Chap04/#453-grand-central-dispatch",
            "text": "A ma\nsOS/iOS combination of extensions to the C.  Like OpenMP, GCD manges most of the details of threading.       ^ {   printf ( \"I am a block.\" );   }   GCD schedules blocks for run-time execution by placing them on a  dispatch queue .   Serial (FIFO)  Concurrent (FIFO)  low  default  high     dispatch_queue_t   queue   =   dispatch_get_global_queue ( DISPATCH_QUEUE_PRIORITY_DEFAULT ,   0 );  dispatch_async ( queue ,   ^ {   printf ( \"I am a block.\" )   });",
            "title": "4.5.3 Grand Central Dispatch"
        },
        {
            "location": "/OS/Chap04/#454-other-approaches",
            "text": "e.g. Intel's Threading Building Blocks (TBB),  java.util.concurrent .",
            "title": "4.5.4 Other Approaches"
        },
        {
            "location": "/OS/Chap04/#46-threading-issues",
            "text": "",
            "title": "4.6 Threading Issues"
        },
        {
            "location": "/OS/Chap04/#461-the-fork-and-exec-system-calls",
            "text": "fork()  issue   Duplicate all threads?  Is the new process single-threaded?     exec()  issue  If a thread invokese the  exec() , the program specified in the parameter to  exec()  will replace the entire process\u2014including all threads. Thus if  exec()  is called immediately after forking, then duplicating all threads is unnecessary.",
            "title": "4.6.1 The fork() and exec() System Calls"
        },
        {
            "location": "/OS/Chap04/#462-signal-handling",
            "text": "All signals follows:   A signal is generated by the occurrence of a particular event.  The signal is delivered to a process.  Once delivered, the signal must be handled.   Two types of signals:    Synchronous signal: delivered to the same process that performed the operation causing the signal.   illegal memory access  division by 0     Asynchronous signal   generated by an external process (e.g. ^C)  having a timer expire     A signal may be handled by:   A default signal handler  A user-defined signal handler   Signal delivering:   Deliver the signal to the thread to which the signal applies. (e.g. division by 0)  Deliver the signal to every thread in the process. (e.g. ^C)  Deliver the signal to certain threads in the process.  Assign a specific thread to receive all signals for the process.   Functions/Methods for delivering a signal:    UNIX:       kill ( pid_t   pid ,   int   signal )     POSIX:       pthread_kill ( pthread_t   tid ,   int   signal )     Windows:   Asynchronous Procedure Calls (APCs)",
            "title": "4.6.2 Signal Handling"
        },
        {
            "location": "/OS/Chap04/#463-thread-cancellation",
            "text": "Target thread  A thread that is to be canceled.   Cancellation of a target thread may occur in two different scenarios:   Asynchronous cancellation . One thread immediately terminates the target thread.  Deferred cancellation . The target thread periodically checks whether it should terminate, allowing it an opportunity to terminate itself in an orderly fashion.    Canceling a thread asynchronously may not free a necessary system-wide resource.   pthread_tid ;  /* create the thread */  pthread_create ( & tid ,   0 ,   worker ,   NULL );  ...  /* cancel the thread */  pthread_cancel ( tid );   Pthreads supports three cancellation modes:     Mode  State  Type      Off  Disabled  \u2013    Deferred  Enabled  Deferred    Asynchronous  Enabled  Asynchronous      Cancellation point  Cancellation occurs only when a thread reaches a cancellation point.    Cleanup handler  If a cancellation request is found to be pending, this function allows any resources a thread may have acquired to be released before the thread is terminated.   e.g. deferred cancellation:  while   ( 1 )   { \n     /* do some work for awhile */ \n\n     /* check if there is a cancellation request */ \n     pthread_testcancel ();  }",
            "title": "4.6.3 Thread Cancellation"
        },
        {
            "location": "/OS/Chap04/#464-thread-local-storage",
            "text": "Thread-Local Storage (TLS)  Each thread might need its own copy of certain data.   TLS is similar to  static  data.     TLS  Local variables      visible across function invocations  visible only during a single function invocation",
            "title": "4.6.4 Thread-Local Storage"
        },
        {
            "location": "/OS/Chap04/#465-scheduler-activations",
            "text": "Lightweight process (LWP)  A virtual processor (kernel threads) on which the application can schedule a user thread to run. (many-to-many or two-level)     Scheduler activation  The kernel provides an application with a set of virtual processors (LWPs), and the application can schedule user threads onto an available virtual processor.    Upcall  The kernel must inform an application about certain events.",
            "title": "4.6.5 Scheduler Activations"
        },
        {
            "location": "/OS/Chap04/#47-operating-system-examples",
            "text": "",
            "title": "4.7 Operating-System Examples"
        },
        {
            "location": "/OS/Chap04/#471-windows-threads",
            "text": "The general components of a thread include:   A thread ID uniquely identifying the thread  A register set representing the status of the processor  A user stack, employed when the thread is running in user mode  A kernel stack, employed when the thread is running in kernel mode  A private storage area used by various run-time libraries and dynamic link libraries (DLLs)   Context  (register set, stacks, and private sotrage area) of the thread:    Kernel space    ETHREAD\u2014executive thread block:   a pointer to the process  the address of the routine  a pointer to the corresponding KTHREAD     KTHREAD\u2014kernel thread block   scheduling/synchronization information  the kernel stack  a pointer to TEB       User space   TEB\u2014thread environment block  the thread ID  a user-mode stack  an array for TLS",
            "title": "4.7.1 Windows Threads"
        },
        {
            "location": "/OS/Chap04/#472-linux-threads",
            "text": "clone()  vs  fork()   term  task \u2014rather than  process  or  thread  Several per-process data structures  points  to the same data structures for open files, signal handling, virtual memory, etc.",
            "title": "4.7.2 Linux Threads"
        },
        {
            "location": "/OS/Chap05/",
            "text": "Chapter 5 Process Synchronization\n\u00b6\n\n\n5.1 Background\n\u00b6\n\n\nRecall \nproducer\u2013consumer problem\n. We modify it as follows:\n\n\nwhile\n \n(\ntrue\n)\n \n{\n\n    \n/* produce an item in next_produced */\n\n\n    \nwhile\n \n(\ncounter\n \n==\n \nBUFFER_SIZE\n)\n \n;\n    \n// do nothing\n\n\n    \nbuffer\n[\nin\n]\n \n=\n \nnext_produced\n;\n\n    \nin\n \n=\n \n(\nin\n \n+\n \n1\n)\n \n%\n \nBUFFER_SIZE\n;\n\n    \ncounter\n++\n;\n\n\n}\n\n\n\n\n\nwhile\n \n(\ntrue\n)\n \n{\n\n    \nwhile\n \n(\ncounter\n \n==\n \n0\n)\n \n;\n      \n// do nothing\n\n\n    \nnext_consumed\n \n=\n \nbuffer\n[\nout\n];\n\n    \nout\n \n=\n \n(\nout\n \n+\n \n1\n)\n \n%\n \nBUFFER_SIZE\n;\n\n    \ncounter\n--\n;\n\n\n    \n/* consume the item in next_consumed */\n\n\n}\n\n\n\n\n\nSuppose \ncounter == 5\n initially. After executing \ncounter++\n in producer or \ncounter--\n in consumer. The value of \ncounter\n may be $4$, $5$, or $6$!\n\n\n\\begin{array}{lllll}\nT_0: producer & \\text{execute} & register_1 = \\text{counter} & \\{register_1 = 5\\} \\\\\nT_1: producer & \\text{execute} & register_1 = register_1 + 1 & \\{register_1 = 6\\} \\\\\nT_2: consumer & \\text{execute} & register_2 = \\text{counter} & \\{register_2 = 5\\} \\\\\nT_3: consumer & \\text{execute} & register_2 = register_2 - 1 & \\{register_2 = 4\\} \\\\\nT_4: producer & \\text{execute} & \\text{counter} = register_1 & \\{counter = 6\\} \\\\\nT_5: consumer & \\text{execute} & \\text{counter} = register_2 & \\{counter = 4\\}\n\\end{array}\n\n\n\n\nRace condition\n\n\nSeveral processes access and manipulate the same data concurrently and the outcome of the execution depends on the \nparticular order\n in which the access takes place.\n\n\n\n\nWe need to ensure that only one process at a time can be manipulating the variable \ncounter\n.\n\n\n5.2 The Critical-Section Problem\n\u00b6\n\n\n\n\nCritical section\n\n\nIn which the process may be changing common variables, updating a table, writing a file, and so on.\n\n\n\n\ndo\n \n{\n\n    \n/* entry section */\n\n        \n/* critical section */\n\n    \n/* exit section */\n\n        \n/* remainder section */\n\n\n}\n \nwhile\n \n(\ntrue\n);\n\n\n\n\n\nA solution to the critical-section problem must satisfy:\n\n\n\n\nMutual exclusion\n\n\nProgress\n. Cannot be postponed indefinitely.\n\n\nBounded waiting\n\n\n\n\nTwo general approches are used to handle critical sections:\n\n\n\n\nPreemptive kernels\n\n\nNonpreemptive kernels\n\n\n\n\nWhy anyone favor a preemptive kernel over a nonpreemptive one?\n\n\n\n\nResponsive.\n\n\nMore suitable for real-time programming.\n\n\n\n\n5.3 Peterson's Solution\n\u00b6\n\n\nPeterson's solution is restricted to two processes that alternate execution between their critical sections and remainder sections. The processes are named $P_i$ and $P_j$.\n\n\nShared data items:\n\n\nint\n \nturn\n;\n\n\nboolean\n \nflag\n[\n2\n];\n\n\n\n\n\ndo\n \n{\n\n    \nflag\n[\ni\n]\n \n=\n \ntrue\n;\n\n    \nturn\n \n=\n \nj\n;\n\n    \nwhile\n \n(\nflag\n[\nj\n]\n \n&&\n \nturn\n \n==\n \nj\n)\n \n;\n\n    \n/* critical section */\n\n\n    \nflag\n[\ni\n]\n \n=\n \nfalse\n;\n\n    \n/* remainder section */\n\n\n}\n \nwhile\n \n(\ntrue\n);\n\n\n\n\n\n\n\nIf both processes try to enter at the same time, \nturn\n will be set to both $i$ and $j$ at roughly the same time. \nOnly one of these assignments will last.\n\n\n\n\nProof\n\n\n\n\nMutual exclusion is preserved.\n\n\nThe progress requirement is satisfied.\n\n\n\n\nThe bounded-waiting requirement is met.\n\n\nSuppose $P_i$ execute $turn = j$ first, then $P_j$ execute $turn = i$. In this assumption, $P_i$ will enter its critical section first and $P_j$ will be stucked in the \nwhile(flag[i] && turn == i\n (remember that here \ni\n should be thinked as \nj\n in the code!). After $P_i$ entering exit section, there are two possibilities:\n\n\n\n\n$P_i$ sets \nflag[i] = false\n, then $P_j$ enters its critical section.\n\n\nAfter $P_i$ setting \nflag[i] = false\n, it immediately sets \nflag[i] = true\n again, consequently, it'll set \nturn = j\n, thus $P_j$ still can enter its critical section.\n\n\n\n\n\n\n\n\nBakery Algorithm\n\u00b6\n\n\n\n\nOriginally designed for distrubuted systems\n\n\nProcesses which are ready to enter their critical section must take a number and wait till the number becomes the lowest.\n\n\n\n\nint\n \nnumber\n[\ni\n];\n          \n// Pi's number if it is nonzeros\n\n\nboolean\n \nchoosing\n[\ni\n];\n    \n// Pi is taking a number\n\n\n\n\n\ndo\n \n{\n\n    \nchoosing\n[\ni\n]\n \n=\n \ntrue\n;\n         \n// A process want to enter its critical section\n\n    \nnumber\n[\ni\n]\n \n=\n \nmax\n(\nnumber\n[\n0\n],\n \n...,\n \nnumber\n[\nn\n \n-\n \n1\n])\n \n+\n \n1\n;\n\n    \nchoosing\n[\nj\n]\n \n=\n \nfalse\n;\n        \n// A process has got its number\n\n    \nfor\n \n(\nint\n \nj\n \n=\n \n0\n;\n \nj\n \n<\n \nn\n;\n \nj\n++\n)\n \n{\n\n        \nwhile\n \n(\nchoosing\n[\nj\n])\n \n;\n\n        \nwhile\n \n(\nnumber\n[\nj\n]\n \n!=\n \n0\n \n&&\n \n(\nnumber\n[\nj\n],\n \nj\n)\n \n<\n \n(\nnumber\n[\ni\n],\n \ni\n))\n \n;\n     \n// If two processes got the same number, then we should compare their indices\n\n    \n}\n\n    \n/* critical section */\n\n\n    \nnumber\n[\ni\n]\n \n=\n \n0\n;\n\n    \n/* remainder section */\n\n\n}\n \nwhite\n \n(\ntrue\n);\n\n\n\n\n\n\n\nAn observation: If $P_i$ is in its critical section, and $P_k (k \\ne i)$ , then $(number[i], i) < (number[k], k)$.\n\n\n\n\nProof\n\n\n\n\nMutual exclusion: Only the process holds the lowest number can enter the critical section. For each process, when that process doens't get its number, the original process will be stucked in the first while-loop. After that process getting its number, we still need to compare their $numbers$ and $indices$.\n\n\nProgress requirement: The processes won't be forever postponed.\n\n\nBounded-waiting: Assume that a process holds the biggest number, it should wait other processes in the second while-loop. But after all other process entering their exit section and again entering their entry section, they'll get a bigger number, thus the process won't wait forever.\n\n\n\n\n5.4 Synchronization Hardware\n\u00b6\n\n\nDisaple interrupt $\\to$ No preemption:\n\n\n\n\nInfeasible in multiprocessor environment.\n\n\nPotential impacts on interrupt-driven system clocks.\n\n\n\n\n\n\nAtomic\n\n\nModern computer allow us either to test and modify the content of a word or to swap the contents of two words \natomically\n\u2014that is, as one uninterruptible.\n\n\n\n\nAlthough following algorithms satisfy the mutual-exclusion requirement, they don't satisfy the bounded-waiting requirement.\n\n\nboolean\n \ntest_and_set\n(\nboolean\n \n*\ntarget\n)\n \n{\n\n    \nboolean\n \nrv\n \n=\n \n*\ntarget\n;\n\n    \n*\ntarget\n \n=\n \ntrue\n;\n\n\n    \nreturn\n \nrv\n;\n\n\n}\n\n\n\n\n\ndo\n \n{\n\n    \nwhile\n \n(\ntest_and_set\n(\n&\nlock\n))\n \n;\n\n    \n/* critical section */\n\n\n    \nlock\n \n=\n \nfalse\n;\n\n    \n/* remainder section */\n\n\n}\n \nwhile\n \n(\ntrue\n);\n\n\n\n\n\nThe first process executing \nwhile (test_and_set(&lock))\n will set the address value of \nlock\n to \ntrue\n and get the return value \nrv = false\n, thus it won't be stucked in the while-loop and it can enter its critical section.\n\n\n\n\nMutual exclusion: OK\n\n\nProgress requirement: OK\n\n\n\n\nBounded-waiting: FAIL\n\n\nAssume there is only one CPU, after $P_i$ entering its critical section, $P_j$ will be stucked in the while-loop. After $P_i$ exiting its critical section, there are two possibilities:\n\n\n\n\n$P_i$ sets \nlock = false\n, the CPU context switch to $P_j$, thus $P_j$ can enters its critical section.\n\n\nAfter $P_i$ setting \nlock = false\n, the CPU still executes the code of $P_i$, thus $P_i$ enters its critical section again, so $P_j$ may wait forever.\n\n\n\n\n\n\n\n\nvoid\n \nswap\n(\nboolean\n \n*\na\n,\n \nboolean\n \n*\nb\n)\n \n{\n\n    \nboolean\n \ntemp\n \n=\n \n*\na\n;\n\n    \n*\na\n \n=\n \n*\nb\n;\n\n    \n*\nb\n \n=\n \ntemp\n;\n\n\n}\n\n\n\n\n\ndo\n \n{\n\n    \nkey\n \n=\n \ntrue\n;\n\n    \nwhile\n \n(\nkey\n \n==\n \ntrue\n)\n\n        \nswap\n(\n&\nlock\n,\n \n&\nkey\n);\n\n    \n/* critical section */\n\n\n    \nlock\n \n=\n \nfalse\n;\n\n    \n/* remainder section */\n\n\n}\n \nwhile\n \n(\ntrue\n);\n\n\n\n\n\n\n\nMutual exclusion: OK\n\n\nProgress requirement: OK\n\n\nBounded-waiting: FAIL (the reason is like above)\n\n\n\n\nint\n \ncompare_and_swap\n(\nint\n \n*\nvalue\n,\n \nint\n \nexpected\n,\n \nint\n \nnew_value\n)\n \n{\n\n    \nint\n \ntemp\n \n=\n \n*\nvalue\n;\n\n\n    \nif\n \n(\n*\nvalue\n \n==\n \nexpected\n)\n\n        \n*\nvalue\n \n=\n \nnew_value\n;\n\n\n    \nreturn\n \ntemp\n;\n\n\n}\n\n\n\n\n\ndo\n \n{\n\n    \nwhile\n \n(\ncompare_and_swap\n(\n&\nlock\n,\n \n0\n,\n \n1\n)\n \n!=\n \n0\n)\n \n;\n\n    \n/* critical section */\n\n\n    \nlock\n \n=\n \n0\n;\n\n    \n/* remainder section */\n\n\n}\n \nwhile\n \n(\ntrue\n);\n\n\n\n\n\nFollowing algorithms satisfies all the critical-section requirements.\n\n\nboolean\n \nwaiting\n[\nn\n];\n\n\nboolean\n \nlock\n;\n\n\n\n\n\ndo\n \n{\n\n    \nwaiting\n[\ni\n]\n \n=\n \ntrue\n;\n\n    \nkey\n \n=\n \ntrue\n;\n\n    \nwhile\n \n(\nwaiting\n[\ni\n]\n \n&&\n \nkey\n)\n\n        \nkey\n \n=\n \ntest_and_set\n(\n&\nlock\n);\n\n    \nwaiting\n[\ni\n]\n \n=\n \nfalse\n;\n\n    \n/* critical section */\n\n\n    \nj\n \n=\n \n(\ni\n \n+\n \n1\n)\n \n%\n \nn\n;\n                    \n// Assign its next process\n\n    \nwhile\n \n((\nj\n \n!=\n \ni\n)\n \n&&\n \n!\nwaiting\n[\nj\n])\n     \n// Find a following process who is waiting\n\n        \nj\n \n=\n \n(\nj\n \n+\n \n1\n)\n \n%\n \nn\n;\n\n\n    \nif\n \n(\nj\n \n==\n \ni\n)\n                         \n// If no process is waiting\n\n        \nlock\n \n=\n \nfalse\n;\n\n    \nelse\n\n        \nwaiting\n[\nj\n]\n \n=\n \nfalse\n;\n             \n// Thus line 4 will be false and Pj won't be stucked anymore\n\n    \n/* remainder section */\n\n\n}\n \nwhile\n \n(\ntrue\n);\n\n\n\n\n\nboolean\n \ntest_and_set\n(\nboolean\n \n*\ntarget\n)\n \n{\n\n    \nboolean\n \nrv\n \n=\n \n*\ntarget\n;\n\n    \n*\ntarget\n \n=\n \ntrue\n;\n\n\n    \nreturn\n \nrv\n;\n\n\n}\n\n\n\n\n\nAssume \nlock\n is initialized to \nfalse\n.\n\n\n\n\nMutual exclusion: If many processes set their \nwaiting[i] = true\n, after the first process execute \nkey = test_and_set(&lock)\n, \nkey\n will be set to \nfalse\n and \nlock\n will be set to \ntrue\n. Therefore, other processes will be stucked in \nwhile (waiting[i] && key)\n since their \nkey\n will be set to \ntrue\n after \ntest_and_set(&lock)\n (\nlock\n is now \ntrue\n).\n\n\nProgress requirement: Only the process first run \ntest_and_set\n can enter its critical section.\n\n\nBounded-waiting: Wait at most $n - 1$ times.\n\n\n\n\nMutex Locks\n\u00b6\n\n\nA high-level software solution to provide protect critical sections with mutual exclusion.\n\n\n\n\nAtomic execution of \nacquire()\n and \nrelease()\n.\n\n\nSpinlock:\n\n\npros: No context switch for multiprocessor systems.\n\n\ncons: Busy waiting.\n\n\n\n\n\n\n\n\nacquire\n()\n \n{\n\n    \nwhile\n \n(\n!\navailable\n)\n \n;\n        \n// busy wait\n\n    \navailable\n \n=\n \nfalse\n;\n\n\n}\n\n\n\n\n\nrelease\n()\n \n{\n\n    \navailable\n \n=\n \ntrue\n;\n\n\n}\n\n\n\n\n\ndo\n \n{\n\n    \n// acquire lock\n\n        \n/* critical section */\n\n    \n// release lock\n\n        \n/* remainder section */\n\n\n}\n \nwhile\n \n(\ntrue\n);\n\n\n\n\n\n\n\nSpinlock\n\n\nThe process \"spins\" while waiting for the lock to become available.\n\n\n\n\n5.6 Semaphores\n\u00b6\n\n\nA high-level solution for more complex problems.\n\n\n\n\nA variable \nS\n only accessible by two atomic operations\n\n\nSpinlock\n\n\n\n\nwait\n(\nS\n)\n \n{\n               \n/* P */\n\n    \nwhile\n \n(\nS\n \n<=\n \n0\n)\n \n;\n    \n// busy wait\n\n    \nS\n--\n;\n\n\n}\n\n\n\n\n\nsignal\n(\nS\n)\n \n{\n             \n/* V */\n\n    \nS\n++\n;\n\n\n}\n\n\n\n\n\n5.6.1 Semaphore Usage\n\u00b6\n\n\n\n\n\n\nCritical sections:\n\n\ndo\n \n{\n\n    \nwait\n(\nmutex\n);\n\n    \n/* critical section */\n\n    \nsignal\n(\nmutex\n);\n\n    \n/* remainder section */\n\n\n}\n \nwhile\n \n(\ntrue\n);\n\n\n\n\n\n\n\n\n\nPrecedence enforcement:\n\n\n\n\n\n\n$P_1$:\n\n\nS1\n;\n\n\nsignal\n(\nsynch\n);\n\n\n\n\n\n\n\n\n\n$P_2$:\n\n\nwait\n(\nsynch\n);\n\n\nS2\n;\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.6.2 Semaphore Implementation\n\u00b6\n\n\nIt's not good for single CPU.\nEven if it's implemented in a multi-CPU environment, the locks should be held for a short time.\n\n\nWe can implement the Semaphores with block waiting:\n\n\ntypedef\n \nstruct\n \n{\n\n    \nint\n \nvalue\n;\n\n    \nstruct\n \nprocess\n \n*\nlist\n;\n\n\n}\n \nsemaphore\n;\n\n\n\n\n\nwait\n(\nsemaphore\n \n*\nS\n)\n \n{\n\n    \nS\n->\nvalue\n--\n;\n\n    \nif\n \n(\nS\n->\nvalue\n \n<\n \n0\n)\n \n{\n\n        \nadd\n \nthis\n \nprocess\n \nto\n \nS\n->\nlist\n;\n\n        \nblock\n();\n\n    \n}\n\n\n}\n\n\n\n\n\nsignal\n(\nsemaphore\n \n*\nS\n)\n \n{\n\n    \nS\n->\nvalue\n++\n;\n\n    \nif\n \n(\nS\n->\nvalue\n \n<=\n \n0\n)\n \n{\n\n        \nremove\n \na\n \nprocess\n \nP\n \nfrom\n \nS\n->\nlist\n;\n\n        \nwakeup\n(\nP\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n$|S.value|$ = # of waiting processes if $S.value < 0$.\n\n\n\n\nBounded-waiting can be satisfied by FIFO queue but may be unsatisfied by priority queue.\n\n\n5.6.3 Deadlocks and Starvation\n\u00b6\n\n\n\n\nDeadlock\n\n\nA set of processes is in a deadlock state when every process in the set is waiting for an event that can be caused only by another process in the set.\n\n\n\n\n\\begin{array}{cc}\nP_0 & P_1 \\\\\nwait(S); & wait(Q); \\\\\nwait(Q); & wait(S); \\\\\n\\vdots & \\vdots \\\\\nsignal(S); & signal(Q); \\\\\nsignal(Q); & signal(S); \\\\\n\\end{array}\n\n\nDeadlock may happen (assume $S = 1$ and $Q = 1$: \n\n\n\n\n$P_0$ calls $wait(S)$\n\n\n$P_1$ calls $wait(Q)$\n\n\n$P_1$ calls $wait(S)$\n\n\n$P_0$ calls $wait(Q)$\n\n\n\n\n\n\nStarvation (Indefinite blocking)\n\n\nA situation in which processes wait indefinitely within the semaphore.\n\n\ne.g. priority queue, stack (LIFO).\n\n\n\n\n5.6.4 Priority Inversion\n\u00b6\n\n\n\n\nPriority Inversion\n\n\nA higher-priority task is blocked by a lower-priority task due to some resource access conflict.\n\n\n\n\nBinary Semaphore\n\u00b6\n\n\nWe can implement counting semaphores by binary semaphores. ($S_1 = 1$, $S_2 = 0$ and $S_3 = 1$)\n\n\nWAIT\n(\nS\n)\n \n{\n\n    \nwait\n(\nS3\n);\n   \n// protect the whole program\n\n    \nwait\n(\nS1\n);\n   \n// protect C\n\n    \nC\n--\n;\n\n    \nif\n \n(\nC\n \n<\n \n0\n)\n \n{\n\n        \nsignal\n(\nS1\n);\n\n        \nwait\n(\nS2\n);\n\n    \n}\n \nelse\n \nsignal\n(\nS1\n);\n\n    \nsignal\n(\nS3\n);\n\n\n}\n\n\n\n\n\nSIGNAL\n(\nS\n)\n \n{\n\n    \nwait\n(\nS1\n);\n\n    \nC\n++\n;\n\n    \nif\n \n(\nC\n \n<=\n \n0\n)\n\n        \nsignal\n(\nS2\n);\n     \n// wake up\n\n    \nsignal\n(\nS1\n);\n\n\n}\n\n\n\n\n\n\n\nIs \nwait(S3)\n necessary?\n\n\nCan we change the order of \nsignal(S1)\n and \nwait(S2)\n?\n\n\nThere are lots of implementation details.\n\n\n\n\n5.7 Classic Problems of Synchronization\n\u00b6\n\n\n5.7.1 The Bounded-Buffer Problem\n\u00b6\n\n\nint\n \nn\n;\n\n\nsemaphore\n \nmutex\n \n=\n \n1\n;\n\n\nsemaphore\n \nempty\n \n=\n \nn\n;\n\n\nsemaphore\n \nfull\n \n=\n \n0\n;\n\n\n\n\n\n\n\n\n\nProducer:\n\n\ndo\n \n{\n\n    \n/* produce an item in next_produced */\n\n\n    \nwait\n(\nempty\n);\n\n    \nwait\n(\nmutex\n);\n\n\n    \n/* add next_produced to the buffer */\n\n\n    \nsignal\n(\nmutex\n);\n\n    \nsignal\n(\nfull\n);\n\n\n}\n \nwhile\n \n(\ntrue\n);\n\n\n\n\n\n\n\n\n\nConsumer:\n\n\ndo\n \n{\n\n    \nwait\n(\nfull\n);\n\n    \nwait\n(\nmutex\n);\n\n\n    \n/* remove an item from buffer to next_consumed */\n\n\n    \nsignal\n(\nmutex\n);\n\n    \nsignal\n(\nempty\n);\n\n\n    \n/* consume the item in next_consumed */\n\n\n}\n \nwhile\n \n(\ntrue\n);\n\n\n\n\n\n\n\n\n\n5.7.2 The Readers\u2013Writers Problem\n\u00b6\n\n\n\n\n\n\nThe basic assumption:\n\n\n\n\nReaders: shared locks\n\n\nWriters: exclusive locks\n\n\n\n\n\n\n\n\nThe first reader-writers problem\n\n\n\n\nNo readers will be kept waiting unless a writer has already obtained permission to use the shared object $\\to$ potential hazard to writers!\n\n\n\n\n\n\n\n\nThe second reader-writers problem\n\n\n\n\nOne a writer is ready, it performs its write asap $\\to$ potential hazard to readers.\n\n\n\n\n\n\n\n\nsemaphore\n \nrw_mutex\n \n=\n \n1\n;\n\n\nsemaphore\n \nmutex\n \n=\n \n1\n;\n\n\nint\n \nread_count\n \n=\n \n0\n;\n\n\n\n\n\ndo\n \n{\n\n    \nwait\n(\nrw_mutex\n);\n\n\n    \n/* writing is performed */\n\n\n    \nsignal\n(\nrw_mutex\n);\n\n\n}\n \nwhile\n \n(\ntrue\n);\n\n\n\n\n\ndo\n \n{\n\n    \nwait\n(\nmutex\n);\n        \n// protect read_count\n\n    \nread_count\n++\n;\n\n    \nif\n \n(\nread_count\n \n==\n \n1\n)\n\n        \nwait\n(\nrw_mutex\n);\n\n    \nsignal\n(\nmutex\n);\n\n\n    \n/* reading is performed */\n\n\n    \nwait\n(\nmutex\n);\n        \n// protect read_count\n\n    \nread_count\n--\n;\n\n    \nif\n \n(\nread_count\n \n==\n \n0\n)\n\n        \nsignal\n(\nrw_mutex\n);\n\n    \nsignal\n(\nmutex\n);\n\n\n}\n \nwhile\n \n(\ntrue\n);\n\n\n\n\n\n5.7.3 The Dining-Philosophers Problem\n\u00b6\n\n\n\n\nEach philosopher must pick up one chopstick beside him/her at a time.\n\n\nWhen two chopsticks are picked up, the philosopher can eat.\n\n\n\n\nsemaphore\n \nchopstick\n[\n5\n];\n\n\n\n\n\ndo\n \n{\n\n    \nwait\n(\nchopstick\n[\ni\n]);\n\n    \nwait\n(\nchopstick\n[(\ni\n \n+\n \n1\n)\n \n%\n \n5\n]);\n\n\n    \n/* eat for awhile */\n\n\n    \nsignal\n(\nchopstick\n[\ni\n]);\n\n    \nsignal\n(\nchopstick\n[(\ni\n \n+\n \n1\n)\n \n%\n \n5\n]);\n\n\n    \n/* think for awhile */\n\n\n}\n \nwhile\n \n(\ntrue\n);\n\n\n\n\n\nCritical Regions\n\u00b6\n\n\n\n\nRegion $v$ when $C$ (condition) do $S$ (statements)\n\n\nVariable $v$ \u2014 shared among processes and only accessible in the region.\n\n\n\n\n\n\n\n\nstruct\n \nbuffer\n \n{\n\n    \nitem\n \npool\n[\nn\n];\n\n    \nint\n \ncount\n,\n \nin\n,\n \nout\n;\n\n\n};\n\n\n\n\n\n\n\n\n\nProducer:\n\n\nregion\n \nbuffer\n \nwhen\n\n\n(\ncount\n \n<\n \nn\n)\n \n{\n\n    \npool\n[\nin\n]\n \n=\n \nnext_produced\n;\n\n    \nin\n \n=\n \n(\nin\n \n+\n \n1\n)\n \n%\n \nn\n;\n\n    \ncount\n++\n;\n\n\n}\n\n\n\n\n\n\n\n\n\nConsumer:\n\n\nregion\n \nbuffer\n \nwhen\n\n\n(\ncount\n \n>\n \n0\n)\n \n{\n\n    \nnext_consumed\n \n=\n \npool\n[\nout\n];\n\n    \nout\n \n=\n \n(\nout\n \n+\n \n1\n)\n \n%\n \nn\n;\n\n    \ncount\n--\n;\n\n\n}\n\n\n\n\n\n\n\n\n\n5.8 Monitors\n\u00b6\n\n\nmonitor\n \nmonitor\n \nname\n \n{\n\n    \n/* shared variable declarations */\n\n\n    \nfunction\n \nP1\n \n(\n \n.\n \n.\n \n.\n \n)\n \n{\n\n        \n.\n \n.\n \n.\n\n    \n}\n\n\n    \nfunction\n \nP2\n \n(\n \n.\n \n.\n \n.\n \n)\n \n{\n\n        \n.\n \n.\n \n.\n\n    \n}\n\n\n        \n.\n\n        \n.\n\n        \n.\n\n    \nfunction\n \nPn\n \n(\n \n.\n \n.\n \n.\n \n)\n \n{\n\n        \n.\n \n.\n \n.\n\n    \n}\n\n\n    \ninitialization_code\n \n(\n \n.\n \n.\n \n.\n \n)\n \n{\n\n        \n.\n \n.\n \n.\n\n    \n}\n\n\n}\n\n\n\n\n\n5.8.1 Monitor Usage\n\u00b6\n\n\nAn abstract data type\u2014or ADT\u2014encapsulates data with a set of functions to operate on that data that are independent of any specific implementation of the ADT.\n\n\nThe monitor construct ensures that only one process at a time is active within the monitor.\n\n\nA programmer who needs to write a tailor-made synchronization scheme can define one or more variables of type $condition$:\n\n\n    \ncondition\n \nx\n,\n \ny\n;\n\n\n\n\n\nThe only operations that can be invoked on a condition variable are \nwait()\n and \nsignal()\n. The operation\n\n\n    \nx\n.\nwait\n();\n\n\n\n\n\nmeans that the process invoking this operation is suspended until another process invokes\n\n\n    \nx\n.\nsignal\n();\n\n\n\n\n\n\n\nCondition variables (of a monitor) vs. signal operation (of binary semaphore)\n\n\nThe \nx.signal()\n operation resumes exactly one suspended process. If no process is suspended, then the \nsignal()\n operation has no effect; that is, the state of \nx\n is the same as if the operation had never been executed. Contrast this operation with the \nsignal()\n operation associated with semaphores, which always affects the state of the semaphore.\n\n\n\n\nSuppose that, when the \nx.signal()\n operation is invoked by a process \nP\n, there exists a suspended process \nQ\n associated with condition \nx\n. Clearly, if the suspended process \nQ\n is allowed to resume its execution, the signaling process \nP\n must wait. Two possibilities exist:\n\n\n\n\n\n\nSignal and wait\n: \nP\n either waits until \nQ\n leaves the monitor or waits for another condition.\n\n\n\n\n\n\nSignal and continue\n: \nQ\n either waits until \nP\n leaves the monitor or waits for another condition.\n\n\n\n\n\n\n\n\n5.8.2 Dining-Philosophers Solution Using Monitors\n\u00b6\n\n\nenum\n \n{\nTHINKING\n,\n \nHUNGRY\n,\n \nEATING\n}\n \nstate\n[\n5\n];\n\n\ncondition\n \nself\n[\n5\n];\n\n\n\n\n\nmonitor\n \nDiningPhilosophers\n \n{\n\n    \nenum\n \n{\nTHINKING\n,\n \nHUNGRY\n,\n \nEATING\n}\n \nstate\n[\n5\n];\n\n    \ncondition\n \nself\n[\n5\n];\n\n\n    \nvoid\n \npickup\n(\nint\n \ni\n)\n \n{\n\n        \nstate\n[\ni\n]\n \n=\n \nHUNGRY\n;\n\n        \ntest\n(\ni\n);\n\n        \nif\n \n(\nstate\n[\ni\n]\n \n!=\n \nEATING\n)\n\n            \nself\n[\ni\n].\nwait\n();\n\n    \n}\n\n\n    \nvoid\n \nputdown\n(\nint\n \ni\n)\n \n{\n\n        \nstate\n[\ni\n]\n \n=\n \nTHINKING\n;\n\n        \ntest\n((\ni\n \n+\n \n4\n)\n \n%\n \n5\n);\n      \n// help your right-hand side to run test\n\n        \ntest\n((\ni\n \n+\n \n1\n)\n \n%\n \n5\n);\n      \n// help your left-hand side to run test\n\n    \n}\n\n\n    \nvoid\n \ntest\n(\nint\n \ni\n \n)\n \n{\n\n        \nif\n \n((\nstate\n[(\ni\n \n+\n \n4\n)\n \n%\n \n5\n]\n \n!=\n \nEATING\n)\n \n&&\n       \n// right-hand side\n\n            \n(\nstate\n[\ni\n]\n \n==\n \nHUNGRY\n)\n \n&&\n\n            \n(\nstate\n[(\ni\n \n+\n \n1\n)\n \n%\n \n5\n]\n \n!=\n \nEATING\n))\n \n{\n       \n// left-hand side\n\n            \nstate\n[\ni\n]\n \n=\n \nEATING\n;\n\n            \nself\n[\ni\n].\nsignal\n();\n\n        \n}\n\n    \n}\n\n\n    \ninitialization_code\n()\n \n{\n\n        \nfor\n \n(\nint\n \ni\n \n=\n \n0\n;\n \ni\n \n<\n \n5\n;\n \ni\n++\n)\n\n            \nstate\n[\ni\n]\n \n=\n \nTHINKING\n;\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\n\n$P_i$:\n\n\nDiningPhilosophers\n.\npickup\n(\ni\n);\n\n\n\n/* eat */\n\n\n\nDiningPhilosophers\n.\nputdown\n(\ni\n);\n\n\n\n\n\n\n\n\n\nNo deadlock, but starvation could occur!\n\n\n5.8.3 Implementing a Monitor Using Semaphores\n\u00b6\n\n\n\n\nSemaphores\n\n\nmutex\n: to protect the monitor\n\n\nnext\n: being initialized to zero, on which processes may suspend themselves\n\n\nnext_count\n\n\n\n\n\n\n\n\n\n\n\n\nEach external function \nF\n is replaced by\n\n\nwait\n(\nmutex\n);\n\n\n\n/* body of F */\n\n\n\nif\n \n(\nnext_count\n \n>\n \n0\n)\n\n    \nsignal\n(\nnext\n);\n\n\nelse\n\n    \nsignal\n(\nmutex\n);\n\n\n\n\n\nFor each condition \nx\n, we introduce a semaphore \nx_sem\n and an integer variable \nx_count\n, both initialized to $0$.\n\n\n\n\n\n\nx.wait()\n\n\nx_count\n++\n;\n\n\nif\n \n(\nnext_count\n \n>\n \n0\n)\n\n    \nsignal\n(\nnext\n);\n\n\nelse\n\n    \nsignal\n(\nmutex\n);\n\n\nwait\n(\nx_sem\n);\n\n\nx_count\n--\n;\n\n\n\n\n\n\n\n\n\nx.signal()\n\n\nif\n \n(\nx_count\n \n>\n \n0\n)\n \n{\n      \n/* If there's somebody being waiting */\n\n    \nnext_count\n++\n;\n\n    \nsignal\n(\nx_sem\n);\n\n    \nwait\n(\nnext\n);\n\n    \nnext_count\n--\n;\n\n\n}\n\n\n\n\n\n\n\n\n\n5.8.4 Resuming Processes within a Monitor\n\u00b6\n\n\n\n\n\n\nconditional-wait\n:\n\n\nx\n.\nwait\n(\nc\n);\n\n\n\n\n\nwhere $c$ is a \npriority number\n. When \nx.signal()\n is executed, the process with the smallest priority number is resumed next.\n\n\n\n\n\n\nConsider the \nResourceAllocator\n monitor, which controls the allocation of a single resource among competing processes.\n\n\nmonitor\n \nResourceAllocator\n \n{\n\n    \nboolean\n \nbusy\n;\n\n    \ncondition\n \nx\n;\n\n\n    \nvoid\n \nacquire\n(\nint\n \ntime\n)\n \n{\n\n        \nif\n \n(\nbusy\n)\n\n            \nx\n.\nwait\n(\ntime\n);\n\n        \nbusy\n \n=\n \ntrue\n;\n\n    \n}\n\n\n    \nvoid\n \nrelease\n()\n \n{\n\n        \nbusy\n \n=\n \nfalse\n;\n\n        \nx\n.\nsignal\n();\n\n    \n}\n\n\n    \ninitialization_code\n()\n \n{\n\n        \nbusy\n \n=\n \nfalse\n;\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\n\nA process that needs to access the resource in question must observe the following sequence:\n\n\nR\n.\nacquire\n(\nt\n);\n\n\n\n/* access the resource */\n\n\n\nR\n.\nrelease\n();\n\n\n\n\n\n\n\n\n\nThe monitor concept cannot guarantee that the preceding access sequence will be observed. In particular, the following problems can occur:\n\n\n\n\n\n\nA process might access a resource without first gaining access permission to the resource.\n\n\n\n\n\n\nA process might never release a resource once it has been granted access to the resource.\n\n\n\n\n\n\nA process might attempt to release a resource that it never requested.\n\n\n\n\n\n\nA process might request the same resource twice (without first releasing the resource).\n\n\n\n\n\n\n5.9 Synchronization Examples\n\u00b6\n\n\n5.9.1 Synchronization in Windows\n\u00b6\n\n\n\n\n\n\nGeneral Mechanism\n\n\n\n\nSpin-locking for short code segments in a multiprocessor platform.\n\n\nInterrupt disabling when the kernel accesses global variables in a uniprocessor platform.\n\n\n\n\n\n\n\n\nDispatcher Object\n\n\n\n\nState: signaled or non-signaled\n\n\nMutex: select one process from its waiting queue to the ready queue.\n\n\nCritical-section object \u2014 user-mode mutex\n\n\n\n\n\n\nEvents: like condition variables\n\n\nTimers: select all waiting processes\n\n\n\n\n\n\n\n\n5.9.2 Synchronization in Linux\n\u00b6\n\n\nPreemptive kernel after version 2.6.\n\n\n\n\n\n\nAtomic integer\n\n\natomic_t\n \ncounter\n;\n\n\n...\n\n\natomic_set\n(\n&\ncounter\n,\n \n5\n);\n\n\natomic_add\n(\n10\n,\n \n&\ncounter\n);\n\n\n\n\n\n\n\n\n\nSemaphores for long code segments. Mutex locks for the kernel code.\n\n\n\n\nSping-locking for short code segments in a multiprocessor platform.\n\n\nPreeption disabling and enabling in a uniprocessor platform.\n\n\npreempt_disable()\n and \npreempt_enable()\n\n\npreempt_count\n for each task in the system\n\n\n\n\n\n\n\n\n5.9.3 Synchronization in Solaris\n\u00b6\n\n\n\n\nSemaphores and condition variables\n\n\nAdaptive mutex\n\n\nspin-locking if the lock-holding thread is running; otherwise, blocking is used\n\n\n\n\n\n\nReaders-writers locks\n\n\nexpensive in implementations\n\n\n\n\n\n\nTurnstile\n\n\nA queue structure containing threads blocked on a lock\n\n\nPriotity inversion $\\to$ priority inheritance protocol for kernel threads\n\n\n\n\n\n\n\n\n5.9.4 Pthreads Synchronization\n\u00b6\n\n\n\n\nGeneral Mechanism\n\n\nMutex locks: mutual exclusion\n\n\ncondition variables: monitor\n\n\nRead-write locks\n\n\n\n\n\n\n\n\n5.10 Alternative Approaches\n\u00b6\n\n\n5.10.1 Transactional Memory\n\u00b6\n\n\n\n\nMemory transaction\n\n\nA sequence of memory read-write operations that are atomic.\n\n\n\n\nCommitted or being roleld back:\n\n\nvoid\n \nupdate\n()\n \n{\n\n    \natomic\n \n{\n\n        \n/* modify shared data */\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\nAdvantages:\n\n\nNo deadlock\n\n\nIdentification of potentially concurrently executing statements in atomic blocks\n\n\n\n\n\n\nImplementations:\n\n\nSoftware transaction memory\n\n\nCode is inserted by the \ncompiler\n.\n\n\n\n\n\n\nHardware transactional memory\n\n\nHardware\n cache hierarchies and cache coherency protocols are used.\n\n\n\n\n\n\n\n\n\n\n\n\n5.10.2 OpenMP\n\u00b6\n\n\n\n\nA set of compiler directives and an API\n\n\nThe critical-section compiler directive behaves like a binary semaphore or mutex.\n\n\n\n\n\n\n\n\nvoid\n \nupdate\n()\n \n{\n\n    \n#pragma omp critical {\n\n        \ncounter\n \n+=\n \nvalue\n;\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\npros: easy to use\n\n\ncons: identification of protected code and potentials of deadlocks\n\n\n\n\n5.10.3 Functional Programming Languages\n\u00b6",
            "title": "Chapter 5 Process Synchronization"
        },
        {
            "location": "/OS/Chap05/#chapter-5-process-synchronization",
            "text": "",
            "title": "Chapter 5 Process Synchronization"
        },
        {
            "location": "/OS/Chap05/#51-background",
            "text": "Recall  producer\u2013consumer problem . We modify it as follows:  while   ( true )   { \n     /* produce an item in next_produced */ \n\n     while   ( counter   ==   BUFFER_SIZE )   ;      // do nothing \n\n     buffer [ in ]   =   next_produced ; \n     in   =   ( in   +   1 )   %   BUFFER_SIZE ; \n     counter ++ ;  }   while   ( true )   { \n     while   ( counter   ==   0 )   ;        // do nothing \n\n     next_consumed   =   buffer [ out ]; \n     out   =   ( out   +   1 )   %   BUFFER_SIZE ; \n     counter -- ; \n\n     /* consume the item in next_consumed */  }   Suppose  counter == 5  initially. After executing  counter++  in producer or  counter--  in consumer. The value of  counter  may be $4$, $5$, or $6$!  \\begin{array}{lllll}\nT_0: producer & \\text{execute} & register_1 = \\text{counter} & \\{register_1 = 5\\} \\\\\nT_1: producer & \\text{execute} & register_1 = register_1 + 1 & \\{register_1 = 6\\} \\\\\nT_2: consumer & \\text{execute} & register_2 = \\text{counter} & \\{register_2 = 5\\} \\\\\nT_3: consumer & \\text{execute} & register_2 = register_2 - 1 & \\{register_2 = 4\\} \\\\\nT_4: producer & \\text{execute} & \\text{counter} = register_1 & \\{counter = 6\\} \\\\\nT_5: consumer & \\text{execute} & \\text{counter} = register_2 & \\{counter = 4\\}\n\\end{array}   Race condition  Several processes access and manipulate the same data concurrently and the outcome of the execution depends on the  particular order  in which the access takes place.   We need to ensure that only one process at a time can be manipulating the variable  counter .",
            "title": "5.1 Background"
        },
        {
            "location": "/OS/Chap05/#52-the-critical-section-problem",
            "text": "Critical section  In which the process may be changing common variables, updating a table, writing a file, and so on.   do   { \n     /* entry section */ \n         /* critical section */ \n     /* exit section */ \n         /* remainder section */  }   while   ( true );   A solution to the critical-section problem must satisfy:   Mutual exclusion  Progress . Cannot be postponed indefinitely.  Bounded waiting   Two general approches are used to handle critical sections:   Preemptive kernels  Nonpreemptive kernels   Why anyone favor a preemptive kernel over a nonpreemptive one?   Responsive.  More suitable for real-time programming.",
            "title": "5.2 The Critical-Section Problem"
        },
        {
            "location": "/OS/Chap05/#53-petersons-solution",
            "text": "Peterson's solution is restricted to two processes that alternate execution between their critical sections and remainder sections. The processes are named $P_i$ and $P_j$.  Shared data items:  int   turn ;  boolean   flag [ 2 ];   do   { \n     flag [ i ]   =   true ; \n     turn   =   j ; \n     while   ( flag [ j ]   &&   turn   ==   j )   ; \n     /* critical section */ \n\n     flag [ i ]   =   false ; \n     /* remainder section */  }   while   ( true );    If both processes try to enter at the same time,  turn  will be set to both $i$ and $j$ at roughly the same time.  Only one of these assignments will last.   Proof   Mutual exclusion is preserved.  The progress requirement is satisfied.   The bounded-waiting requirement is met.  Suppose $P_i$ execute $turn = j$ first, then $P_j$ execute $turn = i$. In this assumption, $P_i$ will enter its critical section first and $P_j$ will be stucked in the  while(flag[i] && turn == i  (remember that here  i  should be thinked as  j  in the code!). After $P_i$ entering exit section, there are two possibilities:   $P_i$ sets  flag[i] = false , then $P_j$ enters its critical section.  After $P_i$ setting  flag[i] = false , it immediately sets  flag[i] = true  again, consequently, it'll set  turn = j , thus $P_j$ still can enter its critical section.",
            "title": "5.3 Peterson's Solution"
        },
        {
            "location": "/OS/Chap05/#bakery-algorithm",
            "text": "Originally designed for distrubuted systems  Processes which are ready to enter their critical section must take a number and wait till the number becomes the lowest.   int   number [ i ];            // Pi's number if it is nonzeros  boolean   choosing [ i ];      // Pi is taking a number   do   { \n     choosing [ i ]   =   true ;           // A process want to enter its critical section \n     number [ i ]   =   max ( number [ 0 ],   ...,   number [ n   -   1 ])   +   1 ; \n     choosing [ j ]   =   false ;          // A process has got its number \n     for   ( int   j   =   0 ;   j   <   n ;   j ++ )   { \n         while   ( choosing [ j ])   ; \n         while   ( number [ j ]   !=   0   &&   ( number [ j ],   j )   <   ( number [ i ],   i ))   ;       // If two processes got the same number, then we should compare their indices \n     } \n     /* critical section */ \n\n     number [ i ]   =   0 ; \n     /* remainder section */  }   white   ( true );    An observation: If $P_i$ is in its critical section, and $P_k (k \\ne i)$ , then $(number[i], i) < (number[k], k)$.   Proof   Mutual exclusion: Only the process holds the lowest number can enter the critical section. For each process, when that process doens't get its number, the original process will be stucked in the first while-loop. After that process getting its number, we still need to compare their $numbers$ and $indices$.  Progress requirement: The processes won't be forever postponed.  Bounded-waiting: Assume that a process holds the biggest number, it should wait other processes in the second while-loop. But after all other process entering their exit section and again entering their entry section, they'll get a bigger number, thus the process won't wait forever.",
            "title": "Bakery Algorithm"
        },
        {
            "location": "/OS/Chap05/#54-synchronization-hardware",
            "text": "Disaple interrupt $\\to$ No preemption:   Infeasible in multiprocessor environment.  Potential impacts on interrupt-driven system clocks.    Atomic  Modern computer allow us either to test and modify the content of a word or to swap the contents of two words  atomically \u2014that is, as one uninterruptible.   Although following algorithms satisfy the mutual-exclusion requirement, they don't satisfy the bounded-waiting requirement.  boolean   test_and_set ( boolean   * target )   { \n     boolean   rv   =   * target ; \n     * target   =   true ; \n\n     return   rv ;  }   do   { \n     while   ( test_and_set ( & lock ))   ; \n     /* critical section */ \n\n     lock   =   false ; \n     /* remainder section */  }   while   ( true );   The first process executing  while (test_and_set(&lock))  will set the address value of  lock  to  true  and get the return value  rv = false , thus it won't be stucked in the while-loop and it can enter its critical section.   Mutual exclusion: OK  Progress requirement: OK   Bounded-waiting: FAIL  Assume there is only one CPU, after $P_i$ entering its critical section, $P_j$ will be stucked in the while-loop. After $P_i$ exiting its critical section, there are two possibilities:   $P_i$ sets  lock = false , the CPU context switch to $P_j$, thus $P_j$ can enters its critical section.  After $P_i$ setting  lock = false , the CPU still executes the code of $P_i$, thus $P_i$ enters its critical section again, so $P_j$ may wait forever.     void   swap ( boolean   * a ,   boolean   * b )   { \n     boolean   temp   =   * a ; \n     * a   =   * b ; \n     * b   =   temp ;  }   do   { \n     key   =   true ; \n     while   ( key   ==   true ) \n         swap ( & lock ,   & key ); \n     /* critical section */ \n\n     lock   =   false ; \n     /* remainder section */  }   while   ( true );    Mutual exclusion: OK  Progress requirement: OK  Bounded-waiting: FAIL (the reason is like above)   int   compare_and_swap ( int   * value ,   int   expected ,   int   new_value )   { \n     int   temp   =   * value ; \n\n     if   ( * value   ==   expected ) \n         * value   =   new_value ; \n\n     return   temp ;  }   do   { \n     while   ( compare_and_swap ( & lock ,   0 ,   1 )   !=   0 )   ; \n     /* critical section */ \n\n     lock   =   0 ; \n     /* remainder section */  }   while   ( true );   Following algorithms satisfies all the critical-section requirements.  boolean   waiting [ n ];  boolean   lock ;   do   { \n     waiting [ i ]   =   true ; \n     key   =   true ; \n     while   ( waiting [ i ]   &&   key ) \n         key   =   test_and_set ( & lock ); \n     waiting [ i ]   =   false ; \n     /* critical section */ \n\n     j   =   ( i   +   1 )   %   n ;                      // Assign its next process \n     while   (( j   !=   i )   &&   ! waiting [ j ])       // Find a following process who is waiting \n         j   =   ( j   +   1 )   %   n ; \n\n     if   ( j   ==   i )                           // If no process is waiting \n         lock   =   false ; \n     else \n         waiting [ j ]   =   false ;               // Thus line 4 will be false and Pj won't be stucked anymore \n     /* remainder section */  }   while   ( true );   boolean   test_and_set ( boolean   * target )   { \n     boolean   rv   =   * target ; \n     * target   =   true ; \n\n     return   rv ;  }   Assume  lock  is initialized to  false .   Mutual exclusion: If many processes set their  waiting[i] = true , after the first process execute  key = test_and_set(&lock) ,  key  will be set to  false  and  lock  will be set to  true . Therefore, other processes will be stucked in  while (waiting[i] && key)  since their  key  will be set to  true  after  test_and_set(&lock)  ( lock  is now  true ).  Progress requirement: Only the process first run  test_and_set  can enter its critical section.  Bounded-waiting: Wait at most $n - 1$ times.",
            "title": "5.4 Synchronization Hardware"
        },
        {
            "location": "/OS/Chap05/#mutex-locks",
            "text": "A high-level software solution to provide protect critical sections with mutual exclusion.   Atomic execution of  acquire()  and  release() .  Spinlock:  pros: No context switch for multiprocessor systems.  cons: Busy waiting.     acquire ()   { \n     while   ( ! available )   ;          // busy wait \n     available   =   false ;  }   release ()   { \n     available   =   true ;  }   do   { \n     // acquire lock \n         /* critical section */ \n     // release lock \n         /* remainder section */  }   while   ( true );    Spinlock  The process \"spins\" while waiting for the lock to become available.",
            "title": "Mutex Locks"
        },
        {
            "location": "/OS/Chap05/#56-semaphores",
            "text": "A high-level solution for more complex problems.   A variable  S  only accessible by two atomic operations  Spinlock   wait ( S )   {                 /* P */ \n     while   ( S   <=   0 )   ;      // busy wait \n     S -- ;  }   signal ( S )   {               /* V */ \n     S ++ ;  }",
            "title": "5.6 Semaphores"
        },
        {
            "location": "/OS/Chap05/#561-semaphore-usage",
            "text": "Critical sections:  do   { \n     wait ( mutex ); \n     /* critical section */ \n     signal ( mutex ); \n     /* remainder section */  }   while   ( true );     Precedence enforcement:    $P_1$:  S1 ;  signal ( synch );     $P_2$:  wait ( synch );  S2 ;",
            "title": "5.6.1 Semaphore Usage"
        },
        {
            "location": "/OS/Chap05/#562-semaphore-implementation",
            "text": "It's not good for single CPU.\nEven if it's implemented in a multi-CPU environment, the locks should be held for a short time.  We can implement the Semaphores with block waiting:  typedef   struct   { \n     int   value ; \n     struct   process   * list ;  }   semaphore ;   wait ( semaphore   * S )   { \n     S -> value -- ; \n     if   ( S -> value   <   0 )   { \n         add   this   process   to   S -> list ; \n         block (); \n     }  }   signal ( semaphore   * S )   { \n     S -> value ++ ; \n     if   ( S -> value   <=   0 )   { \n         remove   a   process   P   from   S -> list ; \n         wakeup ( P ); \n     }  }    $|S.value|$ = # of waiting processes if $S.value < 0$.   Bounded-waiting can be satisfied by FIFO queue but may be unsatisfied by priority queue.",
            "title": "5.6.2 Semaphore Implementation"
        },
        {
            "location": "/OS/Chap05/#563-deadlocks-and-starvation",
            "text": "Deadlock  A set of processes is in a deadlock state when every process in the set is waiting for an event that can be caused only by another process in the set.   \\begin{array}{cc}\nP_0 & P_1 \\\\\nwait(S); & wait(Q); \\\\\nwait(Q); & wait(S); \\\\\n\\vdots & \\vdots \\\\\nsignal(S); & signal(Q); \\\\\nsignal(Q); & signal(S); \\\\\n\\end{array}  Deadlock may happen (assume $S = 1$ and $Q = 1$:    $P_0$ calls $wait(S)$  $P_1$ calls $wait(Q)$  $P_1$ calls $wait(S)$  $P_0$ calls $wait(Q)$    Starvation (Indefinite blocking)  A situation in which processes wait indefinitely within the semaphore.  e.g. priority queue, stack (LIFO).",
            "title": "5.6.3 Deadlocks and Starvation"
        },
        {
            "location": "/OS/Chap05/#564-priority-inversion",
            "text": "Priority Inversion  A higher-priority task is blocked by a lower-priority task due to some resource access conflict.",
            "title": "5.6.4 Priority Inversion"
        },
        {
            "location": "/OS/Chap05/#binary-semaphore",
            "text": "We can implement counting semaphores by binary semaphores. ($S_1 = 1$, $S_2 = 0$ and $S_3 = 1$)  WAIT ( S )   { \n     wait ( S3 );     // protect the whole program \n     wait ( S1 );     // protect C \n     C -- ; \n     if   ( C   <   0 )   { \n         signal ( S1 ); \n         wait ( S2 ); \n     }   else   signal ( S1 ); \n     signal ( S3 );  }   SIGNAL ( S )   { \n     wait ( S1 ); \n     C ++ ; \n     if   ( C   <=   0 ) \n         signal ( S2 );       // wake up \n     signal ( S1 );  }    Is  wait(S3)  necessary?  Can we change the order of  signal(S1)  and  wait(S2) ?  There are lots of implementation details.",
            "title": "Binary Semaphore"
        },
        {
            "location": "/OS/Chap05/#57-classic-problems-of-synchronization",
            "text": "",
            "title": "5.7 Classic Problems of Synchronization"
        },
        {
            "location": "/OS/Chap05/#571-the-bounded-buffer-problem",
            "text": "int   n ;  semaphore   mutex   =   1 ;  semaphore   empty   =   n ;  semaphore   full   =   0 ;     Producer:  do   { \n     /* produce an item in next_produced */ \n\n     wait ( empty ); \n     wait ( mutex ); \n\n     /* add next_produced to the buffer */ \n\n     signal ( mutex ); \n     signal ( full );  }   while   ( true );     Consumer:  do   { \n     wait ( full ); \n     wait ( mutex ); \n\n     /* remove an item from buffer to next_consumed */ \n\n     signal ( mutex ); \n     signal ( empty ); \n\n     /* consume the item in next_consumed */  }   while   ( true );",
            "title": "5.7.1 The Bounded-Buffer Problem"
        },
        {
            "location": "/OS/Chap05/#572-the-readerswriters-problem",
            "text": "The basic assumption:   Readers: shared locks  Writers: exclusive locks     The first reader-writers problem   No readers will be kept waiting unless a writer has already obtained permission to use the shared object $\\to$ potential hazard to writers!     The second reader-writers problem   One a writer is ready, it performs its write asap $\\to$ potential hazard to readers.     semaphore   rw_mutex   =   1 ;  semaphore   mutex   =   1 ;  int   read_count   =   0 ;   do   { \n     wait ( rw_mutex ); \n\n     /* writing is performed */ \n\n     signal ( rw_mutex );  }   while   ( true );   do   { \n     wait ( mutex );          // protect read_count \n     read_count ++ ; \n     if   ( read_count   ==   1 ) \n         wait ( rw_mutex ); \n     signal ( mutex ); \n\n     /* reading is performed */ \n\n     wait ( mutex );          // protect read_count \n     read_count -- ; \n     if   ( read_count   ==   0 ) \n         signal ( rw_mutex ); \n     signal ( mutex );  }   while   ( true );",
            "title": "5.7.2 The Readers\u2013Writers Problem"
        },
        {
            "location": "/OS/Chap05/#573-the-dining-philosophers-problem",
            "text": "Each philosopher must pick up one chopstick beside him/her at a time.  When two chopsticks are picked up, the philosopher can eat.   semaphore   chopstick [ 5 ];   do   { \n     wait ( chopstick [ i ]); \n     wait ( chopstick [( i   +   1 )   %   5 ]); \n\n     /* eat for awhile */ \n\n     signal ( chopstick [ i ]); \n     signal ( chopstick [( i   +   1 )   %   5 ]); \n\n     /* think for awhile */  }   while   ( true );",
            "title": "5.7.3 The Dining-Philosophers Problem"
        },
        {
            "location": "/OS/Chap05/#critical-regions",
            "text": "Region $v$ when $C$ (condition) do $S$ (statements)  Variable $v$ \u2014 shared among processes and only accessible in the region.     struct   buffer   { \n     item   pool [ n ]; \n     int   count ,   in ,   out ;  };     Producer:  region   buffer   when  ( count   <   n )   { \n     pool [ in ]   =   next_produced ; \n     in   =   ( in   +   1 )   %   n ; \n     count ++ ;  }     Consumer:  region   buffer   when  ( count   >   0 )   { \n     next_consumed   =   pool [ out ]; \n     out   =   ( out   +   1 )   %   n ; \n     count -- ;  }",
            "title": "Critical Regions"
        },
        {
            "location": "/OS/Chap05/#58-monitors",
            "text": "monitor   monitor   name   { \n     /* shared variable declarations */ \n\n     function   P1   (   .   .   .   )   { \n         .   .   . \n     } \n\n     function   P2   (   .   .   .   )   { \n         .   .   . \n     } \n\n         . \n         . \n         . \n     function   Pn   (   .   .   .   )   { \n         .   .   . \n     } \n\n     initialization_code   (   .   .   .   )   { \n         .   .   . \n     }  }",
            "title": "5.8 Monitors"
        },
        {
            "location": "/OS/Chap05/#581-monitor-usage",
            "text": "An abstract data type\u2014or ADT\u2014encapsulates data with a set of functions to operate on that data that are independent of any specific implementation of the ADT.  The monitor construct ensures that only one process at a time is active within the monitor.  A programmer who needs to write a tailor-made synchronization scheme can define one or more variables of type $condition$:       condition   x ,   y ;   The only operations that can be invoked on a condition variable are  wait()  and  signal() . The operation       x . wait ();   means that the process invoking this operation is suspended until another process invokes       x . signal ();    Condition variables (of a monitor) vs. signal operation (of binary semaphore)  The  x.signal()  operation resumes exactly one suspended process. If no process is suspended, then the  signal()  operation has no effect; that is, the state of  x  is the same as if the operation had never been executed. Contrast this operation with the  signal()  operation associated with semaphores, which always affects the state of the semaphore.   Suppose that, when the  x.signal()  operation is invoked by a process  P , there exists a suspended process  Q  associated with condition  x . Clearly, if the suspended process  Q  is allowed to resume its execution, the signaling process  P  must wait. Two possibilities exist:    Signal and wait :  P  either waits until  Q  leaves the monitor or waits for another condition.    Signal and continue :  Q  either waits until  P  leaves the monitor or waits for another condition.",
            "title": "5.8.1 Monitor Usage"
        },
        {
            "location": "/OS/Chap05/#582-dining-philosophers-solution-using-monitors",
            "text": "enum   { THINKING ,   HUNGRY ,   EATING }   state [ 5 ];  condition   self [ 5 ];   monitor   DiningPhilosophers   { \n     enum   { THINKING ,   HUNGRY ,   EATING }   state [ 5 ]; \n     condition   self [ 5 ]; \n\n     void   pickup ( int   i )   { \n         state [ i ]   =   HUNGRY ; \n         test ( i ); \n         if   ( state [ i ]   !=   EATING ) \n             self [ i ]. wait (); \n     } \n\n     void   putdown ( int   i )   { \n         state [ i ]   =   THINKING ; \n         test (( i   +   4 )   %   5 );        // help your right-hand side to run test \n         test (( i   +   1 )   %   5 );        // help your left-hand side to run test \n     } \n\n     void   test ( int   i   )   { \n         if   (( state [( i   +   4 )   %   5 ]   !=   EATING )   &&         // right-hand side \n             ( state [ i ]   ==   HUNGRY )   && \n             ( state [( i   +   1 )   %   5 ]   !=   EATING ))   {         // left-hand side \n             state [ i ]   =   EATING ; \n             self [ i ]. signal (); \n         } \n     } \n\n     initialization_code ()   { \n         for   ( int   i   =   0 ;   i   <   5 ;   i ++ ) \n             state [ i ]   =   THINKING ; \n     }  }     $P_i$:  DiningPhilosophers . pickup ( i );  /* eat */  DiningPhilosophers . putdown ( i );     No deadlock, but starvation could occur!",
            "title": "5.8.2 Dining-Philosophers Solution Using Monitors"
        },
        {
            "location": "/OS/Chap05/#583-implementing-a-monitor-using-semaphores",
            "text": "Semaphores  mutex : to protect the monitor  next : being initialized to zero, on which processes may suspend themselves  next_count       Each external function  F  is replaced by  wait ( mutex );  /* body of F */  if   ( next_count   >   0 ) \n     signal ( next );  else \n     signal ( mutex );   For each condition  x , we introduce a semaphore  x_sem  and an integer variable  x_count , both initialized to $0$.    x.wait()  x_count ++ ;  if   ( next_count   >   0 ) \n     signal ( next );  else \n     signal ( mutex );  wait ( x_sem );  x_count -- ;     x.signal()  if   ( x_count   >   0 )   {        /* If there's somebody being waiting */ \n     next_count ++ ; \n     signal ( x_sem ); \n     wait ( next ); \n     next_count -- ;  }",
            "title": "5.8.3 Implementing a Monitor Using Semaphores"
        },
        {
            "location": "/OS/Chap05/#584-resuming-processes-within-a-monitor",
            "text": "conditional-wait :  x . wait ( c );   where $c$ is a  priority number . When  x.signal()  is executed, the process with the smallest priority number is resumed next.    Consider the  ResourceAllocator  monitor, which controls the allocation of a single resource among competing processes.  monitor   ResourceAllocator   { \n     boolean   busy ; \n     condition   x ; \n\n     void   acquire ( int   time )   { \n         if   ( busy ) \n             x . wait ( time ); \n         busy   =   true ; \n     } \n\n     void   release ()   { \n         busy   =   false ; \n         x . signal (); \n     } \n\n     initialization_code ()   { \n         busy   =   false ; \n     }  }     A process that needs to access the resource in question must observe the following sequence:  R . acquire ( t );  /* access the resource */  R . release ();     The monitor concept cannot guarantee that the preceding access sequence will be observed. In particular, the following problems can occur:    A process might access a resource without first gaining access permission to the resource.    A process might never release a resource once it has been granted access to the resource.    A process might attempt to release a resource that it never requested.    A process might request the same resource twice (without first releasing the resource).",
            "title": "5.8.4 Resuming Processes within a Monitor"
        },
        {
            "location": "/OS/Chap05/#59-synchronization-examples",
            "text": "",
            "title": "5.9 Synchronization Examples"
        },
        {
            "location": "/OS/Chap05/#591-synchronization-in-windows",
            "text": "General Mechanism   Spin-locking for short code segments in a multiprocessor platform.  Interrupt disabling when the kernel accesses global variables in a uniprocessor platform.     Dispatcher Object   State: signaled or non-signaled  Mutex: select one process from its waiting queue to the ready queue.  Critical-section object \u2014 user-mode mutex    Events: like condition variables  Timers: select all waiting processes",
            "title": "5.9.1 Synchronization in Windows"
        },
        {
            "location": "/OS/Chap05/#592-synchronization-in-linux",
            "text": "Preemptive kernel after version 2.6.    Atomic integer  atomic_t   counter ;  ...  atomic_set ( & counter ,   5 );  atomic_add ( 10 ,   & counter );     Semaphores for long code segments. Mutex locks for the kernel code.   Sping-locking for short code segments in a multiprocessor platform.  Preeption disabling and enabling in a uniprocessor platform.  preempt_disable()  and  preempt_enable()  preempt_count  for each task in the system",
            "title": "5.9.2 Synchronization in Linux"
        },
        {
            "location": "/OS/Chap05/#593-synchronization-in-solaris",
            "text": "Semaphores and condition variables  Adaptive mutex  spin-locking if the lock-holding thread is running; otherwise, blocking is used    Readers-writers locks  expensive in implementations    Turnstile  A queue structure containing threads blocked on a lock  Priotity inversion $\\to$ priority inheritance protocol for kernel threads",
            "title": "5.9.3 Synchronization in Solaris"
        },
        {
            "location": "/OS/Chap05/#594-pthreads-synchronization",
            "text": "General Mechanism  Mutex locks: mutual exclusion  condition variables: monitor  Read-write locks",
            "title": "5.9.4 Pthreads Synchronization"
        },
        {
            "location": "/OS/Chap05/#510-alternative-approaches",
            "text": "",
            "title": "5.10 Alternative Approaches"
        },
        {
            "location": "/OS/Chap05/#5101-transactional-memory",
            "text": "Memory transaction  A sequence of memory read-write operations that are atomic.   Committed or being roleld back:  void   update ()   { \n     atomic   { \n         /* modify shared data */ \n     }  }    Advantages:  No deadlock  Identification of potentially concurrently executing statements in atomic blocks    Implementations:  Software transaction memory  Code is inserted by the  compiler .    Hardware transactional memory  Hardware  cache hierarchies and cache coherency protocols are used.",
            "title": "5.10.1 Transactional Memory"
        },
        {
            "location": "/OS/Chap05/#5102-openmp",
            "text": "A set of compiler directives and an API  The critical-section compiler directive behaves like a binary semaphore or mutex.     void   update ()   { \n     #pragma omp critical { \n         counter   +=   value ; \n     }  }    pros: easy to use  cons: identification of protected code and potentials of deadlocks",
            "title": "5.10.2 OpenMP"
        },
        {
            "location": "/OS/Chap05/#5103-functional-programming-languages",
            "text": "",
            "title": "5.10.3 Functional Programming Languages"
        },
        {
            "location": "/OS/Chap06/",
            "text": "Chapter 6 CPU Scheduling\n\u00b6\n\n\n6.1 Basic Concepts\n\u00b6\n\n\nThe objective of multiprogramming is to have some process running at all times, to maximize CPU utilization.\n\n\nA process is executed until it must wait, typically for the completion of some I/O request.\n\n\n6.1.1 CPU\u2013I/O Burst Cycle\n\u00b6\n\n\nProcess execution = cycle of CPU + I/O wait.\n\n\n\n\n6.1.2 CPU Scheduler\n\u00b6\n\n\nShort-term scheduler\n (CPU scheduler): select process in the ready queue.\n\n\n6.1.3 Preemptive Scheduling\n\u00b6\n\n\nCPU-scheduling decisions when a process:\n\n\n\n\n(nonpreemptive) Switches from the running state $\\to$ the waiting state (e.g. I/O request, \nwait()\n for child)\n\n\n(preemptive) Switches from the running state $\\to$ the ready state (e.g. interrupt)\n\n\n(preemptive) Switches from the waiting state $\\to$ the ready state (e.g. completion of I/O)\n\n\n(nonpreemptive) Terminates\n\n\n\n\n6.1.4 Dispatcher\n\u00b6\n\n\n\n\nDispatcher\n\n\nThe module that gives control of the CPU to \nthe process selected by the short-term scheduler\n. It should be fast.\n\n\n\n\n\n\nSwitching context\n\n\nSwitching to user mode\n\n\nJumping to the proper location in the user program to restart that program\n\n\n\n\n\n\nDispatch latency\n\n\nThe time it takes for the dispatcher to stop one process and start another running.\n\n\nStop a process $\\leftrightarrow$ Start a process\n\n\n\n\n6.2 Scheduling Criteria\n\u00b6\n\n\n\n\nCPU utilization\n\n\nThroughput\n\n\nTurnaround time\n: $\\text{Completion Time} - \\text{Start Time}$.\n\n\nWaiting time\n: The sum of the periods spent waiting in the ready queue.\n\n\nResponse time\n\n\n\n\n6.3 Scheduling Algorithms\n\u00b6\n\n\n6.3-1 First-Come, First-Served Scheduling\n\u00b6\n\n\n\n\nThe process which requests the CPU first is allocated the CPU.\n\n\n\n\nProperties:\n\n\n\n\nNonpreemptive FCFS.\n\n\nCPU might be hold for an extended period.\n\n\n\n\n\n\n\n\nCritical problem: Convoy effect!\n\n\n\n\n\n\nExample:\n\n\n\n\n\n\nGiven processes:\n\n\n\n\n\n\n\n\nProcess\n\n\nBusrt Time\n\n\n\n\n\n\n\n\n\n\n$P_1$\n\n\n24\n\n\n\n\n\n\n$P_2$\n\n\n3\n\n\n\n\n\n\n$P_3$\n\n\n3\n\n\n\n\n\n\n\n\n\n\n\n\nConsider order: $P_1 \\to P_2 \\to P_3$:\n\n\n\n\n\n\nGantt chart:\n\n\n\n\n\n\n\n\nAverage waiting time = (0 + 24 + 27) / 3 = 17 ms.\n\n\n\n\n\n\n\n\n\n\nConsider order: $P_2 \\to P_3 \\to P_1$:\n\n\n\n\n\n\nGantt chart:\n\n\n\n\n\n\n\n\nAverage waiting time = (0 + 3 + 6) / 3 = 9 ms.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConvoy effect\nAll the other processes wait for the one big process to get off the CPU.\n\n\n\n\n\n\n6.3.2 Shortest-Job-First Scheduling\n\u00b6\n\n\n\n\n\n\nProperties:\n\n\n\n\nNonpreemptive SJF\n\n\nShortest-next-CPU-burst first\n\n\n\n\n\n\n\n\nProblem: Measure the future!\n\n\n\n\n\n\nExample 1:\n\n\n\n\n\n\nGiven processes:\n\n\n\n\n\n\n\n\nProcess\n\n\nBurst Time\n\n\n\n\n\n\n\n\n\n\n$P_1$\n\n\n6\n\n\n\n\n\n\n$P_2$\n\n\n8\n\n\n\n\n\n\n$P_3$\n\n\n7\n\n\n\n\n\n\n$P_4$\n\n\n3\n\n\n\n\n\n\n\n\n\n\n\n\nBy SJF scheduling:\n\n\n\n\n\n\nGantt chart:\n\n\n\n\n\n\n\n\nAverage waiting time = (3 + 16 + 9 + 0) / 4 = 7 ms.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSJF is used frequently in long-term (job) scheduling, but it cannot be implemented at the level of short-term CPU scheduling.\n\n\n\n\n\n\nExponential average\n\n\nLet $t_n$ be time of $n$th CPU burst, and $\\tau_{n + 1}$ be the next CPU burst.\n\n\n\\begin{align}\n\\tau_{n + 1} & = \\alpha t_n + (1 - \\alpha)\\tau_n, \\quad 0 \\le \\alpha \\le 1. \\\\\n             & = \\alpha t_n + (1 - \\alpha)\\alpha t_{n - 1} + \\cdots + (1 - \\alpha)^j \\alpha t_{n - j} + \\cdots + (1 - \\alpha)^{n + 1}\\tau_0.\n\\end{align}\n\n\n\n\n\n\n\n\nExample 2:\n\n\n\n\n\n\nGiven processes:\n\n\n\n\n\n\n\n\nProcess\n\n\nArrival Time\n\n\nBurst Time\n\n\n\n\n\n\n\n\n\n\n$P_1$\n\n\n0\n\n\n8\n\n\n\n\n\n\n$P_2$\n\n\n1\n\n\n4\n\n\n\n\n\n\n$P_3$\n\n\n2\n\n\n9\n\n\n\n\n\n\n$P_4$\n\n\n3\n\n\n5\n\n\n\n\n\n\n\n\n\n\n\n\nBy preemptive SJF scheduling:\n\n\n\n\n\n\nGantt chart:\n\n\n\n\n\n\n\n\nAverage waiting time = [(10 - 1) + (1 - 1) + (17 - 2) + (5 - 3)] / 4 = 26 / 4 = 6.5 ms.\n\n\n\n\n\n\n\n\n\n\n6.3.3 Priority Scheduling\n\u00b6\n\n\n\n\n\n\nProperties: \n\n\n\n\nCPU is assigned to the process with the highest priority \u2014 A framework for various scheduling algorithms:\n\n\nFCFS: Equal-priority with tie-breaking\n\n\nSJF: Priority = 1 / next CPU burst length\n\n\n\n\n\n\n\n\n\n\n\n\nExample:\n\n\n\n\n\n\nGiven processes:\n\n\n\n\n\n\n\n\nProcess\n\n\nBurst Time\n\n\nPriority\n\n\n\n\n\n\n\n\n\n\n$P_1$\n\n\n10\n\n\n3\n\n\n\n\n\n\n$P_2$\n\n\n1\n\n\n1\n\n\n\n\n\n\n$P_3$\n\n\n2\n\n\n4\n\n\n\n\n\n\n$P_4$\n\n\n1\n\n\n5\n\n\n\n\n\n\n$P_5$\n\n\n5\n\n\n2\n\n\n\n\n\n\n\n\n\n\n\n\nBy preemptive SJF scheduling:\n\n\n\n\n\n\nGantt chart:\n\n\n\n\n\n\n\n\nAverage waiting time = (6 + 0 + 16 + 18 + 1) / 5 = 8.2 ms.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem with priority scheduling\n\n\n\n\nindefinite blocking: low-priority processes could starve to death!\n\n\nstarvation\n\n\n\n\n\n\n\n\nAging\n\n\nAging gradually increase the priority of processes that wait in the system for a long time.\n\n\n\n\n6.3.4 Round-Robin Scheduling\n\u00b6\n\n\n\n\nRR is similar to FCFS except that preemption is added to switch between processes.\n\n\n\n\nGoal: fairness, time sharing.\n\n\n\n\n\n\nExample:\n\n\n\n\n\n\nGiven processes with quantum = 4ms:\n\n\n\n\n\n\n\n\nProcess\n\n\nBurst Time\n\n\n\n\n\n\n\n\n\n\n$P_1$\n\n\n24\n\n\n\n\n\n\n$P_2$\n\n\n3\n\n\n\n\n\n\n$P_3$\n\n\n3\n\n\n\n\n\n\n\n\n\n\n\n\nGantt chart:\n\n\n\n\n\n\n\n\nAverage waiting time = [(10 - 4) + 4 + 7] / 3 = 5.66 ms.\n\n\n\n\n\n\n\n\n\n\n\n\nAlthough the time quantum should be large compared with the context switch time, it should not be too large.\n\n\n\n\n6.3.5 Multilevel Queue Scheduling\n\u00b6\n\n\n\n\n\n\nIntra-queue scheduling\n\n\n\n\nIndependent choice of scheduling algorithms\n\n\n\n\n\n\n\n\nInter-queue scheduling\n\n\n\n\nFixed-priority preemptive scheduling\n\n\ne.g., foreground queues always have absolute priority over the background queues.\n\n\n\n\n\n\nTime slice between queues\n\n\ne.g., 80% CPU is given to foreground processes, and 20% CPU is given to background processes.\n\n\n\n\n\n\n\n\n\n\n\n\nEach queue has absolute priority over lower-priority queues.\n\n\nIf an interactive editing process entered the ready queue while a batch process was running, the batch process would be preempted.\n\n\n\n\n6.3.6 Multilevel Feedback Queue Scheduling\n\u00b6\n\n\n\n\nMultilevel feedback queue allows a process to move between queues.\n\n\n\n\nA multilevel feedback queue is defined by:\n\n\n\n\n#queues\n\n\nThe scheduling algorithm for each queue\n\n\n\n\nThe method used to determine when to \n\n\n\n\nupgrade a process to a higher priority queue\n\n\ndemote a process to a lower priority queue\n\n\n\n\n\n\n\n\nThe method used to determine which queue a process will enter when that process needs service\n\n\n\n\n\n\n6.4 Thread Scheduling\n\u00b6\n\n\n6.4.1 Contention Scope\n\u00b6\n\n\n\n\nProcess Contention Scope (PCS)\n\n\nOn systems implementing the \nmany-to-one\n and \nmany-to-many\n models, the thread library schedules user-level threads to run on an available LWP, since competition for the CPU takes place among threads belonging to the same process.\n\n\nIt is important to note that PCS will typically preempt the thread currently running in favor of a higher-priority thread\n\n\n\n\n\n\nSystem Contention Scope (SCS)\n\n\nCompetition for the CPU with SCS scheduling takes place among all threads in the system. Systems using the \none-to-one\n model.\n\n\n\n\n6.4.2 Pthread Scheduling\n\u00b6\n\n\n\n\nPCS: \nPTHREAD_SCOPE_PROCESS\n\n\nSCS: \nPTHREAD_SCOPE_SYSTEM\n\n\n\n\n2 methods:\n\n\n\n\npthread_attr_setscope(pthread attr_t *attr, int scope)\n\n\npthread_attr_getscope(pthread attr_t *attr, int *scope)\n\n\n\n\n6.5 Multiple-Processor Scheduling\n\u00b6\n\n\n6.5.1 Approaches to Multiple-Processor Scheduling\n\u00b6\n\n\n\n\nAsymmetric multiprocessing\n: only \nthe master server\n process accesses the system data structures, reducing the need for data sharing.\n\n\nSymmetric multiprocessing (SMP)\n: each processor is self-scheduling.\n\n\n\n\n6.5.2 Processor Affinity\n\u00b6\n\n\n\n\nProcessor Affinity\n\n\nA process has an affinity for the processor on which it is currently running.\n\n\n\n\n\n\nSoft affinity\n\n\nHard affinity\n (e.g. Linux: \nsched_setaffinity()\n)\n\n\n\n\n\n\nNon-Uniform Memory Access (NUMA)\n\n\nA CPU has faster access to some parts of main memory than to other parts.\n\n\n\n\n\n\n6.5.3 Load Balancing\n\u00b6\n\n\nOn systems with a common run queue, load balancing is often unnecessary, because once a processor becomes idle, it immediately extracts a runnable process from the common run queue.\n\n\n\n\nPush migration\n: pushing processes from overloaded to less-busy processors.\n\n\nPull migration\n: pulling a waiting task from a busy processor.\n\n\n\n\n6.5.4 Multicore Processors\n\u00b6\n\n\nSMP systems that use multicore processors are faster and consume less power than systems in which each processor has its own physical chip.\n\n\nThere are two ways to multithread a processing core:\n\n\n\n\nCoarse-grained\n: a thread executes on a processor until a long-latency event such as a memory stall occurs.\n\n\nFine-grained (interleaved)\n: switches between threads at a much finer level of granularity\n\n\n\n\n6.6 Real-Time CPU Scheduling\n\u00b6\n\n\n\n\nSoft real-time systems\n\n\nHard real-time systems\n\n\n\n\n6.6.1 Minimizing Latency\n\u00b6\n\n\n\n\nEvent latency\n\n\nThe amount of time that elapses from when an event occurs to when it is serviced.\n\n\n\n\nThere are 2 types:\n\n\n\n\nInterrupt latency\n\n\nDispatch latency\n\n\n\n\n\n\nInterrupt latency\n\n\nThe period of time from the arrival of an interrupt at the CPU to the start of the interrupt service routine (ISR) that services the interrupt.\n\n\n\n\n\n\nDispatch latency\n\n\nThe amount of time required for the scheduling dispatcher to stop one process and start another.\n\n\n\n\n6.6.2 Priority-Based Scheduling\n\u00b6\n\n\nThe processes are considered \nperiodic\n. That is, they require the CPU at constant intervals (periods). ($t$: fixed processing time, $d$: deadline, and $p$: period.)\n\n\n$$0 \\le t \\le d \\le p.$$\n\n\n$$rate = 1 / p.$$\n\n\nAdmission-control\n:\n\n\n\n\nAdmits the process.\n\n\nRejects the request.\n\n\n\n\n6.6.3 Rate-Monotonic Scheduling\n\u00b6\n\n\n\n\n\n\nExample 1:\n\n\n\n\n\n\nGiven processes: (the deadline for each process requires that it complete its CPU burst by the start of its next period.)\n\n\n\n\n\n\n\n\nProcess\n\n\nPeriod\n\n\nProcTime\n\n\n\n\n\n\n\n\n\n\n$P_1$\n\n\n$p_1 = 50$\n\n\n$t_1 = 20$\n\n\n\n\n\n\n$P_2$\n\n\n$p_2 = 100$\n\n\n$t_2 = 35$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2:\n\n\n\n\n\n\nGiven processes:\n\n\n\n\n\n\n\n\nProcess\n\n\nPeriod\n\n\nProcTime\n\n\n\n\n\n\n\n\n\n\n$P_1$\n\n\n$p_1 = 50$\n\n\n$t_1 = 25$\n\n\n\n\n\n\n$P_2$\n\n\n$p_2 = 80$\n\n\n$t_2 = 35$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.6.4 Earliest-Deadline-First Scheduling\n\u00b6\n\n\n\n\n6.6.5 Proportional Share Scheduling\n\u00b6\n\n\nProportional share schedulers operate by allocating $T$ shares among all applications. An application can receive $N$ shares of time.\n\n\n6.6.6 POSIX Real-Time Scheduling\n\u00b6\n\n\n\n\n\n\nPOSIX.1b \u2014 Extensions for real-time computing\n\n\n\n\nSCHED_FIFO\n\n\nSCHED_RR\n\n\nSCHED_OTHER\n\n\n\n\n\n\n\n\nAPI\n\n\n\n\npthread_attr_getsched_policy(pthread_attr_t *attr, int *policy)\n\n\npthread_attr_setsched_policy(pthread_attr_t *attr, int *policy)\n\n\n\n\n\n\n\n\n6.7 Operating-System Examples\n\u00b6\n\n\n6.7.1 Example: Linux Scheduling\n\u00b6\n\n\n6.7.2 Example: Windows Scheduling\n\u00b6\n\n\n6.7.3 Example: Solaris Scheduling\n\u00b6\n\n\n6.8 Algorithm Evaluation\n\u00b6\n\n\n6.8.1 Deterministic Modeling\n\u00b6\n\n\n\n\nDeterministic modeling\n\n\nIt is one type of analytic evaluation. This method takes a particular predetermined workload and defines the performance of each algorithm for that workload.\n\n\n\n\n6.8.2 Queueing Models\n\u00b6\n\n\n\n\nLittle's formula ($n$: # of processes in the queue, $\\lambda$: arrival rate, $W$: average waiting time in the queue.)\n\n\n\n\n$$n = \\lambda \\times W.$$\n\n\n6.8.3 Simulations\n\u00b6\n\n\n\n\n\n\nProperties:\n\n\n\n\nAccurate but expensive\n\n\n\n\n\n\n\n\nProcedures:\n\n\n\n\nProgram a model of the computer system\n\n\nDrive the simulation with various data sets\n\n\n\n\n\n\n\n\n6.8.4 Implementation\n\u00b6",
            "title": "Chapter 6 CPU Scheduling"
        },
        {
            "location": "/OS/Chap06/#chapter-6-cpu-scheduling",
            "text": "",
            "title": "Chapter 6 CPU Scheduling"
        },
        {
            "location": "/OS/Chap06/#61-basic-concepts",
            "text": "The objective of multiprogramming is to have some process running at all times, to maximize CPU utilization.  A process is executed until it must wait, typically for the completion of some I/O request.",
            "title": "6.1 Basic Concepts"
        },
        {
            "location": "/OS/Chap06/#611-cpuio-burst-cycle",
            "text": "Process execution = cycle of CPU + I/O wait.",
            "title": "6.1.1 CPU\u2013I/O Burst Cycle"
        },
        {
            "location": "/OS/Chap06/#612-cpu-scheduler",
            "text": "Short-term scheduler  (CPU scheduler): select process in the ready queue.",
            "title": "6.1.2 CPU Scheduler"
        },
        {
            "location": "/OS/Chap06/#613-preemptive-scheduling",
            "text": "CPU-scheduling decisions when a process:   (nonpreemptive) Switches from the running state $\\to$ the waiting state (e.g. I/O request,  wait()  for child)  (preemptive) Switches from the running state $\\to$ the ready state (e.g. interrupt)  (preemptive) Switches from the waiting state $\\to$ the ready state (e.g. completion of I/O)  (nonpreemptive) Terminates",
            "title": "6.1.3 Preemptive Scheduling"
        },
        {
            "location": "/OS/Chap06/#614-dispatcher",
            "text": "Dispatcher  The module that gives control of the CPU to  the process selected by the short-term scheduler . It should be fast.    Switching context  Switching to user mode  Jumping to the proper location in the user program to restart that program    Dispatch latency  The time it takes for the dispatcher to stop one process and start another running.  Stop a process $\\leftrightarrow$ Start a process",
            "title": "6.1.4 Dispatcher"
        },
        {
            "location": "/OS/Chap06/#62-scheduling-criteria",
            "text": "CPU utilization  Throughput  Turnaround time : $\\text{Completion Time} - \\text{Start Time}$.  Waiting time : The sum of the periods spent waiting in the ready queue.  Response time",
            "title": "6.2 Scheduling Criteria"
        },
        {
            "location": "/OS/Chap06/#63-scheduling-algorithms",
            "text": "",
            "title": "6.3 Scheduling Algorithms"
        },
        {
            "location": "/OS/Chap06/#63-1-first-come-first-served-scheduling",
            "text": "The process which requests the CPU first is allocated the CPU.   Properties:   Nonpreemptive FCFS.  CPU might be hold for an extended period.     Critical problem: Convoy effect!    Example:    Given processes:     Process  Busrt Time      $P_1$  24    $P_2$  3    $P_3$  3       Consider order: $P_1 \\to P_2 \\to P_3$:    Gantt chart:     Average waiting time = (0 + 24 + 27) / 3 = 17 ms.      Consider order: $P_2 \\to P_3 \\to P_1$:    Gantt chart:     Average waiting time = (0 + 3 + 6) / 3 = 9 ms.         Convoy effect All the other processes wait for the one big process to get off the CPU.",
            "title": "6.3-1 First-Come, First-Served Scheduling"
        },
        {
            "location": "/OS/Chap06/#632-shortest-job-first-scheduling",
            "text": "Properties:   Nonpreemptive SJF  Shortest-next-CPU-burst first     Problem: Measure the future!    Example 1:    Given processes:     Process  Burst Time      $P_1$  6    $P_2$  8    $P_3$  7    $P_4$  3       By SJF scheduling:    Gantt chart:     Average waiting time = (3 + 16 + 9 + 0) / 4 = 7 ms.         SJF is used frequently in long-term (job) scheduling, but it cannot be implemented at the level of short-term CPU scheduling.    Exponential average  Let $t_n$ be time of $n$th CPU burst, and $\\tau_{n + 1}$ be the next CPU burst.  \\begin{align}\n\\tau_{n + 1} & = \\alpha t_n + (1 - \\alpha)\\tau_n, \\quad 0 \\le \\alpha \\le 1. \\\\\n             & = \\alpha t_n + (1 - \\alpha)\\alpha t_{n - 1} + \\cdots + (1 - \\alpha)^j \\alpha t_{n - j} + \\cdots + (1 - \\alpha)^{n + 1}\\tau_0.\n\\end{align}     Example 2:    Given processes:     Process  Arrival Time  Burst Time      $P_1$  0  8    $P_2$  1  4    $P_3$  2  9    $P_4$  3  5       By preemptive SJF scheduling:    Gantt chart:     Average waiting time = [(10 - 1) + (1 - 1) + (17 - 2) + (5 - 3)] / 4 = 26 / 4 = 6.5 ms.",
            "title": "6.3.2 Shortest-Job-First Scheduling"
        },
        {
            "location": "/OS/Chap06/#633-priority-scheduling",
            "text": "Properties:    CPU is assigned to the process with the highest priority \u2014 A framework for various scheduling algorithms:  FCFS: Equal-priority with tie-breaking  SJF: Priority = 1 / next CPU burst length       Example:    Given processes:     Process  Burst Time  Priority      $P_1$  10  3    $P_2$  1  1    $P_3$  2  4    $P_4$  1  5    $P_5$  5  2       By preemptive SJF scheduling:    Gantt chart:     Average waiting time = (6 + 0 + 16 + 18 + 1) / 5 = 8.2 ms.         Problem with priority scheduling   indefinite blocking: low-priority processes could starve to death!  starvation     Aging  Aging gradually increase the priority of processes that wait in the system for a long time.",
            "title": "6.3.3 Priority Scheduling"
        },
        {
            "location": "/OS/Chap06/#634-round-robin-scheduling",
            "text": "RR is similar to FCFS except that preemption is added to switch between processes.   Goal: fairness, time sharing.    Example:    Given processes with quantum = 4ms:     Process  Burst Time      $P_1$  24    $P_2$  3    $P_3$  3       Gantt chart:     Average waiting time = [(10 - 4) + 4 + 7] / 3 = 5.66 ms.       Although the time quantum should be large compared with the context switch time, it should not be too large.",
            "title": "6.3.4 Round-Robin Scheduling"
        },
        {
            "location": "/OS/Chap06/#635-multilevel-queue-scheduling",
            "text": "Intra-queue scheduling   Independent choice of scheduling algorithms     Inter-queue scheduling   Fixed-priority preemptive scheduling  e.g., foreground queues always have absolute priority over the background queues.    Time slice between queues  e.g., 80% CPU is given to foreground processes, and 20% CPU is given to background processes.       Each queue has absolute priority over lower-priority queues.  If an interactive editing process entered the ready queue while a batch process was running, the batch process would be preempted.",
            "title": "6.3.5 Multilevel Queue Scheduling"
        },
        {
            "location": "/OS/Chap06/#636-multilevel-feedback-queue-scheduling",
            "text": "Multilevel feedback queue allows a process to move between queues.   A multilevel feedback queue is defined by:   #queues  The scheduling algorithm for each queue   The method used to determine when to    upgrade a process to a higher priority queue  demote a process to a lower priority queue     The method used to determine which queue a process will enter when that process needs service",
            "title": "6.3.6 Multilevel Feedback Queue Scheduling"
        },
        {
            "location": "/OS/Chap06/#64-thread-scheduling",
            "text": "",
            "title": "6.4 Thread Scheduling"
        },
        {
            "location": "/OS/Chap06/#641-contention-scope",
            "text": "Process Contention Scope (PCS)  On systems implementing the  many-to-one  and  many-to-many  models, the thread library schedules user-level threads to run on an available LWP, since competition for the CPU takes place among threads belonging to the same process.  It is important to note that PCS will typically preempt the thread currently running in favor of a higher-priority thread    System Contention Scope (SCS)  Competition for the CPU with SCS scheduling takes place among all threads in the system. Systems using the  one-to-one  model.",
            "title": "6.4.1 Contention Scope"
        },
        {
            "location": "/OS/Chap06/#642-pthread-scheduling",
            "text": "PCS:  PTHREAD_SCOPE_PROCESS  SCS:  PTHREAD_SCOPE_SYSTEM   2 methods:   pthread_attr_setscope(pthread attr_t *attr, int scope)  pthread_attr_getscope(pthread attr_t *attr, int *scope)",
            "title": "6.4.2 Pthread Scheduling"
        },
        {
            "location": "/OS/Chap06/#65-multiple-processor-scheduling",
            "text": "",
            "title": "6.5 Multiple-Processor Scheduling"
        },
        {
            "location": "/OS/Chap06/#651-approaches-to-multiple-processor-scheduling",
            "text": "Asymmetric multiprocessing : only  the master server  process accesses the system data structures, reducing the need for data sharing.  Symmetric multiprocessing (SMP) : each processor is self-scheduling.",
            "title": "6.5.1 Approaches to Multiple-Processor Scheduling"
        },
        {
            "location": "/OS/Chap06/#652-processor-affinity",
            "text": "Processor Affinity  A process has an affinity for the processor on which it is currently running.    Soft affinity  Hard affinity  (e.g. Linux:  sched_setaffinity() )    Non-Uniform Memory Access (NUMA)  A CPU has faster access to some parts of main memory than to other parts.",
            "title": "6.5.2 Processor Affinity"
        },
        {
            "location": "/OS/Chap06/#653-load-balancing",
            "text": "On systems with a common run queue, load balancing is often unnecessary, because once a processor becomes idle, it immediately extracts a runnable process from the common run queue.   Push migration : pushing processes from overloaded to less-busy processors.  Pull migration : pulling a waiting task from a busy processor.",
            "title": "6.5.3 Load Balancing"
        },
        {
            "location": "/OS/Chap06/#654-multicore-processors",
            "text": "SMP systems that use multicore processors are faster and consume less power than systems in which each processor has its own physical chip.  There are two ways to multithread a processing core:   Coarse-grained : a thread executes on a processor until a long-latency event such as a memory stall occurs.  Fine-grained (interleaved) : switches between threads at a much finer level of granularity",
            "title": "6.5.4 Multicore Processors"
        },
        {
            "location": "/OS/Chap06/#66-real-time-cpu-scheduling",
            "text": "Soft real-time systems  Hard real-time systems",
            "title": "6.6 Real-Time CPU Scheduling"
        },
        {
            "location": "/OS/Chap06/#661-minimizing-latency",
            "text": "Event latency  The amount of time that elapses from when an event occurs to when it is serviced.   There are 2 types:   Interrupt latency  Dispatch latency    Interrupt latency  The period of time from the arrival of an interrupt at the CPU to the start of the interrupt service routine (ISR) that services the interrupt.    Dispatch latency  The amount of time required for the scheduling dispatcher to stop one process and start another.",
            "title": "6.6.1 Minimizing Latency"
        },
        {
            "location": "/OS/Chap06/#662-priority-based-scheduling",
            "text": "The processes are considered  periodic . That is, they require the CPU at constant intervals (periods). ($t$: fixed processing time, $d$: deadline, and $p$: period.)  $$0 \\le t \\le d \\le p.$$  $$rate = 1 / p.$$  Admission-control :   Admits the process.  Rejects the request.",
            "title": "6.6.2 Priority-Based Scheduling"
        },
        {
            "location": "/OS/Chap06/#663-rate-monotonic-scheduling",
            "text": "Example 1:    Given processes: (the deadline for each process requires that it complete its CPU burst by the start of its next period.)     Process  Period  ProcTime      $P_1$  $p_1 = 50$  $t_1 = 20$    $P_2$  $p_2 = 100$  $t_2 = 35$          Example 2:    Given processes:     Process  Period  ProcTime      $P_1$  $p_1 = 50$  $t_1 = 25$    $P_2$  $p_2 = 80$  $t_2 = 35$",
            "title": "6.6.3 Rate-Monotonic Scheduling"
        },
        {
            "location": "/OS/Chap06/#664-earliest-deadline-first-scheduling",
            "text": "",
            "title": "6.6.4 Earliest-Deadline-First Scheduling"
        },
        {
            "location": "/OS/Chap06/#665-proportional-share-scheduling",
            "text": "Proportional share schedulers operate by allocating $T$ shares among all applications. An application can receive $N$ shares of time.",
            "title": "6.6.5 Proportional Share Scheduling"
        },
        {
            "location": "/OS/Chap06/#666-posix-real-time-scheduling",
            "text": "POSIX.1b \u2014 Extensions for real-time computing   SCHED_FIFO  SCHED_RR  SCHED_OTHER     API   pthread_attr_getsched_policy(pthread_attr_t *attr, int *policy)  pthread_attr_setsched_policy(pthread_attr_t *attr, int *policy)",
            "title": "6.6.6 POSIX Real-Time Scheduling"
        },
        {
            "location": "/OS/Chap06/#67-operating-system-examples",
            "text": "",
            "title": "6.7 Operating-System Examples"
        },
        {
            "location": "/OS/Chap06/#671-example-linux-scheduling",
            "text": "",
            "title": "6.7.1 Example: Linux Scheduling"
        },
        {
            "location": "/OS/Chap06/#672-example-windows-scheduling",
            "text": "",
            "title": "6.7.2 Example: Windows Scheduling"
        },
        {
            "location": "/OS/Chap06/#673-example-solaris-scheduling",
            "text": "",
            "title": "6.7.3 Example: Solaris Scheduling"
        },
        {
            "location": "/OS/Chap06/#68-algorithm-evaluation",
            "text": "",
            "title": "6.8 Algorithm Evaluation"
        },
        {
            "location": "/OS/Chap06/#681-deterministic-modeling",
            "text": "Deterministic modeling  It is one type of analytic evaluation. This method takes a particular predetermined workload and defines the performance of each algorithm for that workload.",
            "title": "6.8.1 Deterministic Modeling"
        },
        {
            "location": "/OS/Chap06/#682-queueing-models",
            "text": "Little's formula ($n$: # of processes in the queue, $\\lambda$: arrival rate, $W$: average waiting time in the queue.)   $$n = \\lambda \\times W.$$",
            "title": "6.8.2 Queueing Models"
        },
        {
            "location": "/OS/Chap06/#683-simulations",
            "text": "Properties:   Accurate but expensive     Procedures:   Program a model of the computer system  Drive the simulation with various data sets",
            "title": "6.8.3 Simulations"
        },
        {
            "location": "/OS/Chap06/#684-implementation",
            "text": "",
            "title": "6.8.4 Implementation"
        },
        {
            "location": "/OS/midterm/",
            "text": "Previous Operating System Midterms at NTUCSIE\n\u00b6\n\n\nSpring 2011\n\u00b6\n\n\n\n\n\n\nTerminologies. (24pts)\n\n\n\n\n\n\nSecurity\n\n\nDefense of a system from external and internal attacks, e.g., viruses, denial of services, etc.\n\n\n\n\n\n\nA Layered Approach in OS Designs\n\n\nThe operating system is broken into a number of layers (levels). The bottom layer (layer $0$) is the hardware; the highest (layer $N$) is the user interface.\n\n\n\n\n\n\nPara-virtualization\n\n\nA variation on virtualization that presents a guest/operating system that is similar but not identical to the underlying hardware.\n\n\n\n\n\n\nLightweight Process\n\n\nA virtual processor (kernel threads) on which the application can schedule a user thread to run. (many-to-many or two-level)\n\n\n\n\n\n\nNUMA\n\n\nNon-Uniform Memory Access: A CPU has faster access to some parts of main memory than to other parts.\n\n\n\n\n\n\nDeterministic Modeling\n\n\nTake a particular predetermined workload and defines the performance of each algorithm for that workload.\n\n\n\n\n\n\nRace Condition\n\n\nSeveral processes access and manipulate the same data concurrently and the outcome of the execution depends on the particular order in which the access takes place.\n\n\n\n\n\n\nWrite Ahead Logging\n\n\nAll modifications are written to a log before they are applied.\n\n\n\n\n\n\n\n\n\n\nPlease answer following questions regarding the design the design of operation systems. (22pts)\n\n\nThere are two conflicting goals in OS designs: Convenience and Efficiency.\n\n\n\n\nPlease give me one example feature of OS that shows the conflict in persuing efficiency and convenience (Hint: Live preview of open windows for Windows7 taskbar). (5pts)\n\n\nWhat is the main goal of Unix process init? Is init a user or kernel process? (8pts)\n\n\nPlease explain how I/O protection is done. (5pts)\n\n\nGive me one advantage in OS implementations in some high-level language. (4pts)\n\n\n\n\n\n\n\n\nPlease answer the following questions for process managment. (16pts)\n\n\n\n\nInside the Process Control Block, we might have a filed \"Program Counter\". What is the purpose of the field? (4pts)\n\n\nThere are a lot of segments for a process image, such as code segment, data segment, heap, and user stack. When we call malloc() or free(), which segment is involved? (4pts)\n\n\nWhen a parent process calls fork() to create a child process, how does the parent process know the process ID of the created child process? (4pts)\n\n\nWhich of the following IPC mechanisms does not require two communicating processes to have a parent-child relationship: Named Pipes and sockets. (4pts)\n\n\n\n\n\n\n\n\nPlease answer the following questions for CPU scheduling. (17pts)\n\n\n\n\nCompared to user-level threads, why the cost of context switching for kernel-level threads in higher? (4pts)\n\n\nThe delivery of a signal for theads is complicated. Give me an example signal that should be delivered to the threads to which the signal applies. (4pts)\n\n\nFor preemptive scheduling, there are serveral occasions in triggering scheduling. Please give me three, beside the one in which a running process terminates by itself. (9pts)\n\n\n\n\n\n\n\n\nConsider Shortest-Job-First(SJF) and Round-Robin(RR) scheduling algorithms, and processes under considerations are only of one single CPU burst and are all ready at time $0$. Please answer the folowing questions. Explanation is needed to receive any credit: (18pts)\n\n\n\n\nIs SJF always better than RR, for any time quantum, in terms of the average turnaround time?(6pts)\n\n\nWhen all processes are of the same size, please tell us what the best time quantum is for RR in terms of the average waiting time. (6pts)\n\n\nNow suppose that processes might arrive at different times, and SJF and RR are preemptive scheduling algorithms. Is SJF always better than RR, for any time quantum, in terms of the average waiting time. (6pts)\n\n\n\n\n\n\n\n\nPlease design a solution for airplanes to land in an airport. Suppose that there is only one runway in the airport. Please make sure that only one airplane can control the runway to land at a time, and there should be no starvation for your solution. (Hint: (1) the Bakery Algorithm; (2) Each process donotes an airplane.) (10pts)\n\n\n\n\n\n\nFall 2011\n\u00b6\n\n\nThe exam is 180 minutes long. The total score is 107pts. Please read the questions carefully.\n\n\n\n\n\n\nTerminologies. (24pts)\n\n\n\n\n\n\nDMA\n\n\nRelease CPU from handling excessive interrupts!\nExecute the device driver to set up the registers of the DMA controller. DMA moves blocks of data between the memory and its own buffers. Transfer from its buffers to its devices. Interrupt the CPU when the job is done.\n\n\n\n\n\n\nMultiprogramming\n\n\nIncreases CPU utilization by organizing jobs so that the CPU always has one to execute.\n\n\n\n\n\n\nHorizontal Cache Coherency and Consistency\n\n\nAmong units of the same storage level.\n\n\nFrom \n\u77e5\u4e4e\n:\n\n\n\n\nCoherence \u4fdd\u8b49\u7684\u662f\u540c\u4e00\u5730\u5740\u6709\u4e0d\u540c copy \u7684\u6642\u5019\uff0c\u4fdd\u8b49\u770b\u5230\u7684\u662f\u5728 timing \u4e0a\u96e2\u81ea\u5df1\u6700\u8fd1\u7684\u3002\n\n\n\n\n\u4f46\u662f\uff0c\u53ea\u4fdd\u8b49 Coherence \u662f\u4e0d\u5920\u7684\uff0c\u5728 multiprocessor \u4e0d\u540c\u5730\u5740\u7684\u591a\u500b copy \u8a2a\u554f\u7684\u6642\u5019\u6703\u51fa\u73fe\u554f\u984c\uff0c\u9019\u500b\u5c31\u662fconsistency\n\n\n\n\n\n\nCoherence is concerned with updates/invalidations to a single shared variable.\n\n\n\n\nConsistency is concerned with the behavior of memory references from multiple concurrent threads.\n\n\n\n\n\n\n\n\nA Module Approach in OS Designs\n (Hint: A Layered Approach) [ask]\n\n\nMoving all nonessential components from the kernel to the user or system programs!\n\n\n\n\n\n\nIndirect Communication in Message Passing\n ($\\leftrightarrow$ Direct)\n\n\n\n\nThe messages are sent to and received from mailboxes, or ports.\n\n\n($\\leftrightarrow$) The messages are sent to and received from processes.\n\n\n\n\n\n\n\n\nSocket\n\n\nAn endpoint for communication. (IP + port#)\n\n\n\n\n\n\nDeferred Cancellation\n ($\\leftrightarrow$ Asynchronous Cancellation)\n\n\n\n\nThe target thread periodically checks whether it should terminate, allowing it an opportunity to terminate itself in an orderly fashion.\n\n\n($\\leftrightarrow$) One thread immediately terminates the target thread.\n\n\n\n\n\n\n\n\nPull Migration\n (Hint: Multipocessor Scheduling) ($\\leftrightarrow$ Push Migration)\n\n\n\n\nPulling a waiting task from a busy processor.\n\n\n($\\leftrightarrow$) Pushing processes from overloaded to less-busy processors.\n\n\n\n\n\n\n\n\n\n\n\n\nPlease answer the following questions regarding the designs of operating systems: (23pts)\n\n\n\n\nPlease give me two resources, beside CPU, that are managed by OS. (6pts)\n\n\nWhen an interrupt arrives, a running task is interrupted, and its context could be saved in different ways, such as \"a fixed address for all interrupts\", \"a fixed space for each interrupt type\", and \"a stack\". What is the advantage in using a stack, compared with the approach in using a fixed space for each interrupt type? (5pts)\n\n\nIn a memory hierarchy, we have registers, cache, memory, and disk. Which of them is managed by operating systems? Which of them is managed by hardware? (l2pts)\n\n\n\n\n\n\n\n\nOS services are such as those for \"program execution\", \"file-system manipulation\", \"accounting\", and \"resource allocation\". Which of them are for system efficiency, instead of user convenience? (8pts)\n\n\n\n\n\n\nFamous Application Programming Interfaces (API) are such as Win 32 API and POSIX API. What are the two major benefits in providing API, compared to\n   the providing of system calls only? What does POSIX API offers to programmers, compared to the offering of ANSI C to programmers? (8pts)\n\n\n\n\n\n\nIn the ordinary virtualization design, the virtualization layer runs in the system mode. For VMware, the virtualization layer runs in the system or user mode? For Java, the Java virtual machine run in the system or user mode? (6pts)\n\n\n\n\n\n\nPlease answer the following questions for process management and scheduling. (20pts)\n\n\n\n\nGive me two conditions for a running process to relinquish the CPU to go back to the ready queue in preemptive CPU scheduling. (6pts)\n\n\nWhy a long-term scheduler has more time to choose a process for a system than a short-term scheduler does in process scheduling? (5pts)\n\n\nPlease explain the main difference between a user-level thread and a kernel thread. (5pts)\n\n\nIs a Java thread is a user-level thread or a kernel thread? (4pts)\n\n\n\n\n\n\n\n\nThe scheduling algorithm of Solaris 9 is based on the Multilevel Feedback Queue Scheduling algorithm. There are six priority classes. Please explain the Fair Sharing class? Please explain how interactive threads in the Time Sharing or Interactive class are favored in scheduling in Solaris 8 or 9? (6pts)\n\n\n\n\n\n\nConsider the scheduling of processes in which processes might arrive at different times and have different deadlines to complete their execution. Let the processes be scheduled by the preemptive Shortest-Job-First algorithm (PSJF) and a Priority Scheduling algorithm (PS) in which processes with urgent deadlines have higher priorities, and there is only one processor. Can you give a set of processes such that PS can meet the deadlines of the processes, but PSJF can not do it? (5pts)\n\n\n\n\n\n\nConsider the Round Robin scheduling algorithm (RR) with two different time quantums $L$ and $S$, where $L > S$. Let the scheduling criteria be the average\n   waiting time, and $L$ be larger than the largest CPU burst of all processes. Does RR, in general, favor a small time quantum $S$ when all processes are\n   ready at time $0$? Please give me your answer with argument. (7pts)\n\n\n\n\n\n\nFall 2012\n\u00b6\n\n\nThe exam is 180 minutes long. The total score is 110pts. Please read the questions carefully.\n\n\n\n\n\n\nTerminologies. (24pts)\n\n\n\n\n\n\nHardware Interrupt\n\n\nServices requests of I/O devices.\n\n\n\n\n\n\nVirtual Machine\n\n\nProvides an interface that is identical to the underlying bare hardware.\n\n\n\n\n\n\nContext Switch\n\n\nIt saves the state of the currently running process and loads the state of the newly scheduled process.\n\n\n\n\n\n\nA Full Duplex Pipe\n\n\nA pipe that suppors two ways of message passing simultaneously.\n\n\n\n\n\n\nMultilevel Queue Scheduling\n\n\nProcesses can be classified into different groups and permanently assigned to one queue, where there are Inter-queue and intra-queue scheduling policies.\n\n\n\n\n\n\nMemory Stall\n\n\nA phenomenon in which a processor waits for a significant amount of time waiting for the data to become available.\n\n\n\n\n\n\nBounded Waiting\n (A Requirement of a Critical Section Solution)\n\n\nA waiting process only waits for a bounded number of processes to enter their critical sections.\n\n\n\n\n\n\nAdaptive Mutex\n\n\nA binary semaphore in which it is a spinlock if the lock-holding thread is running; otherwise, blocking is used.\n\n\n\n\n\n\n\n\n\n\nPlease answer the following questions regarding the designs of operating systems: (20pts)\n\n\n\n\n\n\nWhat is the difference between \nmultiprogramming\n and \ntime sharing\n? (6pts)\n\n\nTime sharing (or multitasking) is a logical extension of multiprogramming, where CPU services each of ready tasks in a way that every task receives CPU time in an interactive fashion.\n\n\n\n\n\n\nWhich one of the following memory unit is managed by the operating systems: Registers, Cache, Main Memory, Disks (8pts)\n\n\nMain Memory and Disks.\n\n\n\n\n\n\nOperating systems services include user interfaces. UNIX shells, including the Bourne shell and C shell, provide command interpreters. Consider UNIX shells, please give me one command that is implemented as some code inside the command interpreter and two commands that are implemented by system programs? (6pts)\n\n\n\n\n\n\nInside the command interpreter:\n\n\n\n\nC shell: \numask, cd and limit\n\n\nBourne shell: \nulimit -H and -S\n\n\n\n\n\n\n\n\nBy system programs: \nrm and ls\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMessage passing is a way for interprocess communication. Consider the capacity of a link between two processes has zero capacity. Is the message passing (between the two processes) synchronous or asynchronous? You must provide explanation to receive any credits. (5pts)\n\n\nIt is synchronous because we can only have blocking sends and blocking receives.\n\n\n\n\n\n\n\n\n\n\nPlease give me one occasion when a mid-term scheduler should run.\n\n\nThe remaining main memory is low or the CPU utilization is too high.\n\n\n\n\n\n\nCan a short-term scheduler schedule the executions of user-level threads?\n\n\nNo.\n\n\n\n\n\n\nCan a short-term scheduler schedule the executions of a Java thread? (9pts)\n\n\nIt depends on the thread library on the host system.\n\n\n\n\n\n\n\n\n\n\nConsider signal handling for threads. \n\n\n\n\n\n\nIs a Division-By-Zero signal synchronous or asynchronous?\n\n\nSynchronous.\n\n\n\n\n\n\nShould a Division-By-Zero signal be delivered to every thread of its belonging process? (6pts)\n\n\nNo. It should be only sent to the thread that causes the signal.\n\n\n\n\n\n\n\n\n\n\nPlease answer the following questions for process scheduling. Explanation is needed to receive any credit. (24pts)\n\n\n\n\n\n\nFor the Round-Robin Scheduling, what would be the preferred time slice in general? (4pts)\n\n\nThe time slice $\\ge 80\\%$ CPU burst.\n\n\n\n\n\n\nFor the Round-Robin Scheduling, shall we have a small time slice for a better average turn around time? (4pts)\n\n\nNo, a small time slice will increase the average turnaround time.\n\n\n\n\n\n\nFor the Priority Scheduling, how to avoid the starvation problem (in which a low priority process can never be scheduled)? (4pts)\n\n\nAn \naging\n solution by increasing the priority of a process that waits for a long time.\n\n\n\n\n\n\nPlease explain how a guest operating-system scheduling algorithm that assumes a certain amount of progress in a given amount of time might be negatively impacted by virtualization. (6pts)\n\n\nIt is because the virtualization software needs to schedule the use of the physical CPUs among the virtual CPUs. A given amount of the time slice might take much more than the time of the virtual CPU time.\n\n\n\n\n\n\nFor the evaluation of a scheduling algorithm, please give me two difficulties in using the implementation method. (6pts)\n\n\n\n\nCost in modifying the OS\n\n\nUser reaction to OS changes\n\n\nChanging of the environment in which the algorithm is used\n\n\n\n\n\n\n\n\n\n\n\n\nPlease explain the difference between the signal operation of a binary semaphore and that of a condition variable (of a monitor). (5pts)\n\n\nThe signal operation of a condition variable resumes one suspended process. If there is none, no effect is imposed.\n\n\n\n\n\n\nConsider a barber shop in which there are two barbers. Each barber can service exactly one customer at a time. Please use binary semaphores to implement the request for the hair-cut service. (12pts)\n\n\nUse an integer $S$ with initial value = $2$ to indicate the number of available barbers.\n\n\ntypedef\n \nstruct\n \n{\n\n    \nint\n \nvalue\n;\n\n    \nstruct\n \nprocess\n \n*\nwaiting_list\n;\n\n\n}\n \nsemaphore\n;\n\n\n\n\n\nwait\n(\nsemaphore\n \n*\nS\n)\n \n{\n\n    \nS\n->\nvalue\n--\n;\n\n    \nif\n \n(\nS\n->\nvalue\n \n<\n \n0\n)\n \n{\n\n        \nadd\n \nthis\n \ncustomer\n \nto\n \nS\n->\nwaiting_list\n;\n\n        \nblock\n();\n\n    \n}\n\n\n}\n\n\n\n\n\nsignal\n(\nsemaphore\n \n*\nS\n)\n \n{\n\n    \nS\n->\nvalue\n++\n;\n\n    \nif\n \n(\nS\n->\nvalue\n \n<=\n \n0\n)\n \n{\n\n        \nremove\n \na\n \nprocess\n \nP\n \nfrom\n \nS\n->\nwaiting_list\n;\n\n        \nwakeup\n(\nP\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\n\nConsider the time-stamp protocol of Chapter 6, in which each process $T_i$ is given a time stamp $T_S(T_i)$, and each read/write operation must check it up with the read and write timestamp of the accessed data object $Q$. Is it possible to have any deadlock? You must provide your explanation. (5pts) [ask]\n\n\nNo deadlock because there is no hold-and-wait among processes.\n\n\n\n\n\n\nFall 2013\n\u00b6\n\n\nThe exam is 180 minutes long. The total score is 103pts. Please read the questions carefully.\n\n\n\n\n\n\nTerminologies. (24pts)\n\n\n\n\n\n\nBooting\n\n\nInitialize all aspects of the system and then load and run the OS.\n\n\n\n\n\n\nInterrupt Vector\n\n\nAn array of interrupt-handlers' addresses that are indexed by device numbers (or interrupt numbers).\n\n\n\n\n\n\nCache Coherency\n [Fall 2011 1.(c)]\n\n\nCache coherency problems can arise when more than one processors refer to the same data. Coherency defines what value is returned on a read.\n\n\n\n\n\n\nPlatform as a service (PaaS) in Cloud Computing\n\n\nPass provides a computing platform and a solution stack as a service, such as a database server. One example is Microsoft Azure.\n\n\n\n\n\n\nA Modular Kernel\n (Hint: OS Structure) [Fall 2011 1.(d)]\n\n\nA moduler kernel consists of a set of components, where there are core/primary modules, and it is of modules without a layer structure.\n\n\n\n\n\n\nData Parellelism in Multicore Programming\n\n\nDistribute data over cores to execute the \nsame operation\n.\n\n\n\n\n\n\nRate Monotonic Scheduling\n\n\nA fixed priority real-time process scheduling algorithm in which the priorities of processes are \ninversely proportional to their periods\n.\n\n\n\n\n\n\nDeterministic Modeling\n [Spring 2011 1.(f)]\n\n\nTake a particular predetermined workload and defines the performance of each algorithm for that workload.\n\n\n\n\n\n\n\n\n\n\nPlease answer the following questions regarding the designs of operating systems: (20pts)\n\n\n\n\n\n\nThere are two conflicting goals in the designs of operating systems. What is the other one, beside \"convenient for the users\" ? (3pts)\n\n\nEfficient operation of the computer system.\n\n\n\n\n\n\nWhich one of the following actions/events is belonging to or might result in software interrupts: System calls, child termination, mouse clicking, invalid memory access. (8pts)\n\n\nSystem calls, child temination, and invalid memory access.\n\n\n\n\n\n\nConsider the implementation of virtual machines in which operating systems run on the top of the virtual machine software (or referred to as the hypervisor). Is an operating system running in the user mode or kernel mode? (3pts)\n\n\nThe user mode.\n\n\n\n\n\n\nPlease give me 2 advantages of virtual machines, beside system consolidation and easy in system development/deployment. (6pts)\n\n\nCopmlete isolation and multiple personalities.\n\n\n\n\n\n\n\n\n\n\nANSI C refers to the family of successive standards published by ANSI for the C programming language. Please compare difference (or provide the purpose difference) between POSIX and ANSI C. (5pts)\n\n\n\n\n\n\nAny program written only in ANSI C and without any hardware dependent assumptions is virtully guaranteed to compile correctly on any platform with a conforming C implementation.\n\n\n\n\n\n\nPOSIX is an acronym for \"Portable Operating System Interface\". POSIX is for software compatibility with variants of Unix and other operating systems.\n\n\n\n\n\n\n\n\n\n\nPlease answer the following questions for task scheduling. (14pts)\n\n\n\n\n\n\nIs the \"Swapper\" a short-term or mid-term scheduler? [ask]\n\n\nShort-term scheduler.\n\n\n\n\n\n\nIn Unix, the process control block PCB[] of a process consists of proc[] and .u, where the attributes in .u are those needed when the process is running, and the attributes in proc[] are those needed all the time. Please indicate which one should be in .u : file[], task priority, pid, signal disposition, and task state. You must provide explanation to receive any credits. (10pts) [ask]\n\n\n\n\nfile[]: what files are \"being\" opened.\n\n\nsignal disposition: how to deal with signals.\n\n\n\n\n\n\n\n\n\n\n\n\nConsider message passing and shared memory for inerprocess communication. Is \"Pipe\" considered one for message passing or shared memory ? Is \"Pipe\" direct or indirect communication ? Is it \"synchronous\" or \"asynchronous\"? for a reader or a writer of the communication in Unix. You must provide explanation to receive any credits. (12pts)\n\n\n\n\nMessage passing. Since it's communication between processes without sharing the same address space.\n\n\nIndirect communication. [ask]\n\n\nSynchronous for a reader. [ask]\n\n\nAsynchronous for a writer. [ask]\n\n\n\n\n\n\n\n\nKernel-level threads are superior than uer-level threads do in many ways.\n\n\n\n\n\n\nWhat is the main disadvantage of kernel-level threads?\n\n\nIt is context switching cost.\n\n\n\n\n\n\nWith OpenMP in program development, shall we prefer kernel-level or user-level threads? You must provide explanation to receive any credits. (8pts)\n\n\nWe prefer kernel-level threads because we look for parallelism to better utilize multiple cores of a system.\n\n\n\n\n\n\n\n\n\n\nPlease answer the following questions for process scheduling. Explanation is needed to receive any credits. (15pts)\n\n\n\n\n\n\nGiven 3 processes $P_1$, $P_2$, and $P_3$ with CPU burst time $5$, $6$, $7$, respectively. Suppose that the 3 processes arrive at time $0$, and $P_1$ and $P_3$ are the first and the last processes in the ready queue, respectively. What is the average waiting time in running the 3 processes under the Round-Robin Scheduling with the time slice equal to $3$. (5pts)\n\n\n (6 + (3 + 5) + (6 + 5)) / 3 = 25 / 3.\n\n\n\n\n\n\nConsider FCFS and Round-Robin Scheduling. If process are only of CPU burst and all arrive at time $0$, do FCFS and Round-Robin Scheduling with time slice = $1$ always have the same total waiting time in running all processes ? Prove your answer. (5pts)\n\n\nNo, for example, given processes of CPU burst 7, 1, and 1.\n\n\n\n\n\n\nSuppose that the variance of the tunaround time is the cirterion in process scheduling. Shall we have a small time slice for a better variance turnaround time when all processes arrive at time $0$? (5pts)\n\n\nNo. For example, given processes $P_1$, $P_2$ and $P_3$ with CPU burst time $10$, $10$ and $10$.\n\n\n\n\nWith quantum $= 10$, average turnaround time = (10 + 20 + 30) / 3 = 60 / 3 = 20.\n\n\nWith quantum $= 5$, average turnaround time = (20 + 25 + 30) / 3 = 75 / 3 = 25.\n\n\nWith quantum $= 1$, average turnaround time = ... = (28 + 29 + 30) / 3 = 87 / 3 = 29.\n\n\nWith quantum $\\to 0$, average turnaround time $\\approx$ 30 + 30 + 30 = 90 / 3 = 30.\n\n\n\n\nIt is obvious that smaller time slice will lead a longer average turnaround time.\n\n\n\n\n\n\n\n\n\n\nPlease explain why the Completely Fair Scheduling (CFS) of Linux V2.6 favors I/O tasks. (5pts)\n\n\nCFS usually dispatches the CPU to the task with the smallest vruntime (that denotes how long the task runs) such that I/O tasks usually have smaller vruntime.\n\n\n\n\n\n\nFall 2014\n\u00b6\n\n\nThe exam is 180 minutes long. The total score is 108pts. Please read the questions carefully.\n\n\n\n\n\n\nTerminologies. (24pts)\n\n\n\n\n\n\nBuffering\n (Hint: It is not caching.)\n\n\nIt means to keep data in a faster medium temporarily before moving them to a slower layer.\n\n\n\n\n\n\nVirtual Machine\n [Fall 2012 1.(b)]\n\n\nProvides an interface that is identical to the underlying bare hardware.\n\n\n\n\n\n\nSystem Generation\n (SYSGEN)\n\n\nThe process to configure or generate an operating system for a one specific computer.\n\n\n\n\n\n\nContext Switch\n [Fall 2012 1.(c)]\n\n\nSave the state of the old process and load the state of the newly scheduled process.\n\n\n\n\n\n\nRemote Procedure Call\n (Hint: Message Passing)\n\n\nSenders are blocked until the receivers have received messages and replied by reply messaeggs. (A way to abstract the procedure-call mechanism for use between systems with network connection.)\n\n\n\n\n\n\nImplicit Threading\n\n\nTransfer the creation and management of the threading from the application developers to compilers and run-time libraries.\n\n\n\n\n\n\nEarliest Deadline First Scheduling\n\n\nA dynamic-priority real-time process scheduling algorithm in which the priorities of processes are higher if their deadlines are closer.\n\n\n\n\n\n\nRace Condition\n [Spring 2011 1.(g)]\n\n\nSeveral processes access and manipulate the same data concurrently and the outcome of the execution depends on the particular order in which the access takes place.\n\n\n\n\n\n\n\n\n\n\nPlease answer the following questions regarding the designs of operating systems: (22pts)\n\n\n\n\n\n\nAn operating system could be considered as a resource allocator. Please list 3 resources managed by an operating systems. (6pts)\n\n\nCPU time, Memory Space, File Storage, I/O Devices, Shared Code, Data Structures, and more.\n\n\n\n\n\n\nPlease explain what happens to the operating system when an interrupt arrives (until the interrupt is serviced). (4pts)\n\n\nSaving of the address of the interrupted instruction, determine the interrupt type (by polling or interrupt vector), call the corresponding handlers.\n\n\n\n\n\n\nWhich one of the following instructions is a privileged instruction:\n\n\nReading of the Timer, setting of the base register of the memory space of a process, increment the value of a CPU register by one. No explanation is needed. (6pts)\n\n\nSetting of the base register of the memory space of a process.\n\n\n\n\n\n\nPlease explain what happens when a command-line user interface of Unix executes a command. (6pts)\n\n\nSearch the exec file which corresponds to the command; fork a process\n       to execute the file.\n\n\n\n\n\n\n\n\n\n\nConsider parameter passing to a system call. Give me the major advantage in having a register pointing to a memory block that stores all parameters, compared to having all parameters stored in registers? (5pts)\n\n\nThe space needed to store all parameters is virtually unlimited.\n\n\n\n\n\n\nThe memory image of a Unix process might consist of a code segment, a data segment, a heap area, a user stack, a kernel stack, an environment variable area, and .u. \n\n\n\n\n\n\nWhich one of the above is used when \nmalloc()\n is invoked?\n\n\nheap.\n\n\n\n\n\n\nWhen the kernel stack is used? (8pts) [ask]\n\n\nProcedure invocation in the system mode.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlease explain how \nfork()\n works when a parent process invoke \nfork()\n.\n\n\nWhen a parent process invoke fork(), a duplication of the parent process is created for the resulted child process, where the parent process returns from fork() with the process ID of the created child process. The child process returns 0.\n\n\n\n\n\n\nPlease use the answer to the \nfork()\n invocation to explain the difference between \nfork()\n and \nvfork()\n. (10pts)\n\n\nWhen a parent process invoke vfork(), a child process is created by\n       using the process image of the parent process, including its code and data segments. However, the parent process stop temporarily until the child process invokes an execve()-like system call to start a new program or terminates. The child process can modify any contents of the\n       data segment of the parent process.\n\n\n\n\n\n\n\n\n\n\nIn the multi-core age, threading is encouraged. Please answer the following questions: (8pts)\n\n\n\n\n\n\nFor multiple cores, do we prefer kernel-level threads or user-level threads? Why? (3pts) [Fall 2013 6.(b)]\n\n\nWe prefer kernel-level threads because we look for parallelism to better utilize multiple cores of a system.\n\n\n\n\n\n\nThere are also challenges in programming. Consider merge sorting, in which an unsorted list is divided into $N$ sublists, each containing $1$ element, and then we repeatedly merge sublists to produce new sorted sublists until there is only $1$ sublist remaining. This will be the sorted list. Please use the concept of task parallelism to execute the merge sort over $N$ cores. (5pts)\n\n\nEach core is given a sublist of one element. We then group 2 adjacent cores and let one of the cores merge the sublists of the two cores.\n\n\n\n\n\n\n\n\n\n\nPlease answer the following questions for process scheduling. Explanation is needed to receive any credit. (15pts)\n\n\n\n\n\n\nGiven 5 processes $P_1$, $P_2$, $P_3$, $P_4$, and $P_5$ with CPU burst time $6$, $5$, $2$, $10$, $5$, respectively. Suppose that the $P_1$, $P_2$, $P_3$, $P_4$, and $P_5$ arrive at time $0$, $3$, $4$, $2$, and $5$, respectively. What is the average waiting time in running the 5 processes under the Preemptive Shortest-Job-First Scheduling. (5pts)\n\n\n(0 + (8 - 3) + (6 - 4) + (18 - 2) + (13 - 5)) / 5 = 31 / 5.\n\n\n\n\n\n\nConsider Shortest-Job-First Scheduling and Round-Robin Scheduling. Please prove that the total waiting time in running all processes under Shortest-Job-First Scheduling is always no larger than that of Round-Robin Scheduling with time slice equal to $1$ when all processes are ready at time $0$? (5pts)\n\n\nYes. \nProof\n:\n\n\nWLOG, given processes $P_1$, $P_2$, $\\dots$, $P_n$ with CPU burst time $t_1$, $t_2$, $\\dots$, $t_n$, where $t_1 < t_2 < \\cdots < t_n$.\n\n\nBy SJF, their waiting time should be:\n\n\n\\begin{array}{c|c}\nP_i & \\text{waiting time} \\\\\n\\hline\nP_1 & 0 \\\\\nP_2 & t_1 \\\\\nP_3 & t_1 + t_2 \\\\\n\\vdots & \\vdots \\\\\nP_n & t_1 + t_2 + \\cdots + t_{n - 1}\n\\end{array}\n\n\nTotal waiting time:\n\n\n$$(n - 1)t_1 + (n - 2)t_2 + \\cdots + t_{n - 1}.$$\n\n\nObviously, this sum is minimized if $t_i$'s that are multiplied more times are smaller ones, i.e., \n\n\n$$t_1 < t_2 < \\cdots < t_{n - 1} < t_n.$$\n\n\nThus, in non-preemptive scheduling, SJF (actually Shortest-next-CPU-burst-first) is optimal for the purpose of minimizing average waiting time.\n\n\n\n\n\n\nSuppose that the variance of the waiting time is the criterion in process scheduling. Shall we have a small time slice for a better variance for Round-Robin Scheduling when all processes of the same CPU burst arrive at time $0$? (5pts) [Fall 2013, 7.(c)]\n\n\nNo. For example, given processes $P_1$, $P_2$ and $P_3$ with CPU burst time $10$, $10$ and $10$\n\n\n\n\nWith quantum $= 10$, average waiting time = (0 + (10 - 0) + (20 - 0)) / 3 = 30 / 10 = 10.\n\n\nWith quantum $= 5$, average waiting time = [0 + (15 - 5) + (5 - 0) + (20 - 10) + (10 - 0) + (25 - 15)] = 45 / 3 = 15.\n\n\nWith quantum $= 1$, average waiting time = ... = (18 + 19 + 20) / 3 = 19.\n\n\nWith quantum $\\to 0$, average waiting time $\\approx$ (20 + 20 + 20) / 3 = 20.\n\n\n\n\nIt is obvious that smaller time slice will lead a longer average waiting time.\n\n\n\n\n\n\n\n\n\n\nPlease answer the following questions for process synchronization: (16pts)\n\n\n\n\n\n\nPlease compare the difference between a binary semaphore and a condition variable. (3pts) [Fall 2012 7.]\n\n\nThe signal operation of a condition variable resumes one suspended process. If there is none, no effect is imposed.\n\n\n\n\n\n\nPlease use Monitor to implement Consumer and Producer with a bounded buffer. (10pts)\n\n\nmonitor\n \nProducerConsumer\n \n{\n\n    \nint\n \ncounter\n \n=\n \n0\n;\n\n    \ncondition\n \nempty\n;\n\n    \ncondition\n \nfull\n;\n\n\n    \nvoid\n \nproducer\n()\n \n{\n\n        \nif\n \n(\ncounter\n \n==\n \nn\n)\n\n            \nwait\n(\nempty\n);\n\n            \n/* produce a slot */\n\n        \ncounter\n++\n;\n\n        \nsignal\n(\nfull\n);\n\n    \n}\n\n\n    \nvoid\n \nconsumer\n()\n \n{\n\n        \nif\n \n(\ncounter\n \n==\n \n0\n)\n\n            \nwait\n(\nfull\n);\n\n            \n/* consume a slot */\n\n        \ncounter\n--\n;\n\n        \nsignal\n(\nempty\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\ncounter: number of filled slots\n\n\nempty: buffer has at least one empty slot\n\n\nfull: buffer has at lesat one full slot\n\n\n\n\n\n\n\n\nPlease prove that your above solution satisfy the Progress requirement of the Critical Section Problem. (3pts)\n\n\nBoth producer and consumer won't be postponed forever...\n\n\n\n\n\n\n\n\n\n\nFall 2015\n\u00b6\n\n\nThe Exam is 180 minutes long. The total score is 105pts. Please read the questions carefully.\n\n\n\n\n\n\nTerminologies.(24pts)\n\n\n\n\n\n\nSoftware Interrupts\n\n\nCaused by software execution, e.g. signals, invalid memory access, division by zero, system calls.\n\n\n\n\n\n\nPerformance Tuning\n\n\nA procedure that seeks to improve performance by removing bottlenecks.\n\n\n\n\n\n\nMid-Term Scheduler\n ($\\leftrightarrow$ Long-Term Scheduler $\\leftrightarrow$ Short-Term Scheduler)\n\n\n\n\nSwap processes in and out to control the degree of multiprogramming.\n\n\n($\\leftrightarrow$) Long-Term Scheduler:\n\n\nSelects processes from this pool\n\n\nLoads them into memory for execution\n\n\nControls the degree of multiprogramming (# processes). \n\n\nSelects a good process mix of I/O-bound and CPU-bound.\n\n\n\n\n\n\n($\\leftrightarrow$) Short-Term Scheduler:\n\n\nSelects from among the processes that are ready to execute\n\n\nAllocates CPU to one of them\n\n\n\n\n\n\n\n\n\n\n\n\nFIFOS of UNIX\n\n\nNamed pipes.\n\n\n\n\n\n\nAsynchronous Signal\n ($\\leftrightarrow$ Synchronous Signal)\n\n\n\n\nAn asynchronous signal usually reports some asynchronous event outside the program, e.g., ^C or time expiration.\n\n\n($\\leftrightarrow$) Delivered to the same process that performed the operation causing the signal. e.g., illegal memory access, division by 0.\n\n\n\n\n\n\n\n\nPush Migration\n (Hint: Load Balancing) [Fall 2011 1.(h)] ($\\leftrightarrow$ Pull Migration)\n\n\n\n\nPushing processes from overloaded to less-busy processors.\n\n\n($\\leftrightarrow$) Pulling a waiting task from a busy processor.\n\n\n\n\n\n\n\n\nCoarse-Grained Multithreading of Hardware Threads\n ($\\leftrightarrow$ Fine-Grained (interleved))\n\n\n\n\nA thread executes on a processor until a long-latency event such as a memory stall occurs.\n\n\n($\\leftrightarrow$) Switches between threads at a much finer level of granularity\n\n\n\n\n\n\n\n\nAnalytic Evaluation\n [Spring 2011 1.(f), Fall 2013 1.(h)]\n\n\nAnalytic evaluation uses the given algorithm and the system workload to produce a formula or number to evaluate the performance of the algorithm for that workload.\n\n\n\n\n\n\n\n\n\n\nPlease answer the following questions regarding operating systems: (20pts)\n\n\n\n\n\n\nPlease compare the difference between interrupt handling by a generic handler and interrupt vector in terms of the mechanism and the response performance. (6pts)\n\n\nA generic handler finds out the interupt type and invokes the corresponding procedure but the interrupt vector lets the corresponding procedure directly invoked though checking up of the interrupt vector; performance: interrupt vector is faster.\n\n\n\n\n\n\nPlease compare the difference between the terms \"time sharing\" and \"multiprogramming\". (4pts) [Fall 2012 2.(a)]\n\n\nTime sharing (or multitasking) is a logical extension of multiprogramming, where CPU services each of ready tasks in a way that every task receives CPU time in an interactive fashion.\n\n\n\n\n\n\nOne of the most challenging parts in the implementations of a virtual machine is to satisfy the assumption of a certain amount of progress in a given amount of time. Please explain the challenge. (6pts)\n\n\nFor example, when two virtual cores share a physical core, in which a task must run for 2ms for every 5ms, but its virtual machine might not receive any service within a 5ms time window.\n\n\n\n\n\n\nParameter passing is an important issue in the implementation of command interpreters. Please explain how a command interpreter of Unix passes parameters to the running process of a command issued on the command interpreter. (4pts)\n\n\nIt can be done by using one of the exec() system calls.\n\n\n\n\n\n\n\n\n\n\nConsider process states: New, Ready, Running, Waiting, and Terminated. Please explain how a state makes a transition to another state, where there is only one processor. (12pts)\n\n\n\n\n\n\n\n\nMessage passing is one major way for interprocess communication.\n\n\n\n\n\n\nWhat is the main difficulty in using symmetric addressing for direct communication?\n\n\nProcess naming (or modularity).\n\n\n\n\n\n\nFor indirect communication, small messages are sent from a sender to a receiver usually by message copying.\n\n\n\n\n\n\nHow to reduce system overheads in-sending large messages to a receiver? (8pts)\n\n\nRemapping of addressing space.\n\n\n\n\n\n\n\n\n\n\nFor multicore programming, there could be data parallelism or task parallelism. Please explain how to use data parallelism to find the largest integer of a given set of integers. (5pts) [Fall 2014 6.(b)]\n\n\nFirst split data over $N$ cores, and let each core find the largest integer of its given integers. Then let one core find the largest integers among the latgest integers found on each core.\n\n\n\n\n\n\nPlease answer the following questions for process scheduling. Explanation is needed to receive any credit. (15pts)\n\n\n\n\n\n\nIs the First-Come, First-Served Scheduling (FIFO) a non-preemptive or preemptive scheduling algorithm? Why? (4pts)\n\n\nIt is non-preemptive because the running process will not volunteer to give up its CPU until it stops.\n\n\n\n\n\n\nGiven 4 processes $P_1$, $P_2$, $P_3$, and $P_4$ with CPU burst time $5$, $2$, $4$, and $6$, respectively. Suppose that the $P_1$, $P_2$, $P_3$, and $P_4$ all arrive at time $0$. What is the average waiting time in running the 4 processes under the Round-Robin Scheduling with the time slice equal to $3$? (5pts) [Fall 2013 7.(a)]\n\n\n(8 + 3 + (5 + 5) + (8 + 3)) / 4 = 32 / 4 = 8.\n\n\n\n\n\n\nLongest-Job-First Scheduling always schedules the process of the longest CPU burst first. When all processes arrive at time $0$, does Longest-Job-First Scheduling have the largest average turnaround time? (6pts) [Fall 2013 7.(c)]\n\n\nYes.\n\n\n\n\n\n\n\n\n\n\nConsider the intersection of the following two roads, where cars can go from each of the four directions. There is a stop sign for each direction so that every car must stop at the intersection and wait for any car that arrives earlier at the intersection to leave first.\n\n\n\n\n\n\nPlease use semaphores to implement your solution with some pseudo code. (10pts) [Fall 2012 8.]\n\n\nUse an integer $S$ with initial value = $1$ to indicate the number of available car and a FIFO queue waiting list.\n\n\ntypedef\n \nstruct\n \n{\n\n    \nint\n \nvalue\n;\n\n    \nstruct\n \nprocess\n \n*\nwaiting_list\n;\n\n\n}\n \nsemaphore\n;\n\n\n\n\n\nwait\n(\nsemaphore\n \n*\nS\n)\n \n{\n\n    \nS\n->\nvalue\n--\n;\n\n    \nif\n \n(\nS\n->\nvalue\n \n<\n \n0\n)\n \n{\n\n        \nadd\n \nthis\n \ncar\n \nto\n \nS\n->\nwaiting_list\n;\n\n        \nblock\n();\n\n    \n}\n\n\n}\n\n\n\n\n\nsignal\n(\nsemaphore\n \n*\nS\n)\n \n{\n\n    \nS\n->\nvalue\n++\n;\n\n    \nif\n \n(\nS\n->\nvalue\n \n<=\n \n0\n)\n \n{\n\n        \nremove\n \na\n \nprocess\n \nP\n \nfrom\n \nS\n->\nwaiting_list\n;\n\n        \nwakeup\n(\nP\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\n\nPlease prove that your above solution satisfy the three requirements of the Critical Section Problem. (6pts)\n\n\n\n\nMutual exclusioin: only a car can go in the intersection.\n\n\nProgress requirement: by block() and wakeup(), the processes won't wait forever.\n\n\nBounded-waiting: \n\n\n\n\n\n\n\n\nCould you revise your solution so that an ambulance can always go first? (5pts)\n\n\n\n\nLet the ambulance has the highest priority in the waiting queue.",
            "title": "Previous Exams"
        },
        {
            "location": "/OS/midterm/#previous-operating-system-midterms-at-ntucsie",
            "text": "",
            "title": "Previous Operating System Midterms at NTUCSIE"
        },
        {
            "location": "/OS/midterm/#spring-2011",
            "text": "Terminologies. (24pts)    Security  Defense of a system from external and internal attacks, e.g., viruses, denial of services, etc.    A Layered Approach in OS Designs  The operating system is broken into a number of layers (levels). The bottom layer (layer $0$) is the hardware; the highest (layer $N$) is the user interface.    Para-virtualization  A variation on virtualization that presents a guest/operating system that is similar but not identical to the underlying hardware.    Lightweight Process  A virtual processor (kernel threads) on which the application can schedule a user thread to run. (many-to-many or two-level)    NUMA  Non-Uniform Memory Access: A CPU has faster access to some parts of main memory than to other parts.    Deterministic Modeling  Take a particular predetermined workload and defines the performance of each algorithm for that workload.    Race Condition  Several processes access and manipulate the same data concurrently and the outcome of the execution depends on the particular order in which the access takes place.    Write Ahead Logging  All modifications are written to a log before they are applied.      Please answer following questions regarding the design the design of operation systems. (22pts)  There are two conflicting goals in OS designs: Convenience and Efficiency.   Please give me one example feature of OS that shows the conflict in persuing efficiency and convenience (Hint: Live preview of open windows for Windows7 taskbar). (5pts)  What is the main goal of Unix process init? Is init a user or kernel process? (8pts)  Please explain how I/O protection is done. (5pts)  Give me one advantage in OS implementations in some high-level language. (4pts)     Please answer the following questions for process managment. (16pts)   Inside the Process Control Block, we might have a filed \"Program Counter\". What is the purpose of the field? (4pts)  There are a lot of segments for a process image, such as code segment, data segment, heap, and user stack. When we call malloc() or free(), which segment is involved? (4pts)  When a parent process calls fork() to create a child process, how does the parent process know the process ID of the created child process? (4pts)  Which of the following IPC mechanisms does not require two communicating processes to have a parent-child relationship: Named Pipes and sockets. (4pts)     Please answer the following questions for CPU scheduling. (17pts)   Compared to user-level threads, why the cost of context switching for kernel-level threads in higher? (4pts)  The delivery of a signal for theads is complicated. Give me an example signal that should be delivered to the threads to which the signal applies. (4pts)  For preemptive scheduling, there are serveral occasions in triggering scheduling. Please give me three, beside the one in which a running process terminates by itself. (9pts)     Consider Shortest-Job-First(SJF) and Round-Robin(RR) scheduling algorithms, and processes under considerations are only of one single CPU burst and are all ready at time $0$. Please answer the folowing questions. Explanation is needed to receive any credit: (18pts)   Is SJF always better than RR, for any time quantum, in terms of the average turnaround time?(6pts)  When all processes are of the same size, please tell us what the best time quantum is for RR in terms of the average waiting time. (6pts)  Now suppose that processes might arrive at different times, and SJF and RR are preemptive scheduling algorithms. Is SJF always better than RR, for any time quantum, in terms of the average waiting time. (6pts)     Please design a solution for airplanes to land in an airport. Suppose that there is only one runway in the airport. Please make sure that only one airplane can control the runway to land at a time, and there should be no starvation for your solution. (Hint: (1) the Bakery Algorithm; (2) Each process donotes an airplane.) (10pts)",
            "title": "Spring 2011"
        },
        {
            "location": "/OS/midterm/#fall-2011",
            "text": "The exam is 180 minutes long. The total score is 107pts. Please read the questions carefully.    Terminologies. (24pts)    DMA  Release CPU from handling excessive interrupts!\nExecute the device driver to set up the registers of the DMA controller. DMA moves blocks of data between the memory and its own buffers. Transfer from its buffers to its devices. Interrupt the CPU when the job is done.    Multiprogramming  Increases CPU utilization by organizing jobs so that the CPU always has one to execute.    Horizontal Cache Coherency and Consistency  Among units of the same storage level.  From  \u77e5\u4e4e :   Coherence \u4fdd\u8b49\u7684\u662f\u540c\u4e00\u5730\u5740\u6709\u4e0d\u540c copy \u7684\u6642\u5019\uff0c\u4fdd\u8b49\u770b\u5230\u7684\u662f\u5728 timing \u4e0a\u96e2\u81ea\u5df1\u6700\u8fd1\u7684\u3002   \u4f46\u662f\uff0c\u53ea\u4fdd\u8b49 Coherence \u662f\u4e0d\u5920\u7684\uff0c\u5728 multiprocessor \u4e0d\u540c\u5730\u5740\u7684\u591a\u500b copy \u8a2a\u554f\u7684\u6642\u5019\u6703\u51fa\u73fe\u554f\u984c\uff0c\u9019\u500b\u5c31\u662fconsistency    Coherence is concerned with updates/invalidations to a single shared variable.   Consistency is concerned with the behavior of memory references from multiple concurrent threads.     A Module Approach in OS Designs  (Hint: A Layered Approach) [ask]  Moving all nonessential components from the kernel to the user or system programs!    Indirect Communication in Message Passing  ($\\leftrightarrow$ Direct)   The messages are sent to and received from mailboxes, or ports.  ($\\leftrightarrow$) The messages are sent to and received from processes.     Socket  An endpoint for communication. (IP + port#)    Deferred Cancellation  ($\\leftrightarrow$ Asynchronous Cancellation)   The target thread periodically checks whether it should terminate, allowing it an opportunity to terminate itself in an orderly fashion.  ($\\leftrightarrow$) One thread immediately terminates the target thread.     Pull Migration  (Hint: Multipocessor Scheduling) ($\\leftrightarrow$ Push Migration)   Pulling a waiting task from a busy processor.  ($\\leftrightarrow$) Pushing processes from overloaded to less-busy processors.       Please answer the following questions regarding the designs of operating systems: (23pts)   Please give me two resources, beside CPU, that are managed by OS. (6pts)  When an interrupt arrives, a running task is interrupted, and its context could be saved in different ways, such as \"a fixed address for all interrupts\", \"a fixed space for each interrupt type\", and \"a stack\". What is the advantage in using a stack, compared with the approach in using a fixed space for each interrupt type? (5pts)  In a memory hierarchy, we have registers, cache, memory, and disk. Which of them is managed by operating systems? Which of them is managed by hardware? (l2pts)     OS services are such as those for \"program execution\", \"file-system manipulation\", \"accounting\", and \"resource allocation\". Which of them are for system efficiency, instead of user convenience? (8pts)    Famous Application Programming Interfaces (API) are such as Win 32 API and POSIX API. What are the two major benefits in providing API, compared to\n   the providing of system calls only? What does POSIX API offers to programmers, compared to the offering of ANSI C to programmers? (8pts)    In the ordinary virtualization design, the virtualization layer runs in the system mode. For VMware, the virtualization layer runs in the system or user mode? For Java, the Java virtual machine run in the system or user mode? (6pts)    Please answer the following questions for process management and scheduling. (20pts)   Give me two conditions for a running process to relinquish the CPU to go back to the ready queue in preemptive CPU scheduling. (6pts)  Why a long-term scheduler has more time to choose a process for a system than a short-term scheduler does in process scheduling? (5pts)  Please explain the main difference between a user-level thread and a kernel thread. (5pts)  Is a Java thread is a user-level thread or a kernel thread? (4pts)     The scheduling algorithm of Solaris 9 is based on the Multilevel Feedback Queue Scheduling algorithm. There are six priority classes. Please explain the Fair Sharing class? Please explain how interactive threads in the Time Sharing or Interactive class are favored in scheduling in Solaris 8 or 9? (6pts)    Consider the scheduling of processes in which processes might arrive at different times and have different deadlines to complete their execution. Let the processes be scheduled by the preemptive Shortest-Job-First algorithm (PSJF) and a Priority Scheduling algorithm (PS) in which processes with urgent deadlines have higher priorities, and there is only one processor. Can you give a set of processes such that PS can meet the deadlines of the processes, but PSJF can not do it? (5pts)    Consider the Round Robin scheduling algorithm (RR) with two different time quantums $L$ and $S$, where $L > S$. Let the scheduling criteria be the average\n   waiting time, and $L$ be larger than the largest CPU burst of all processes. Does RR, in general, favor a small time quantum $S$ when all processes are\n   ready at time $0$? Please give me your answer with argument. (7pts)",
            "title": "Fall 2011"
        },
        {
            "location": "/OS/midterm/#fall-2012",
            "text": "The exam is 180 minutes long. The total score is 110pts. Please read the questions carefully.    Terminologies. (24pts)    Hardware Interrupt  Services requests of I/O devices.    Virtual Machine  Provides an interface that is identical to the underlying bare hardware.    Context Switch  It saves the state of the currently running process and loads the state of the newly scheduled process.    A Full Duplex Pipe  A pipe that suppors two ways of message passing simultaneously.    Multilevel Queue Scheduling  Processes can be classified into different groups and permanently assigned to one queue, where there are Inter-queue and intra-queue scheduling policies.    Memory Stall  A phenomenon in which a processor waits for a significant amount of time waiting for the data to become available.    Bounded Waiting  (A Requirement of a Critical Section Solution)  A waiting process only waits for a bounded number of processes to enter their critical sections.    Adaptive Mutex  A binary semaphore in which it is a spinlock if the lock-holding thread is running; otherwise, blocking is used.      Please answer the following questions regarding the designs of operating systems: (20pts)    What is the difference between  multiprogramming  and  time sharing ? (6pts)  Time sharing (or multitasking) is a logical extension of multiprogramming, where CPU services each of ready tasks in a way that every task receives CPU time in an interactive fashion.    Which one of the following memory unit is managed by the operating systems: Registers, Cache, Main Memory, Disks (8pts)  Main Memory and Disks.    Operating systems services include user interfaces. UNIX shells, including the Bourne shell and C shell, provide command interpreters. Consider UNIX shells, please give me one command that is implemented as some code inside the command interpreter and two commands that are implemented by system programs? (6pts)    Inside the command interpreter:   C shell:  umask, cd and limit  Bourne shell:  ulimit -H and -S     By system programs:  rm and ls        Message passing is a way for interprocess communication. Consider the capacity of a link between two processes has zero capacity. Is the message passing (between the two processes) synchronous or asynchronous? You must provide explanation to receive any credits. (5pts)  It is synchronous because we can only have blocking sends and blocking receives.      Please give me one occasion when a mid-term scheduler should run.  The remaining main memory is low or the CPU utilization is too high.    Can a short-term scheduler schedule the executions of user-level threads?  No.    Can a short-term scheduler schedule the executions of a Java thread? (9pts)  It depends on the thread library on the host system.      Consider signal handling for threads.     Is a Division-By-Zero signal synchronous or asynchronous?  Synchronous.    Should a Division-By-Zero signal be delivered to every thread of its belonging process? (6pts)  No. It should be only sent to the thread that causes the signal.      Please answer the following questions for process scheduling. Explanation is needed to receive any credit. (24pts)    For the Round-Robin Scheduling, what would be the preferred time slice in general? (4pts)  The time slice $\\ge 80\\%$ CPU burst.    For the Round-Robin Scheduling, shall we have a small time slice for a better average turn around time? (4pts)  No, a small time slice will increase the average turnaround time.    For the Priority Scheduling, how to avoid the starvation problem (in which a low priority process can never be scheduled)? (4pts)  An  aging  solution by increasing the priority of a process that waits for a long time.    Please explain how a guest operating-system scheduling algorithm that assumes a certain amount of progress in a given amount of time might be negatively impacted by virtualization. (6pts)  It is because the virtualization software needs to schedule the use of the physical CPUs among the virtual CPUs. A given amount of the time slice might take much more than the time of the virtual CPU time.    For the evaluation of a scheduling algorithm, please give me two difficulties in using the implementation method. (6pts)   Cost in modifying the OS  User reaction to OS changes  Changing of the environment in which the algorithm is used       Please explain the difference between the signal operation of a binary semaphore and that of a condition variable (of a monitor). (5pts)  The signal operation of a condition variable resumes one suspended process. If there is none, no effect is imposed.    Consider a barber shop in which there are two barbers. Each barber can service exactly one customer at a time. Please use binary semaphores to implement the request for the hair-cut service. (12pts)  Use an integer $S$ with initial value = $2$ to indicate the number of available barbers.  typedef   struct   { \n     int   value ; \n     struct   process   * waiting_list ;  }   semaphore ;   wait ( semaphore   * S )   { \n     S -> value -- ; \n     if   ( S -> value   <   0 )   { \n         add   this   customer   to   S -> waiting_list ; \n         block (); \n     }  }   signal ( semaphore   * S )   { \n     S -> value ++ ; \n     if   ( S -> value   <=   0 )   { \n         remove   a   process   P   from   S -> waiting_list ; \n         wakeup ( P ); \n     }  }     Consider the time-stamp protocol of Chapter 6, in which each process $T_i$ is given a time stamp $T_S(T_i)$, and each read/write operation must check it up with the read and write timestamp of the accessed data object $Q$. Is it possible to have any deadlock? You must provide your explanation. (5pts) [ask]  No deadlock because there is no hold-and-wait among processes.",
            "title": "Fall 2012"
        },
        {
            "location": "/OS/midterm/#fall-2013",
            "text": "The exam is 180 minutes long. The total score is 103pts. Please read the questions carefully.    Terminologies. (24pts)    Booting  Initialize all aspects of the system and then load and run the OS.    Interrupt Vector  An array of interrupt-handlers' addresses that are indexed by device numbers (or interrupt numbers).    Cache Coherency  [Fall 2011 1.(c)]  Cache coherency problems can arise when more than one processors refer to the same data. Coherency defines what value is returned on a read.    Platform as a service (PaaS) in Cloud Computing  Pass provides a computing platform and a solution stack as a service, such as a database server. One example is Microsoft Azure.    A Modular Kernel  (Hint: OS Structure) [Fall 2011 1.(d)]  A moduler kernel consists of a set of components, where there are core/primary modules, and it is of modules without a layer structure.    Data Parellelism in Multicore Programming  Distribute data over cores to execute the  same operation .    Rate Monotonic Scheduling  A fixed priority real-time process scheduling algorithm in which the priorities of processes are  inversely proportional to their periods .    Deterministic Modeling  [Spring 2011 1.(f)]  Take a particular predetermined workload and defines the performance of each algorithm for that workload.      Please answer the following questions regarding the designs of operating systems: (20pts)    There are two conflicting goals in the designs of operating systems. What is the other one, beside \"convenient for the users\" ? (3pts)  Efficient operation of the computer system.    Which one of the following actions/events is belonging to or might result in software interrupts: System calls, child termination, mouse clicking, invalid memory access. (8pts)  System calls, child temination, and invalid memory access.    Consider the implementation of virtual machines in which operating systems run on the top of the virtual machine software (or referred to as the hypervisor). Is an operating system running in the user mode or kernel mode? (3pts)  The user mode.    Please give me 2 advantages of virtual machines, beside system consolidation and easy in system development/deployment. (6pts)  Copmlete isolation and multiple personalities.      ANSI C refers to the family of successive standards published by ANSI for the C programming language. Please compare difference (or provide the purpose difference) between POSIX and ANSI C. (5pts)    Any program written only in ANSI C and without any hardware dependent assumptions is virtully guaranteed to compile correctly on any platform with a conforming C implementation.    POSIX is an acronym for \"Portable Operating System Interface\". POSIX is for software compatibility with variants of Unix and other operating systems.      Please answer the following questions for task scheduling. (14pts)    Is the \"Swapper\" a short-term or mid-term scheduler? [ask]  Short-term scheduler.    In Unix, the process control block PCB[] of a process consists of proc[] and .u, where the attributes in .u are those needed when the process is running, and the attributes in proc[] are those needed all the time. Please indicate which one should be in .u : file[], task priority, pid, signal disposition, and task state. You must provide explanation to receive any credits. (10pts) [ask]   file[]: what files are \"being\" opened.  signal disposition: how to deal with signals.       Consider message passing and shared memory for inerprocess communication. Is \"Pipe\" considered one for message passing or shared memory ? Is \"Pipe\" direct or indirect communication ? Is it \"synchronous\" or \"asynchronous\"? for a reader or a writer of the communication in Unix. You must provide explanation to receive any credits. (12pts)   Message passing. Since it's communication between processes without sharing the same address space.  Indirect communication. [ask]  Synchronous for a reader. [ask]  Asynchronous for a writer. [ask]     Kernel-level threads are superior than uer-level threads do in many ways.    What is the main disadvantage of kernel-level threads?  It is context switching cost.    With OpenMP in program development, shall we prefer kernel-level or user-level threads? You must provide explanation to receive any credits. (8pts)  We prefer kernel-level threads because we look for parallelism to better utilize multiple cores of a system.      Please answer the following questions for process scheduling. Explanation is needed to receive any credits. (15pts)    Given 3 processes $P_1$, $P_2$, and $P_3$ with CPU burst time $5$, $6$, $7$, respectively. Suppose that the 3 processes arrive at time $0$, and $P_1$ and $P_3$ are the first and the last processes in the ready queue, respectively. What is the average waiting time in running the 3 processes under the Round-Robin Scheduling with the time slice equal to $3$. (5pts)   (6 + (3 + 5) + (6 + 5)) / 3 = 25 / 3.    Consider FCFS and Round-Robin Scheduling. If process are only of CPU burst and all arrive at time $0$, do FCFS and Round-Robin Scheduling with time slice = $1$ always have the same total waiting time in running all processes ? Prove your answer. (5pts)  No, for example, given processes of CPU burst 7, 1, and 1.    Suppose that the variance of the tunaround time is the cirterion in process scheduling. Shall we have a small time slice for a better variance turnaround time when all processes arrive at time $0$? (5pts)  No. For example, given processes $P_1$, $P_2$ and $P_3$ with CPU burst time $10$, $10$ and $10$.   With quantum $= 10$, average turnaround time = (10 + 20 + 30) / 3 = 60 / 3 = 20.  With quantum $= 5$, average turnaround time = (20 + 25 + 30) / 3 = 75 / 3 = 25.  With quantum $= 1$, average turnaround time = ... = (28 + 29 + 30) / 3 = 87 / 3 = 29.  With quantum $\\to 0$, average turnaround time $\\approx$ 30 + 30 + 30 = 90 / 3 = 30.   It is obvious that smaller time slice will lead a longer average turnaround time.      Please explain why the Completely Fair Scheduling (CFS) of Linux V2.6 favors I/O tasks. (5pts)  CFS usually dispatches the CPU to the task with the smallest vruntime (that denotes how long the task runs) such that I/O tasks usually have smaller vruntime.",
            "title": "Fall 2013"
        },
        {
            "location": "/OS/midterm/#fall-2014",
            "text": "The exam is 180 minutes long. The total score is 108pts. Please read the questions carefully.    Terminologies. (24pts)    Buffering  (Hint: It is not caching.)  It means to keep data in a faster medium temporarily before moving them to a slower layer.    Virtual Machine  [Fall 2012 1.(b)]  Provides an interface that is identical to the underlying bare hardware.    System Generation  (SYSGEN)  The process to configure or generate an operating system for a one specific computer.    Context Switch  [Fall 2012 1.(c)]  Save the state of the old process and load the state of the newly scheduled process.    Remote Procedure Call  (Hint: Message Passing)  Senders are blocked until the receivers have received messages and replied by reply messaeggs. (A way to abstract the procedure-call mechanism for use between systems with network connection.)    Implicit Threading  Transfer the creation and management of the threading from the application developers to compilers and run-time libraries.    Earliest Deadline First Scheduling  A dynamic-priority real-time process scheduling algorithm in which the priorities of processes are higher if their deadlines are closer.    Race Condition  [Spring 2011 1.(g)]  Several processes access and manipulate the same data concurrently and the outcome of the execution depends on the particular order in which the access takes place.      Please answer the following questions regarding the designs of operating systems: (22pts)    An operating system could be considered as a resource allocator. Please list 3 resources managed by an operating systems. (6pts)  CPU time, Memory Space, File Storage, I/O Devices, Shared Code, Data Structures, and more.    Please explain what happens to the operating system when an interrupt arrives (until the interrupt is serviced). (4pts)  Saving of the address of the interrupted instruction, determine the interrupt type (by polling or interrupt vector), call the corresponding handlers.    Which one of the following instructions is a privileged instruction:  Reading of the Timer, setting of the base register of the memory space of a process, increment the value of a CPU register by one. No explanation is needed. (6pts)  Setting of the base register of the memory space of a process.    Please explain what happens when a command-line user interface of Unix executes a command. (6pts)  Search the exec file which corresponds to the command; fork a process\n       to execute the file.      Consider parameter passing to a system call. Give me the major advantage in having a register pointing to a memory block that stores all parameters, compared to having all parameters stored in registers? (5pts)  The space needed to store all parameters is virtually unlimited.    The memory image of a Unix process might consist of a code segment, a data segment, a heap area, a user stack, a kernel stack, an environment variable area, and .u.     Which one of the above is used when  malloc()  is invoked?  heap.    When the kernel stack is used? (8pts) [ask]  Procedure invocation in the system mode.        Please explain how  fork()  works when a parent process invoke  fork() .  When a parent process invoke fork(), a duplication of the parent process is created for the resulted child process, where the parent process returns from fork() with the process ID of the created child process. The child process returns 0.    Please use the answer to the  fork()  invocation to explain the difference between  fork()  and  vfork() . (10pts)  When a parent process invoke vfork(), a child process is created by\n       using the process image of the parent process, including its code and data segments. However, the parent process stop temporarily until the child process invokes an execve()-like system call to start a new program or terminates. The child process can modify any contents of the\n       data segment of the parent process.      In the multi-core age, threading is encouraged. Please answer the following questions: (8pts)    For multiple cores, do we prefer kernel-level threads or user-level threads? Why? (3pts) [Fall 2013 6.(b)]  We prefer kernel-level threads because we look for parallelism to better utilize multiple cores of a system.    There are also challenges in programming. Consider merge sorting, in which an unsorted list is divided into $N$ sublists, each containing $1$ element, and then we repeatedly merge sublists to produce new sorted sublists until there is only $1$ sublist remaining. This will be the sorted list. Please use the concept of task parallelism to execute the merge sort over $N$ cores. (5pts)  Each core is given a sublist of one element. We then group 2 adjacent cores and let one of the cores merge the sublists of the two cores.      Please answer the following questions for process scheduling. Explanation is needed to receive any credit. (15pts)    Given 5 processes $P_1$, $P_2$, $P_3$, $P_4$, and $P_5$ with CPU burst time $6$, $5$, $2$, $10$, $5$, respectively. Suppose that the $P_1$, $P_2$, $P_3$, $P_4$, and $P_5$ arrive at time $0$, $3$, $4$, $2$, and $5$, respectively. What is the average waiting time in running the 5 processes under the Preemptive Shortest-Job-First Scheduling. (5pts)  (0 + (8 - 3) + (6 - 4) + (18 - 2) + (13 - 5)) / 5 = 31 / 5.    Consider Shortest-Job-First Scheduling and Round-Robin Scheduling. Please prove that the total waiting time in running all processes under Shortest-Job-First Scheduling is always no larger than that of Round-Robin Scheduling with time slice equal to $1$ when all processes are ready at time $0$? (5pts)  Yes.  Proof :  WLOG, given processes $P_1$, $P_2$, $\\dots$, $P_n$ with CPU burst time $t_1$, $t_2$, $\\dots$, $t_n$, where $t_1 < t_2 < \\cdots < t_n$.  By SJF, their waiting time should be:  \\begin{array}{c|c}\nP_i & \\text{waiting time} \\\\\n\\hline\nP_1 & 0 \\\\\nP_2 & t_1 \\\\\nP_3 & t_1 + t_2 \\\\\n\\vdots & \\vdots \\\\\nP_n & t_1 + t_2 + \\cdots + t_{n - 1}\n\\end{array}  Total waiting time:  $$(n - 1)t_1 + (n - 2)t_2 + \\cdots + t_{n - 1}.$$  Obviously, this sum is minimized if $t_i$'s that are multiplied more times are smaller ones, i.e.,   $$t_1 < t_2 < \\cdots < t_{n - 1} < t_n.$$  Thus, in non-preemptive scheduling, SJF (actually Shortest-next-CPU-burst-first) is optimal for the purpose of minimizing average waiting time.    Suppose that the variance of the waiting time is the criterion in process scheduling. Shall we have a small time slice for a better variance for Round-Robin Scheduling when all processes of the same CPU burst arrive at time $0$? (5pts) [Fall 2013, 7.(c)]  No. For example, given processes $P_1$, $P_2$ and $P_3$ with CPU burst time $10$, $10$ and $10$   With quantum $= 10$, average waiting time = (0 + (10 - 0) + (20 - 0)) / 3 = 30 / 10 = 10.  With quantum $= 5$, average waiting time = [0 + (15 - 5) + (5 - 0) + (20 - 10) + (10 - 0) + (25 - 15)] = 45 / 3 = 15.  With quantum $= 1$, average waiting time = ... = (18 + 19 + 20) / 3 = 19.  With quantum $\\to 0$, average waiting time $\\approx$ (20 + 20 + 20) / 3 = 20.   It is obvious that smaller time slice will lead a longer average waiting time.      Please answer the following questions for process synchronization: (16pts)    Please compare the difference between a binary semaphore and a condition variable. (3pts) [Fall 2012 7.]  The signal operation of a condition variable resumes one suspended process. If there is none, no effect is imposed.    Please use Monitor to implement Consumer and Producer with a bounded buffer. (10pts)  monitor   ProducerConsumer   { \n     int   counter   =   0 ; \n     condition   empty ; \n     condition   full ; \n\n     void   producer ()   { \n         if   ( counter   ==   n ) \n             wait ( empty ); \n             /* produce a slot */ \n         counter ++ ; \n         signal ( full ); \n     } \n\n     void   consumer ()   { \n         if   ( counter   ==   0 ) \n             wait ( full ); \n             /* consume a slot */ \n         counter -- ; \n         signal ( empty ); \n     }  }    counter: number of filled slots  empty: buffer has at least one empty slot  full: buffer has at lesat one full slot     Please prove that your above solution satisfy the Progress requirement of the Critical Section Problem. (3pts)  Both producer and consumer won't be postponed forever...",
            "title": "Fall 2014"
        },
        {
            "location": "/OS/midterm/#fall-2015",
            "text": "The Exam is 180 minutes long. The total score is 105pts. Please read the questions carefully.    Terminologies.(24pts)    Software Interrupts  Caused by software execution, e.g. signals, invalid memory access, division by zero, system calls.    Performance Tuning  A procedure that seeks to improve performance by removing bottlenecks.    Mid-Term Scheduler  ($\\leftrightarrow$ Long-Term Scheduler $\\leftrightarrow$ Short-Term Scheduler)   Swap processes in and out to control the degree of multiprogramming.  ($\\leftrightarrow$) Long-Term Scheduler:  Selects processes from this pool  Loads them into memory for execution  Controls the degree of multiprogramming (# processes).   Selects a good process mix of I/O-bound and CPU-bound.    ($\\leftrightarrow$) Short-Term Scheduler:  Selects from among the processes that are ready to execute  Allocates CPU to one of them       FIFOS of UNIX  Named pipes.    Asynchronous Signal  ($\\leftrightarrow$ Synchronous Signal)   An asynchronous signal usually reports some asynchronous event outside the program, e.g., ^C or time expiration.  ($\\leftrightarrow$) Delivered to the same process that performed the operation causing the signal. e.g., illegal memory access, division by 0.     Push Migration  (Hint: Load Balancing) [Fall 2011 1.(h)] ($\\leftrightarrow$ Pull Migration)   Pushing processes from overloaded to less-busy processors.  ($\\leftrightarrow$) Pulling a waiting task from a busy processor.     Coarse-Grained Multithreading of Hardware Threads  ($\\leftrightarrow$ Fine-Grained (interleved))   A thread executes on a processor until a long-latency event such as a memory stall occurs.  ($\\leftrightarrow$) Switches between threads at a much finer level of granularity     Analytic Evaluation  [Spring 2011 1.(f), Fall 2013 1.(h)]  Analytic evaluation uses the given algorithm and the system workload to produce a formula or number to evaluate the performance of the algorithm for that workload.      Please answer the following questions regarding operating systems: (20pts)    Please compare the difference between interrupt handling by a generic handler and interrupt vector in terms of the mechanism and the response performance. (6pts)  A generic handler finds out the interupt type and invokes the corresponding procedure but the interrupt vector lets the corresponding procedure directly invoked though checking up of the interrupt vector; performance: interrupt vector is faster.    Please compare the difference between the terms \"time sharing\" and \"multiprogramming\". (4pts) [Fall 2012 2.(a)]  Time sharing (or multitasking) is a logical extension of multiprogramming, where CPU services each of ready tasks in a way that every task receives CPU time in an interactive fashion.    One of the most challenging parts in the implementations of a virtual machine is to satisfy the assumption of a certain amount of progress in a given amount of time. Please explain the challenge. (6pts)  For example, when two virtual cores share a physical core, in which a task must run for 2ms for every 5ms, but its virtual machine might not receive any service within a 5ms time window.    Parameter passing is an important issue in the implementation of command interpreters. Please explain how a command interpreter of Unix passes parameters to the running process of a command issued on the command interpreter. (4pts)  It can be done by using one of the exec() system calls.      Consider process states: New, Ready, Running, Waiting, and Terminated. Please explain how a state makes a transition to another state, where there is only one processor. (12pts)     Message passing is one major way for interprocess communication.    What is the main difficulty in using symmetric addressing for direct communication?  Process naming (or modularity).    For indirect communication, small messages are sent from a sender to a receiver usually by message copying.    How to reduce system overheads in-sending large messages to a receiver? (8pts)  Remapping of addressing space.      For multicore programming, there could be data parallelism or task parallelism. Please explain how to use data parallelism to find the largest integer of a given set of integers. (5pts) [Fall 2014 6.(b)]  First split data over $N$ cores, and let each core find the largest integer of its given integers. Then let one core find the largest integers among the latgest integers found on each core.    Please answer the following questions for process scheduling. Explanation is needed to receive any credit. (15pts)    Is the First-Come, First-Served Scheduling (FIFO) a non-preemptive or preemptive scheduling algorithm? Why? (4pts)  It is non-preemptive because the running process will not volunteer to give up its CPU until it stops.    Given 4 processes $P_1$, $P_2$, $P_3$, and $P_4$ with CPU burst time $5$, $2$, $4$, and $6$, respectively. Suppose that the $P_1$, $P_2$, $P_3$, and $P_4$ all arrive at time $0$. What is the average waiting time in running the 4 processes under the Round-Robin Scheduling with the time slice equal to $3$? (5pts) [Fall 2013 7.(a)]  (8 + 3 + (5 + 5) + (8 + 3)) / 4 = 32 / 4 = 8.    Longest-Job-First Scheduling always schedules the process of the longest CPU burst first. When all processes arrive at time $0$, does Longest-Job-First Scheduling have the largest average turnaround time? (6pts) [Fall 2013 7.(c)]  Yes.      Consider the intersection of the following two roads, where cars can go from each of the four directions. There is a stop sign for each direction so that every car must stop at the intersection and wait for any car that arrives earlier at the intersection to leave first.    Please use semaphores to implement your solution with some pseudo code. (10pts) [Fall 2012 8.]  Use an integer $S$ with initial value = $1$ to indicate the number of available car and a FIFO queue waiting list.  typedef   struct   { \n     int   value ; \n     struct   process   * waiting_list ;  }   semaphore ;   wait ( semaphore   * S )   { \n     S -> value -- ; \n     if   ( S -> value   <   0 )   { \n         add   this   car   to   S -> waiting_list ; \n         block (); \n     }  }   signal ( semaphore   * S )   { \n     S -> value ++ ; \n     if   ( S -> value   <=   0 )   { \n         remove   a   process   P   from   S -> waiting_list ; \n         wakeup ( P ); \n     }  }     Please prove that your above solution satisfy the three requirements of the Critical Section Problem. (6pts)   Mutual exclusioin: only a car can go in the intersection.  Progress requirement: by block() and wakeup(), the processes won't wait forever.  Bounded-waiting:      Could you revise your solution so that an ambulance can always go first? (5pts)   Let the ambulance has the highest priority in the waiting queue.",
            "title": "Fall 2015"
        },
        {
            "location": "/ML/",
            "text": "Machine Learning | notes\n\u00b6\n\n\nIn this page, I'll work on my notes when I watch the \nMachine Learning course video\n provided by Professor \nHung-yi Lee\n.",
            "title": "Preface"
        },
        {
            "location": "/ML/#machine-learning-notes",
            "text": "In this page, I'll work on my notes when I watch the  Machine Learning course video  provided by Professor  Hung-yi Lee .",
            "title": "Machine Learning | notes"
        },
        {
            "location": "/ML/regression/",
            "text": "Regression\n\u00b6\n\n\nOverview:\n\n\nA set of function -> Goodness of function $f$ <- Training Data\n\n\nStep 1: Model\n\n\n\n\nLinear model: \n\n\n\n\n$$y = b + \\sum w_i x_i,$$\n\n\nwhere\n\n\n\n\n$x_i$: an attribute of input $x$ (feature),\n\n\n$w_i$: weight and\n\n\n$b$: bias.\n\n\n\n\nStep 2: Goodness of Function\n\n\nTraning Data: $(x^1, \\hat y^1)$, $(x^1, \\hat y^1)$, $\\dots$, $(x^{10}, \\hat y^{10})$. This is real data. \n\n\nWe can get $(x_{cp}^n, \\hat y^n)$ based on how many data we have.\n\n\nTo determine \nhow bad\n a function is, we have to declare:\n\n\n\n\nLoss function $L$: \n\n\n\n\nInput: a function, output: how bad it is\n\n\n\\begin{align}\n    L(f) & = L(w, b) \\\\\n         & = \\sum_{n = 1}^{10} (\\hat y^n - (b + w \\cdot x_{cp}^n))^2.\n  \\end{align}\n\n\nWe have to pick the \"best\" function\n\n\n\\begin{align}\nf^* & = arg \\min_f L(f) \\\\\nw^*, b^* & = arg \\min_{w, b} L(w, b) \\\\\n         & = arg \\min_{w, b} \\sum_{n = 1}^{10} (\\hat y^n - (b + w \\cdot x_{cp}^n))^2.\n\\end{align}\n\n\nStep 3: Gradient Descent\n\n\nConsider loss function $L(w)$ with one parameter $w$:\n\n\n\n\n(Randomly) Pick an initial value $w^0$\n\n\nCompute $\\frac{dL}{dw}\\Big |_{w = w^0}$\n\n\nif $\\frac{dL}{dw}\\Big |_{w = w^0} < 0$: increase $w$\n\n\nif $\\frac{dL}{dw}\\Big |_{w = w^0} > 0$: decrease $w$\n\n\n\n\n\n\n\n\n$$w^1 \\leftarrow w^0 - \\eta \\frac{dL}{dw}\\Big |_{w = w^0}$$ \n\n\nwhere $\\eta$: learning rate.\n\n\n\n\nCompute $\\frac{dL}{dw}\\Big |_{w = w^1}$\n\n\n\n\n$$w^2 \\leftarrow w^1 - \\eta \\frac{dL}{dw}\\Big |_{w = w^1}$$\n\n\n$$\\vdots$$\n\n\nConsider two parameters $w$, $b$:\n\n\n\n\n(Randomly) Pick initial value $w^0$, $b^0$\n\n\nCompute $\\frac{\\partial L}{\\partial w}\\Big |_{w = w^0, b = b^0}$ and $\\frac{\\partial L}{\\partial b}\\Big |_{w = w^0, b = b^0}$\n\n\n\n\n$$w^1 \\leftarrow w^0 - \\eta \\frac{\\partial L}{\\partial w}\\Big |_{w = w^0, b = b^0} \\qquad b^1 \\leftarrow b^0 - \\eta \\frac{\\partial L}{\\partial b}\\Big |_{w = w^0, b = b^0}$$",
            "title": "Regression"
        },
        {
            "location": "/ML/regression/#regression",
            "text": "Overview:  A set of function -> Goodness of function $f$ <- Training Data  Step 1: Model   Linear model:    $$y = b + \\sum w_i x_i,$$  where   $x_i$: an attribute of input $x$ (feature),  $w_i$: weight and  $b$: bias.   Step 2: Goodness of Function  Traning Data: $(x^1, \\hat y^1)$, $(x^1, \\hat y^1)$, $\\dots$, $(x^{10}, \\hat y^{10})$. This is real data.   We can get $(x_{cp}^n, \\hat y^n)$ based on how many data we have.  To determine  how bad  a function is, we have to declare:   Loss function $L$:    Input: a function, output: how bad it is  \\begin{align}\n    L(f) & = L(w, b) \\\\\n         & = \\sum_{n = 1}^{10} (\\hat y^n - (b + w \\cdot x_{cp}^n))^2.\n  \\end{align}  We have to pick the \"best\" function  \\begin{align}\nf^* & = arg \\min_f L(f) \\\\\nw^*, b^* & = arg \\min_{w, b} L(w, b) \\\\\n         & = arg \\min_{w, b} \\sum_{n = 1}^{10} (\\hat y^n - (b + w \\cdot x_{cp}^n))^2.\n\\end{align}  Step 3: Gradient Descent  Consider loss function $L(w)$ with one parameter $w$:   (Randomly) Pick an initial value $w^0$  Compute $\\frac{dL}{dw}\\Big |_{w = w^0}$  if $\\frac{dL}{dw}\\Big |_{w = w^0} < 0$: increase $w$  if $\\frac{dL}{dw}\\Big |_{w = w^0} > 0$: decrease $w$     $$w^1 \\leftarrow w^0 - \\eta \\frac{dL}{dw}\\Big |_{w = w^0}$$   where $\\eta$: learning rate.   Compute $\\frac{dL}{dw}\\Big |_{w = w^1}$   $$w^2 \\leftarrow w^1 - \\eta \\frac{dL}{dw}\\Big |_{w = w^1}$$  $$\\vdots$$  Consider two parameters $w$, $b$:   (Randomly) Pick initial value $w^0$, $b^0$  Compute $\\frac{\\partial L}{\\partial w}\\Big |_{w = w^0, b = b^0}$ and $\\frac{\\partial L}{\\partial b}\\Big |_{w = w^0, b = b^0}$   $$w^1 \\leftarrow w^0 - \\eta \\frac{\\partial L}{\\partial w}\\Big |_{w = w^0, b = b^0} \\qquad b^1 \\leftarrow b^0 - \\eta \\frac{\\partial L}{\\partial b}\\Big |_{w = w^0, b = b^0}$$",
            "title": "Regression"
        }
    ]
}